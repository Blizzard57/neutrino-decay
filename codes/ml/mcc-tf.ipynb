{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import ImageFont\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import tensorflow as tf\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./logs/mcc\n",
    "!rm -rf /home2/kalp_shah/tmp/backup/mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['ttbar','wmp','wpwm','zwpm','n2n2']\n",
    "\n",
    "cs_lo_k = {\n",
    "            'ttbar':988.57,\n",
    "            'wmp'  :1.95*1e5,\n",
    "            'wpwm' :124.31,\n",
    "            'zwpm' :51.82,\n",
    "            'n2n2' :1\n",
    "          }\n",
    "\n",
    "br_ratio = {\n",
    "            'ttbar':0.67*(1-0.67)*2,\n",
    "            'wmp'  :(1-0.67),\n",
    "            'wpwm' :(1-0.67)*0.67*2,\n",
    "            'zwpm' :0.7*(1-0.67),\n",
    "            'n2n2' :1\n",
    "          }\n",
    "\n",
    "cs_nmg = {\n",
    "         'ttbar':393.30,\n",
    "         'wmp'  :7.865*1e4,\n",
    "         'wpwm' :74.96,\n",
    "         'zwpm' :14.28,\n",
    "         'n2n2' :1\n",
    "         }\n",
    "\n",
    "cs_mg = {'ttbar':5.883,\n",
    "          'wmp':111.5,\n",
    "          'wpwm':0.944,\n",
    "          'zwpm':0.2381,\n",
    "          'n2n2':3.99*1e-4\n",
    "        }\n",
    "\n",
    "cs_pb = []\n",
    "for f in files:\n",
    "    cs_pb.append((cs_lo_k[f]*br_ratio[f]*cs_mg[f])/cs_nmg[f])\n",
    "\n",
    "cs = [i*1e3 for i in cs_pb]\n",
    "#k_f = [1.954,1.356,1.92,2.09,1.0]\n",
    "\n",
    "cs_corr = {files[i] : cs[i] for i in range(len(files))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6538.845366086956,\n",
       " 91227.27272727272,\n",
       " 692.2567850586979,\n",
       " 199.5908264705882,\n",
       " 0.399]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_list = list(cs_corr.values())\n",
    "cs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_files = {'ttbar':0,\n",
    "              'wmp':0,\n",
    "              'wpwm':0,\n",
    "              'zwpm':0,\n",
    "              'n2n2':0\n",
    "              }\n",
    "\n",
    "red_merging = {'ttbar':98159,\n",
    "               'wmp':96494,\n",
    "               'wpwm':97633,\n",
    "               'zwpm':81076,\n",
    "               'n2n2':1e5\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_res(x):\n",
    "    res = np.zeros(shape=(x.shape[0],5))\n",
    "    #print(x.shape[0],5)\n",
    "    for i in range(len(x)):\n",
    "        #print(i.x[i])\n",
    "        res[i,x[i]] = 1\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for f in range(len(files)):\n",
    "    con_df = []\n",
    "    \n",
    "    for i in range(1,53):\n",
    "        try:\n",
    "            con_df.append(pd.read_csv('~/neutrino/datasets/csvdata/' + files[f] + str(i) + '.csv'))\n",
    "            no_of_files[files[f]] += 1\n",
    "        except:\n",
    "            pass\n",
    "            #print(\"Not Here : \",files[f],i)\n",
    "    \n",
    "    df.append(pd.concat(con_df,ignore_index=True))\n",
    "    df[-1]['type'] = f\n",
    "    \n",
    "    if files[f] == \"n2n2\":\n",
    "        df[-1]['tag'] = 1\n",
    "    else:\n",
    "        df[-1]['tag'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4024519, 3859760, 3417155, 3567344, 3900000.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_events = []\n",
    "\n",
    "for f in range(len(files)):\n",
    "    total_events.append(no_of_files[files[f]] * red_merging[files[f]])\n",
    "    \n",
    "total_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ptl</th>\n",
       "      <th>etal</th>\n",
       "      <th>energyl</th>\n",
       "      <th>ptj</th>\n",
       "      <th>etaj</th>\n",
       "      <th>energyj</th>\n",
       "      <th>massj</th>\n",
       "      <th>mjj</th>\n",
       "      <th>rjj</th>\n",
       "      <th>rjl</th>\n",
       "      <th>met</th>\n",
       "      <th>n21_1</th>\n",
       "      <th>n21_2</th>\n",
       "      <th>n32_1</th>\n",
       "      <th>n32_2</th>\n",
       "      <th>infl</th>\n",
       "      <th>drfl</th>\n",
       "      <th>type</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>562.212</td>\n",
       "      <td>-1.020360</td>\n",
       "      <td>881.172</td>\n",
       "      <td>1204.370</td>\n",
       "      <td>-1.184170</td>\n",
       "      <td>2154.110</td>\n",
       "      <td>90.8672</td>\n",
       "      <td>2064.210</td>\n",
       "      <td>0.951219</td>\n",
       "      <td>2.76494</td>\n",
       "      <td>2582.970</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0.270936</td>\n",
       "      <td>0.582819</td>\n",
       "      <td>0.635798</td>\n",
       "      <td>700.9430</td>\n",
       "      <td>1.054540</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>205.326</td>\n",
       "      <td>-1.533530</td>\n",
       "      <td>497.944</td>\n",
       "      <td>615.805</td>\n",
       "      <td>-0.541517</td>\n",
       "      <td>710.542</td>\n",
       "      <td>56.1178</td>\n",
       "      <td>1261.750</td>\n",
       "      <td>3.530520</td>\n",
       "      <td>2.27416</td>\n",
       "      <td>866.484</td>\n",
       "      <td>0.310466</td>\n",
       "      <td>0.331616</td>\n",
       "      <td>0.188172</td>\n",
       "      <td>0.403781</td>\n",
       "      <td>810.3350</td>\n",
       "      <td>0.847888</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>981.706</td>\n",
       "      <td>0.028503</td>\n",
       "      <td>982.105</td>\n",
       "      <td>422.185</td>\n",
       "      <td>-0.683478</td>\n",
       "      <td>527.591</td>\n",
       "      <td>55.2165</td>\n",
       "      <td>450.912</td>\n",
       "      <td>0.978519</td>\n",
       "      <td>2.71260</td>\n",
       "      <td>708.310</td>\n",
       "      <td>0.277913</td>\n",
       "      <td>0.383677</td>\n",
       "      <td>0.222872</td>\n",
       "      <td>0.272324</td>\n",
       "      <td>59.4255</td>\n",
       "      <td>0.239011</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141.859</td>\n",
       "      <td>-0.879749</td>\n",
       "      <td>200.389</td>\n",
       "      <td>982.502</td>\n",
       "      <td>-1.092660</td>\n",
       "      <td>1631.620</td>\n",
       "      <td>78.4649</td>\n",
       "      <td>1520.520</td>\n",
       "      <td>0.724737</td>\n",
       "      <td>2.23595</td>\n",
       "      <td>1367.480</td>\n",
       "      <td>0.216641</td>\n",
       "      <td>0.222069</td>\n",
       "      <td>0.482801</td>\n",
       "      <td>0.555252</td>\n",
       "      <td>202.8420</td>\n",
       "      <td>3.400040</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1572.220</td>\n",
       "      <td>0.736638</td>\n",
       "      <td>2018.430</td>\n",
       "      <td>694.004</td>\n",
       "      <td>-0.089478</td>\n",
       "      <td>699.541</td>\n",
       "      <td>62.0402</td>\n",
       "      <td>664.824</td>\n",
       "      <td>1.717360</td>\n",
       "      <td>1.09507</td>\n",
       "      <td>2080.970</td>\n",
       "      <td>0.526070</td>\n",
       "      <td>0.655751</td>\n",
       "      <td>0.709811</td>\n",
       "      <td>0.722818</td>\n",
       "      <td>717.7320</td>\n",
       "      <td>2.472730</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ptl      etal   energyl       ptj      etaj   energyj    massj  \\\n",
       "0   562.212 -1.020360   881.172  1204.370 -1.184170  2154.110  90.8672   \n",
       "1   205.326 -1.533530   497.944   615.805 -0.541517   710.542  56.1178   \n",
       "2   981.706  0.028503   982.105   422.185 -0.683478   527.591  55.2165   \n",
       "3   141.859 -0.879749   200.389   982.502 -1.092660  1631.620  78.4649   \n",
       "4  1572.220  0.736638  2018.430   694.004 -0.089478   699.541  62.0402   \n",
       "\n",
       "        mjj       rjj      rjl       met     n21_1     n21_2     n32_1  \\\n",
       "0  2064.210  0.951219  2.76494  2582.970  0.144000  0.270936  0.582819   \n",
       "1  1261.750  3.530520  2.27416   866.484  0.310466  0.331616  0.188172   \n",
       "2   450.912  0.978519  2.71260   708.310  0.277913  0.383677  0.222872   \n",
       "3  1520.520  0.724737  2.23595  1367.480  0.216641  0.222069  0.482801   \n",
       "4   664.824  1.717360  1.09507  2080.970  0.526070  0.655751  0.709811   \n",
       "\n",
       "      n32_2      infl      drfl  type  tag  \n",
       "0  0.635798  700.9430  1.054540     4    1  \n",
       "1  0.403781  810.3350  0.847888     4    1  \n",
       "2  0.272324   59.4255  0.239011     4    1  \n",
       "3  0.555252  202.8420  3.400040     4    1  \n",
       "4  0.722818  717.7320  2.472730     4    1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[-1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtset = pd.concat(df,ignore_index=True)\n",
    "dtset = shuffle(dtset)\n",
    "dtset['met'] = np.fabs(dtset['met'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analysis Level Cuts\n",
    "dtset = dtset[dtset['ptl'] >= 120.0][dtset['ptj'] >= 120.0][dtset['etaj'] <= 2.0][dtset['etaj'] >= -2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes :  (9338860, 17) (9338860, 5) (2334716, 17) (2334716, 5)\n"
     ]
    }
   ],
   "source": [
    "train_len = int(0.8*len(dtset))\n",
    "x_train = dtset.T[:-2].T[:train_len]\n",
    "y_train = get_res(dtset['type'][:train_len].values)\n",
    "\n",
    "x_test = dtset.T[:-2].T[train_len:]\n",
    "y_test = get_res(dtset['type'][train_len:].values)\n",
    "\n",
    "print('Shapes : ',x_train.shape,y_train.shape,x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "backup_callback = tf.keras.callbacks.experimental.BackupAndRestore(backup_dir=\"/home2/kalp_shah/tmp/backup/mcc\")\n",
    "\n",
    "log_dir = \"/home2/kalp_shah/logs/mcc/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCEMultiLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "\n",
    "        y_pred_bce = tf.transpose(tf.transpose(y_pred)[-1])\n",
    "        y_true_bce = tf.transpose(tf.transpose(y_true)[-1])\n",
    "        \n",
    "        bce = tf.keras.losses.BinaryCrossentropy(from_logits=True,reduction = 'none')\n",
    "        return bce(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float64, numpy=array([0.99537605, 0.81586015, 0.82875335, 0.4198848 ])>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = BCEMultiLoss()\n",
    "s.call(np.array([[0,0,0,1],[0,0,0,1]]).T,np.array([[0.534,0.232,0.255,0.921],[0.534,0.232,0.255,0.421]]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sig_callback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        ns_t = logs['Ns']\n",
    "        nb_t = logs['Nb']\n",
    "        \n",
    "        s_train = (ns_t/np.sqrt(nb_t))*(10/8)*(10/6)\n",
    "        \n",
    "        ns_v = logs['val_Ns']\n",
    "        nb_v = logs['val_Nb']\n",
    "        \n",
    "        s_val = ns_v/np.sqrt(nb_v)*(10/8)*(10/6)\n",
    "        print()\n",
    "        print('The training significance is : ',s_train)\n",
    "        print('The validation significance is : ',s_val)\n",
    "        print('The luminosity required for 5 sigma (training) : ',np.square(5/s_train))\n",
    "        print('The luminosity required for 5 sigma (validation) : ',np.square(5/s_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NSignal(tf.keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self,cross_section,tot_events,name='Ns',**kwargs):\n",
    "        super(NSignal, self).__init__(name=name, **kwargs)\n",
    "        self.ns = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.cs = cross_section\n",
    "        self.te = tot_events\n",
    "        \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.cast(tf.argmax(y_true,axis=1),self.dtype)\n",
    "        y_pred = tf.cast(tf.argmax(y_pred,axis=1),self.dtype)\n",
    "        \n",
    "        total = tf.equal(y_true, tf.cast(4,self.dtype))\n",
    "        total = tf.cast(total, tf.bool)\n",
    "        \n",
    "        prediction = tf.equal(y_pred, tf.cast(4,self.dtype))\n",
    "        prediction = tf.cast(prediction, tf.bool)\n",
    "        \n",
    "        signal = tf.logical_and(prediction,total)\n",
    "        signal = tf.cast(signal,self.dtype)\n",
    "        #signal = tf.multiply(signal,self.cs[-1])\n",
    "        self.ns.assign_add((tf.reduce_sum(signal)*self.cs[-1])/self.te[-1])\n",
    "\n",
    "    def result(self):\n",
    "        return self.ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBack(tf.keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self,cross_section,tot_events,name='Nb',**kwargs):\n",
    "        super(NBack, self).__init__(name=name, **kwargs)\n",
    "        self.nb = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.cs = cross_section\n",
    "        self.te = tot_events\n",
    "        \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.cast(tf.argmax(y_true,axis=1),self.dtype)\n",
    "        y_pred = tf.cast(tf.argmax(y_pred,axis=1),self.dtype)\n",
    "        \n",
    "        comp_back = tf.cast(0,self.dtype)\n",
    "        for i in range(len(self.cs) - 1):\n",
    "            total = tf.equal(y_true, tf.cast(i,self.dtype))\n",
    "            total = tf.cast(total, tf.bool)\n",
    "        \n",
    "            prediction = tf.equal(y_pred, tf.cast(4,self.dtype))\n",
    "            prediction = tf.cast(prediction, tf.bool)\n",
    "        \n",
    "            back = tf.logical_and(prediction,total)\n",
    "            back = tf.cast(back,self.dtype)\n",
    "            #back = tf.multiply(back,self.cs[i])\n",
    "        \n",
    "            comp_back += (tf.reduce_sum(back)*self.cs[i])/self.te[i]\n",
    "\n",
    "        self.nb.assign_add(tf.cast(comp_back,self.dtype))\n",
    "\n",
    "    def result(self):\n",
    "        return self.nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "input_shape = x_train.shape\n",
    "\n",
    "from keras.layers.normalization.batch_normalization import BatchNormalization\n",
    "model.add(Dense(10,activation = 'relu',input_dim = input_shape[1]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(25,activation = 'relu',input_dim = 10))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(40,activation = 'relu',input_dim = 25))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(20,activation = 'relu',input_dim = 40))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(12,activation = 'relu',input_dim = 20))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(8,activation = 'relu',input_dim = 12))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(5,activation = 'softmax',input_dim = 8))\n",
    "\n",
    "model.compile(optimizer='adam', loss=BCEMultiLoss(),metrics=['accuracy',NSignal(cs_list,total_events),NBack(cs_list,total_events)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5474/5476 [============================>.] - ETA: 0s - loss: 1.2258 - accuracy: 0.5385 - Ns: 0.1516 - Nb: 530.8671\n",
      "The training significance is :  0.01370731079908584\n",
      "The validation significance is :  0.013060163992278287\n",
      "The luminosity required for 5 sigma (training) :  133056.3141019586\n",
      "The luminosity required for 5 sigma (validation) :  146569.21037094007\n",
      "5476/5476 [==============================] - 35s 6ms/step - loss: 1.2258 - accuracy: 0.5385 - Ns: 0.1516 - Nb: 531.0181 - val_loss: 0.3303 - val_accuracy: 0.5562 - val_Ns: 0.1010 - val_Nb: 259.3202\n",
      "Epoch 2/200\n",
      "5476/5476 [==============================] - ETA: 0s - loss: 1.1378 - accuracy: 0.5702 - Ns: 0.1520 - Nb: 417.6407\n",
      "The training significance is :  0.01549526449355876\n",
      "The validation significance is :  0.013286544151867216\n",
      "The luminosity required for 5 sigma (training) :  104121.88483084088\n",
      "The luminosity required for 5 sigma (validation) :  141617.17885074217\n",
      "5476/5476 [==============================] - 32s 6ms/step - loss: 1.1378 - accuracy: 0.5702 - Ns: 0.1520 - Nb: 417.6407 - val_loss: 0.3230 - val_accuracy: 0.5689 - val_Ns: 0.1011 - val_Nb: 251.3343\n",
      "Epoch 3/200\n",
      "5465/5476 [============================>.] - ETA: 0s - loss: 1.1292 - accuracy: 0.5749 - Ns: 0.1518 - Nb: 403.5012\n",
      "The training significance is :  0.01575987361947752\n",
      "The validation significance is :  0.014273003154356582\n",
      "The luminosity required for 5 sigma (training) :  100654.81330948214\n",
      "The luminosity required for 5 sigma (validation) :  122718.28720067505\n",
      "5476/5476 [==============================] - 32s 6ms/step - loss: 1.1292 - accuracy: 0.5749 - Ns: 0.1521 - Nb: 404.0177 - val_loss: 0.3238 - val_accuracy: 0.5677 - val_Ns: 0.1007 - val_Nb: 216.0789\n",
      "Epoch 4/200\n",
      "5473/5476 [============================>.] - ETA: 0s - loss: 1.1255 - accuracy: 0.5769 - Ns: 0.1520 - Nb: 396.7068\n",
      "The training significance is :  0.015904820925311917\n",
      "The validation significance is :  0.013089725893985795\n",
      "The luminosity required for 5 sigma (training) :  98828.55405095113\n",
      "The luminosity required for 5 sigma (validation) :  145907.9326720832\n",
      "5476/5476 [==============================] - 32s 6ms/step - loss: 1.1254 - accuracy: 0.5769 - Ns: 0.1521 - Nb: 396.9352 - val_loss: 0.3198 - val_accuracy: 0.5768 - val_Ns: 0.1014 - val_Nb: 260.4232\n",
      "Epoch 5/200\n",
      "5474/5476 [============================>.] - ETA: 0s - loss: 1.1225 - accuracy: 0.5786 - Ns: 0.1522 - Nb: 392.8562\n",
      "The training significance is :  0.015994893376705205\n",
      "The validation significance is :  0.013772259544426981\n",
      "The luminosity required for 5 sigma (training) :  97718.61656629306\n",
      "The luminosity required for 5 sigma (validation) :  131804.30987437902\n",
      "5476/5476 [==============================] - 32s 6ms/step - loss: 1.1225 - accuracy: 0.5786 - Ns: 0.1522 - Nb: 393.0595 - val_loss: 0.3189 - val_accuracy: 0.5791 - val_Ns: 0.1011 - val_Nb: 233.9615\n",
      "Epoch 6/200\n",
      "5469/5476 [============================>.] - ETA: 0s - loss: 1.1199 - accuracy: 0.5801 - Ns: 0.1521 - Nb: 390.0214\n",
      "The training significance is :  0.01605854727572957\n",
      "The validation significance is :  0.012407595336911928\n",
      "The luminosity required for 5 sigma (training) :  96945.46531058363\n",
      "The luminosity required for 5 sigma (validation) :  162392.05097382574\n",
      "5476/5476 [==============================] - 32s 6ms/step - loss: 1.1199 - accuracy: 0.5801 - Ns: 0.1523 - Nb: 390.2875 - val_loss: 0.3187 - val_accuracy: 0.5795 - val_Ns: 0.1016 - val_Nb: 290.7563\n",
      "Epoch 7/200\n",
      "5471/5476 [============================>.] - ETA: 0s - loss: 1.1173 - accuracy: 0.5815 - Ns: 0.1521 - Nb: 386.1257\n",
      "The training significance is :  0.01613578412701139\n",
      "The validation significance is :  0.014116762233795254\n",
      "The luminosity required for 5 sigma (training) :  96019.59252217333\n",
      "The luminosity required for 5 sigma (validation) :  125449.75243809597\n",
      "5476/5476 [==============================] - 32s 6ms/step - loss: 1.1173 - accuracy: 0.5815 - Ns: 0.1523 - Nb: 386.5326 - val_loss: 0.3173 - val_accuracy: 0.5815 - val_Ns: 0.1011 - val_Nb: 222.4850\n",
      "Epoch 8/200\n",
      "5475/5476 [============================>.] - ETA: 0s - loss: 1.1155 - accuracy: 0.5824 - Ns: 0.1522 - Nb: 387.0905\n",
      "The training significance is :  0.01612252801054222\n",
      "The validation significance is :  0.013563962795865216\n",
      "The luminosity required for 5 sigma (training) :  96177.55412412448\n",
      "The luminosity required for 5 sigma (validation) :  135883.5326210054\n",
      "5476/5476 [==============================] - 33s 6ms/step - loss: 1.1155 - accuracy: 0.5824 - Ns: 0.1523 - Nb: 387.1469 - val_loss: 0.3173 - val_accuracy: 0.5825 - val_Ns: 0.1011 - val_Nb: 240.9227\n",
      "Epoch 9/200\n",
      "5473/5476 [============================>.] - ETA: 0s - loss: 1.1141 - accuracy: 0.5830 - Ns: 0.1522 - Nb: 385.2913\n",
      "The training significance is :  0.016160267144706208\n",
      "The validation significance is :  0.014300354112790981\n",
      "The luminosity required for 5 sigma (training) :  95728.87101641642\n",
      "The luminosity required for 5 sigma (validation) :  122249.31238387017\n",
      "5476/5476 [==============================] - 35s 6ms/step - loss: 1.1141 - accuracy: 0.5830 - Ns: 0.1523 - Nb: 385.4500 - val_loss: 0.3166 - val_accuracy: 0.5836 - val_Ns: 0.1009 - val_Nb: 216.2482\n",
      "Epoch 10/200\n",
      "5475/5476 [============================>.] - ETA: 0s - loss: 1.1132 - accuracy: 0.5835 - Ns: 0.1523 - Nb: 381.6318\n",
      "The training significance is :  0.01623816535983094\n",
      "The validation significance is :  0.012720268496527815\n",
      "The luminosity required for 5 sigma (training) :  94812.60722781447\n",
      "The luminosity required for 5 sigma (validation) :  154506.7480428487\n",
      "5476/5476 [==============================] - 32s 6ms/step - loss: 1.1132 - accuracy: 0.5835 - Ns: 0.1523 - Nb: 381.7299 - val_loss: 0.3167 - val_accuracy: 0.5831 - val_Ns: 0.1020 - val_Nb: 278.9079\n",
      "Epoch 11/200\n",
      "5469/5476 [============================>.] - ETA: 0s - loss: 1.1124 - accuracy: 0.5837 - Ns: 0.1521 - Nb: 382.0740\n",
      "The training significance is :  0.01621939743255691\n",
      "The validation significance is :  0.013924378420615769\n",
      "The luminosity required for 5 sigma (training) :  95032.15491972507\n",
      "The luminosity required for 5 sigma (validation) :  128940.21012714639\n",
      "5476/5476 [==============================] - 32s 6ms/step - loss: 1.1124 - accuracy: 0.5837 - Ns: 0.1523 - Nb: 382.5521 - val_loss: 0.3160 - val_accuracy: 0.5846 - val_Ns: 0.1012 - val_Nb: 229.4550\n",
      "Epoch 12/200\n",
      "5471/5476 [============================>.] - ETA: 0s - loss: 1.1117 - accuracy: 0.5840 - Ns: 0.1521 - Nb: 378.9575\n",
      "The training significance is :  0.01628839765564117\n",
      "The validation significance is :  0.013962767104339913\n",
      "The luminosity required for 5 sigma (training) :  94228.71786269094\n",
      "The luminosity required for 5 sigma (validation) :  128232.17848065808\n",
      "5476/5476 [==============================] - 32s 6ms/step - loss: 1.1117 - accuracy: 0.5840 - Ns: 0.1523 - Nb: 379.2821 - val_loss: 0.3165 - val_accuracy: 0.5836 - val_Ns: 0.1011 - val_Nb: 227.4307\n",
      "Epoch 13/200\n",
      "5475/5476 [============================>.] - ETA: 0s - loss: 1.1109 - accuracy: 0.5844 - Ns: 0.1522 - Nb: 378.8788\n",
      "The training significance is :  0.016292472703356115\n",
      "The validation significance is :  0.013843991550572088\n",
      "The luminosity required for 5 sigma (training) :  94181.58707937205\n",
      "The luminosity required for 5 sigma (validation) :  130441.97253462038\n",
      "5476/5476 [==============================] - 32s 6ms/step - loss: 1.1110 - accuracy: 0.5844 - Ns: 0.1522 - Nb: 378.9327 - val_loss: 0.3164 - val_accuracy: 0.5841 - val_Ns: 0.1010 - val_Nb: 230.8716\n",
      "Epoch 14/200\n",
      "5468/5476 [============================>.] - ETA: 0s - loss: 1.1107 - accuracy: 0.5845 - Ns: 0.1520 - Nb: 378.5028\n",
      "The training significance is :  0.016292550582491228\n",
      "The validation significance is :  0.01336151584941212\n",
      "The luminosity required for 5 sigma (training) :  94180.68669695767\n",
      "The luminosity required for 5 sigma (validation) :  140032.40455609147\n",
      "5476/5476 [==============================] - 32s 6ms/step - loss: 1.1106 - accuracy: 0.5845 - Ns: 0.1522 - Nb: 378.9192 - val_loss: 0.3179 - val_accuracy: 0.5784 - val_Ns: 0.1016 - val_Nb: 250.8991\n",
      "Epoch 15/200\n",
      "5476/5476 [==============================] - ETA: 0s - loss: 1.1103 - accuracy: 0.5846 - Ns: 0.1522 - Nb: 378.1603\n",
      "The training significance is :  0.016308558693048605\n",
      "The validation significance is :  0.013432373950446094\n",
      "The luminosity required for 5 sigma (training) :  93995.88619637246\n",
      "The luminosity required for 5 sigma (validation) :  138558.91088524347\n",
      "5476/5476 [==============================] - 32s 6ms/step - loss: 1.1103 - accuracy: 0.5846 - Ns: 0.1522 - Nb: 378.1603 - val_loss: 0.3156 - val_accuracy: 0.5845 - val_Ns: 0.1014 - val_Nb: 247.4321\n",
      "Epoch 16/200\n",
      "5467/5476 [============================>.] - ETA: 0s - loss: 1.1098 - accuracy: 0.5849 - Ns: 0.1520 - Nb: 374.0889\n",
      "The training significance is :  0.016384185733126035\n",
      "The validation significance is :  0.015092749605299365\n",
      "The luminosity required for 5 sigma (training) :  93130.14595627684\n",
      "The luminosity required for 5 sigma (validation) :  109749.68304885506\n",
      "5476/5476 [==============================] - 32s 6ms/step - loss: 1.1098 - accuracy: 0.5849 - Ns: 0.1522 - Nb: 374.6623 - val_loss: 0.3171 - val_accuracy: 0.5828 - val_Ns: 0.1006 - val_Nb: 192.8679\n",
      "Epoch 17/200\n",
      "5474/5476 [============================>.] - ETA: 0s - loss: 1.1095 - accuracy: 0.5849 - Ns: 0.1522 - Nb: 377.8195\n",
      "The training significance is :  0.016314824337322044\n",
      "The validation significance is :  0.014346661914367238\n",
      "The luminosity required for 5 sigma (training) :  93923.7025573787\n",
      "The luminosity required for 5 sigma (validation) :  121461.399410114\n",
      "5476/5476 [==============================] - 33s 6ms/step - loss: 1.1095 - accuracy: 0.5849 - Ns: 0.1522 - Nb: 377.9519 - val_loss: 0.3153 - val_accuracy: 0.5855 - val_Ns: 0.1010 - val_Nb: 215.2581\n",
      "Epoch 18/200\n",
      "5467/5476 [============================>.] - ETA: 0s - loss: 1.1092 - accuracy: 0.5852 - Ns: 0.1520 - Nb: 377.1679\n",
      "The training significance is :  0.016320115954006485\n",
      "The validation significance is :  0.01481819018058867\n",
      "The luminosity required for 5 sigma (training) :  93862.80499289904\n",
      "The luminosity required for 5 sigma (validation) :  113854.36357337316\n",
      "5476/5476 [==============================] - 33s 6ms/step - loss: 1.1092 - accuracy: 0.5852 - Ns: 0.1522 - Nb: 377.7079 - val_loss: 0.3177 - val_accuracy: 0.5814 - val_Ns: 0.1002 - val_Nb: 198.5565\n",
      "Epoch 19/200\n",
      "1705/5476 [========>.....................] - ETA: 20s - loss: 1.1098 - accuracy: 0.5852 - Ns: 0.0474 - Nb: 118.3581"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#try:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m              \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m.01\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mbackup_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtensorboard_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43msig_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/apps/miniconda3/envs/tfml/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/apps/miniconda3/envs/tfml/lib/python3.10/site-packages/keras/engine/training.py:1216\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1211\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1212\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1213\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1214\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1215\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1216\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1217\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1218\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/apps/miniconda3/envs/tfml/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/apps/miniconda3/envs/tfml/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    907\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 910\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    912\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    913\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/apps/miniconda3/envs/tfml/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:942\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    939\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    940\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    941\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 942\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/apps/miniconda3/envs/tfml/lib/python3.10/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3127\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   3128\u001b[0m   (graph_function,\n\u001b[1;32m   3129\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/apps/miniconda3/envs/tfml/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1959\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1955\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1957\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1958\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1961\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m     args,\n\u001b[1;32m   1963\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1964\u001b[0m     executing_eagerly)\n\u001b[1;32m   1965\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/apps/miniconda3/envs/tfml/lib/python3.10/site-packages/tensorflow/python/eager/function.py:598\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    605\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    607\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    610\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    611\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/apps/miniconda3/envs/tfml/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 58\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#try:\n",
    "model.fit(x_train,y_train,epochs=200,batch_size=1024,validation_split=0.4,\n",
    "              class_weight={0:5,1:7,2:4,3:4,4:.01},\n",
    "          callbacks=[backup_callback,tensorboard_callback,sig_callback()])\n",
    "\n",
    "#except:\n",
    "#    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7b68e59e8748982a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7b68e59e8748982a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir /home2/kalp_shah/logs/mcc/ --port 8009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11419/11419 [==============================] - 19s 2ms/step - loss: 0.4988 - accuracy: 0.3961 - Ns: 0.0720 - Nb: 1.3723\n"
     ]
    }
   ],
   "source": [
    "tot_pred = model.evaluate(dtset.T[:-2].T,get_res(dtset['type'].values),batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07204782217741013, 1.3723348379135132)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_pred[2],tot_pred[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6296734167847253"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig = (tot_pred[2])/np.sqrt((tot_pred[3]))*np.sqrt(3483)\n",
    "sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pred = model.predict(dtset.T[:-2].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_back_ax(x):\n",
    "    return x.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = get_back_ax(total_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11692840,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 4, 4, 4, 3, 0, 3, 3, 0, 3, 0, 1, 1, 1, 3, 2, 3, 0, 3, 0, 0,\n",
       "       2, 3, 1, 3, 2, 3, 0, 3, 1, 3, 3, 4, 1, 1, 2, 1, 0, 4, 1, 3, 0, 1,\n",
       "       1, 0, 1, 0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol[2:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_set = dtset.copy()\n",
    "pred_set['pred'] = sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the test set is :  0.7845638869598831\n"
     ]
    }
   ],
   "source": [
    "cor_pred = len(pred_set[train_len:][pred_set['pred'] == 4][pred_set['tag'] == 1]) + len(pred_set[train_len:][pred_set['pred'] != 4][pred_set['tag'] == 0])\n",
    "print('The accuracy of the test set is : ',cor_pred/(len(pred_set[train_len:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly identified signal (True Positive)     :  704228\n",
      "Falsely identified signal (False Positive)      :  793\n",
      "Correctly identified background (True Negative) :  8472173\n",
      "Falsely identified background (False Negative)  :  2515646\n"
     ]
    }
   ],
   "source": [
    "print('Correctly identified signal (True Positive)     : ',len(pred_set[pred_set['pred'] == 4][pred_set['tag'] == 1]))\n",
    "print('Falsely identified signal (False Positive)      : ',len(pred_set[pred_set['pred'] == 4][pred_set['tag'] == 0]))\n",
    "print('Correctly identified background (True Negative) : ',len(pred_set[pred_set['pred'] != 4][pred_set['tag'] == 0]))\n",
    "print('Falsely identified background (False Negative)  : ',len(pred_set[pred_set['pred'] != 4][pred_set['tag'] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of signal left is     : 0.21166306695464362\n",
      "The amount of background left is : 7.861282174131266e-05\n"
     ]
    }
   ],
   "source": [
    "print('The amount of signal left is     :', len(pred_set[pred_set['pred'] == 4][pred_set['tag'] == 1])/len(df[-1]))\n",
    "print('The amount of background left is :', len(pred_set[pred_set['pred'] == 4][pred_set['tag'] == 0])/np.sum([len(i) for i in df[:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thus, the rate of correct signal prediction is :  0.9988752108093234\n"
     ]
    }
   ],
   "source": [
    "print('Thus, the rate of correct signal prediction is : ',len(pred_set[pred_set['pred'] == 4][dtset['tag'] == 1])/(len(pred_set[pred_set['pred'] == 4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n2n2 704228\n",
      "ttbar 21\n",
      "wmp 53\n",
      "wpwm 309\n",
      "zwpm 410\n"
     ]
    }
   ],
   "source": [
    "ns = cs_corr['n2n2']*(len(pred_set[pred_set['pred'] == 4][pred_set['tag'] == 1])/(no_of_files['n2n2']*red_merging['n2n2']))*L\n",
    "print('n2n2',(len(pred_set[pred_set['pred'] == 4][pred_set['tag'] == 1])))\n",
    "nb = 0\n",
    "\n",
    "for i in range(len(files)-1):\n",
    "    nb += cs_corr[files[i]]*(len(pred_set[pred_set['pred'] == 4][pred_set['type'] == i])/(no_of_files[files[f]]* red_merging[files[f]]))*L\n",
    "    print(files[i],(len(pred_set[pred_set['pred'] == 4][pred_set['type'] == i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of signal is : 216.14382461538463\n",
      "The number of background is : 4052.3852251302765\n",
      "The significance is : 3.3953728396215817\n"
     ]
    }
   ],
   "source": [
    "print('The number of signal is :', ns)\n",
    "print('The number of background is :', nb)\n",
    "print('The significance is :',ns/np.sqrt(nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home2/kalp_shah/Datasets/Models/s5/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('/home2/kalp_shah/datasets/Models/s5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
