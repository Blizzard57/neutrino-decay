{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import ImageFont\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import tensorflow as tf\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./logs/mcc\n",
    "!rm -rf /home2/kalp_shah/tmp/backup/mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['ttbar','wmp','wpwm','zwpm','n2n2']\n",
    "\n",
    "cs_lo_k = {\n",
    "            'ttbar':988.57,\n",
    "            'wmp'  :1.95*1e5,\n",
    "            'wpwm' :124.31,\n",
    "            'zwpm' :51.82,\n",
    "            'n2n2' :1\n",
    "          }\n",
    "\n",
    "br_ratio = {\n",
    "            'ttbar':0.67*(1-0.67)*2,\n",
    "            'wmp'  :(1-0.67),\n",
    "            'wpwm' :(1-0.67)*0.67*2,\n",
    "            'zwpm' :0.7*(1-0.67),\n",
    "            'n2n2' :1\n",
    "          }\n",
    "\n",
    "cs_nmg = {\n",
    "         'ttbar':393.30,\n",
    "         'wmp'  :7.865*1e4,\n",
    "         'wpwm' :74.96,\n",
    "         'zwpm' :14.28,\n",
    "         'n2n2' :1\n",
    "         }\n",
    "\n",
    "cs_mg = {'ttbar':5.883,\n",
    "          'wmp':111.5,\n",
    "          'wpwm':0.944,\n",
    "          'zwpm':0.2381,\n",
    "          'n2n2':3.99*1e-4\n",
    "        }\n",
    "\n",
    "cs_pb = []\n",
    "for f in files:\n",
    "    cs_pb.append((cs_lo_k[f]*br_ratio[f]*cs_mg[f])/cs_nmg[f])\n",
    "\n",
    "cs = [i*1e3 for i in cs_pb]\n",
    "#k_f = [1.954,1.356,1.92,2.09,1.0]\n",
    "\n",
    "cs_corr = {files[i] : cs[i] for i in range(len(files))}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cs_list = list(cs_corr.values())\n",
    "cs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_files = {'ttbar':0,\n",
    "              'wmp':0,\n",
    "              'wpwm':0,\n",
    "              'zwpm':0,\n",
    "              'n2n2':0\n",
    "              }\n",
    "\n",
    "red_merging = {'ttbar':98159/1e5,\n",
    "               'wmp':96494/1e5,\n",
    "               'wpwm':97633/1e5,\n",
    "               'zwpm':98988/1e5,\n",
    "               'n2n2':1\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_res(x):\n",
    "    res = np.zeros(shape=(x.shape[0],5))\n",
    "    #print(x.shape[0],5)\n",
    "    for i in range(len(x)):\n",
    "        #print(i.x[i])\n",
    "        res[i,x[i]] = 1\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for f in range(len(files)):\n",
    "    con_df = []\n",
    "    \n",
    "    for i in range(1,53):\n",
    "        try:\n",
    "            con_df.append(pd.read_csv('~/neutrino/datasets/csvdata/' + files[f] + str(i) + '.csv'))\n",
    "            no_of_files[files[f]] += 1\n",
    "        except:\n",
    "            pass\n",
    "            #print(\"Not Here : \",files[f],i)\n",
    "    \n",
    "    df.append(pd.concat(con_df,ignore_index=True))\n",
    "    df[-1]['type'] = f\n",
    "    \n",
    "    if files[f] == \"n2n2\":\n",
    "        df[-1]['tag'] = 1\n",
    "    else:\n",
    "        df[-1]['tag'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900000.0, 15656906.0)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_signal = no_of_files['n2n2']*1e5 * red_merging['n2n2']\n",
    "\n",
    "total_background = 0\n",
    "for f in range(len(files)-1):\n",
    "    total_background += no_of_files[files[f]]* 1e5 * red_merging[files[f]]\n",
    "    \n",
    "total_signal,total_background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ptl</th>\n",
       "      <th>etal</th>\n",
       "      <th>energyl</th>\n",
       "      <th>ptj</th>\n",
       "      <th>etaj</th>\n",
       "      <th>energyj</th>\n",
       "      <th>massj</th>\n",
       "      <th>mjj</th>\n",
       "      <th>rjj</th>\n",
       "      <th>rjl</th>\n",
       "      <th>met</th>\n",
       "      <th>n21_1</th>\n",
       "      <th>n21_2</th>\n",
       "      <th>n32_1</th>\n",
       "      <th>n32_2</th>\n",
       "      <th>infl</th>\n",
       "      <th>drfl</th>\n",
       "      <th>type</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>576.562</td>\n",
       "      <td>0.232894</td>\n",
       "      <td>592.269</td>\n",
       "      <td>459.681</td>\n",
       "      <td>0.248122</td>\n",
       "      <td>475.279</td>\n",
       "      <td>36.1316</td>\n",
       "      <td>379.243</td>\n",
       "      <td>1.14509</td>\n",
       "      <td>2.253050</td>\n",
       "      <td>889.067</td>\n",
       "      <td>0.190804</td>\n",
       "      <td>0.258472</td>\n",
       "      <td>0.517955</td>\n",
       "      <td>0.670891</td>\n",
       "      <td>769.506</td>\n",
       "      <td>1.86471</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>823.599</td>\n",
       "      <td>-0.418800</td>\n",
       "      <td>896.887</td>\n",
       "      <td>339.247</td>\n",
       "      <td>-0.696095</td>\n",
       "      <td>431.789</td>\n",
       "      <td>77.3122</td>\n",
       "      <td>1052.580</td>\n",
       "      <td>2.67178</td>\n",
       "      <td>2.072780</td>\n",
       "      <td>1930.330</td>\n",
       "      <td>0.197178</td>\n",
       "      <td>0.222316</td>\n",
       "      <td>0.468612</td>\n",
       "      <td>0.544453</td>\n",
       "      <td>1113.560</td>\n",
       "      <td>1.81712</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>354.758</td>\n",
       "      <td>-1.721930</td>\n",
       "      <td>1024.200</td>\n",
       "      <td>883.807</td>\n",
       "      <td>-0.817714</td>\n",
       "      <td>1200.200</td>\n",
       "      <td>98.7750</td>\n",
       "      <td>1764.850</td>\n",
       "      <td>2.82048</td>\n",
       "      <td>0.922735</td>\n",
       "      <td>3256.570</td>\n",
       "      <td>0.328865</td>\n",
       "      <td>0.361102</td>\n",
       "      <td>0.409280</td>\n",
       "      <td>0.760725</td>\n",
       "      <td>1015.050</td>\n",
       "      <td>2.09248</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>858.275</td>\n",
       "      <td>0.386685</td>\n",
       "      <td>923.245</td>\n",
       "      <td>1258.810</td>\n",
       "      <td>0.184948</td>\n",
       "      <td>1285.290</td>\n",
       "      <td>112.0150</td>\n",
       "      <td>1546.480</td>\n",
       "      <td>1.12283</td>\n",
       "      <td>2.551460</td>\n",
       "      <td>388.116</td>\n",
       "      <td>0.216487</td>\n",
       "      <td>0.234383</td>\n",
       "      <td>0.308864</td>\n",
       "      <td>0.722296</td>\n",
       "      <td>510.332</td>\n",
       "      <td>2.04593</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>590.040</td>\n",
       "      <td>-0.006999</td>\n",
       "      <td>590.055</td>\n",
       "      <td>811.602</td>\n",
       "      <td>0.445120</td>\n",
       "      <td>897.952</td>\n",
       "      <td>90.8938</td>\n",
       "      <td>818.864</td>\n",
       "      <td>1.16291</td>\n",
       "      <td>1.495500</td>\n",
       "      <td>1133.330</td>\n",
       "      <td>0.172456</td>\n",
       "      <td>0.329166</td>\n",
       "      <td>0.461283</td>\n",
       "      <td>0.696238</td>\n",
       "      <td>351.882</td>\n",
       "      <td>3.21196</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ptl      etal   energyl       ptj      etaj   energyj     massj  \\\n",
       "0  576.562  0.232894   592.269   459.681  0.248122   475.279   36.1316   \n",
       "1  823.599 -0.418800   896.887   339.247 -0.696095   431.789   77.3122   \n",
       "2  354.758 -1.721930  1024.200   883.807 -0.817714  1200.200   98.7750   \n",
       "3  858.275  0.386685   923.245  1258.810  0.184948  1285.290  112.0150   \n",
       "4  590.040 -0.006999   590.055   811.602  0.445120   897.952   90.8938   \n",
       "\n",
       "        mjj      rjj       rjl       met     n21_1     n21_2     n32_1  \\\n",
       "0   379.243  1.14509  2.253050   889.067  0.190804  0.258472  0.517955   \n",
       "1  1052.580  2.67178  2.072780  1930.330  0.197178  0.222316  0.468612   \n",
       "2  1764.850  2.82048  0.922735  3256.570  0.328865  0.361102  0.409280   \n",
       "3  1546.480  1.12283  2.551460   388.116  0.216487  0.234383  0.308864   \n",
       "4   818.864  1.16291  1.495500  1133.330  0.172456  0.329166  0.461283   \n",
       "\n",
       "      n32_2      infl     drfl  type  tag  \n",
       "0  0.670891   769.506  1.86471     4    1  \n",
       "1  0.544453  1113.560  1.81712     4    1  \n",
       "2  0.760725  1015.050  2.09248     4    1  \n",
       "3  0.722296   510.332  2.04593     4    1  \n",
       "4  0.696238   351.882  3.21196     4    1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[-1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtset = pd.concat(df,ignore_index=True)\n",
    "dtset = shuffle(dtset)\n",
    "dtset['met'] = np.fabs(dtset['met'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analysis Level Cuts\n",
    "dtset = dtset[dtset['ptl'] >= 120.0][dtset['ptj'] >= 120.0][dtset['etaj'] <= 2.0][dtset['etaj'] >= -2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes :  (9034704, 17) (9034704, 5) (2258676, 17) (2258676, 5)\n"
     ]
    }
   ],
   "source": [
    "train_len = int(0.8*len(dtset))\n",
    "x_train = dtset.T[:-2].T[:train_len]\n",
    "y_train = get_res(dtset['type'][:train_len].values)\n",
    "\n",
    "x_test = dtset.T[:-2].T[train_len:]\n",
    "y_test = get_res(dtset['type'][train_len:].values)\n",
    "\n",
    "print('Shapes : ',x_train.shape,y_train.shape,x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "backup_callback = tf.keras.callbacks.experimental.BackupAndRestore(backup_dir=\"/home2/kalp_shah/tmp/backup/mcc\")\n",
    "\n",
    "log_dir = \"/home2/kalp_shah/logs/mcc/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sig_callback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self,tot_sig,tot_back):\n",
    "        self.tot_sig = tot_sig\n",
    "        self.tot_back = tot_back\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        ns_t = logs['Ns']\n",
    "        nb_t = logs['Nb']\n",
    "        \n",
    "        s_train = (ns_t/(self.tot_sig*(0.8*0.6)))/np.sqrt((nb_t/(self.tot_back*(0.8*0.6))))\n",
    "        \n",
    "        ns_v = logs['val_Ns']\n",
    "        nb_v = logs['val_Nb']\n",
    "        \n",
    "        s_val = (ns_v/(self.tot_sig*(0.8*0.2)))/np.sqrt((nb_v/(self.tot_back*(0.8*0.2))))\n",
    "        print()\n",
    "        print('The training significance is : ',s_train)\n",
    "        print('The validation significance is : ',s_val)\n",
    "        print('The luminosity required for 5 sigma (training) : ',np.square(5/s_train))\n",
    "        print('The luminosity required for 5 sigma (validation) : ',np.square(5/s_val))\n",
    "        \n",
    "    #def on_test_end(self, epoch, logs=None):\n",
    "    #    ns_t = logs['Ns']\n",
    "    #    nb_t = logs['Nb']\n",
    "    #    \n",
    "    #    s_train = (ns_t/(self.tot_sig))/(nb_t/(self.tot_back))\n",
    "    #    print('The testing significance is : ',s_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NSignal(tf.keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self,cross_section,name='Ns',**kwargs):\n",
    "        super(NSignal, self).__init__(name=name, **kwargs)\n",
    "        self.ns = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.cs = cross_section\n",
    "        \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.cast(tf.argmax(y_true,axis=1),self.dtype)\n",
    "        y_pred = tf.cast(tf.argmax(y_pred,axis=1),self.dtype)\n",
    "        \n",
    "        total = tf.equal(y_true, tf.cast(4,self.dtype))\n",
    "        total = tf.cast(total, tf.bool)\n",
    "        \n",
    "        prediction = tf.equal(y_pred, tf.cast(4,self.dtype))\n",
    "        prediction = tf.cast(prediction, tf.bool)\n",
    "        \n",
    "        signal = tf.logical_and(prediction,total)\n",
    "        signal = tf.cast(signal,self.dtype)\n",
    "        #signal = tf.multiply(signal,self.cs[-1])\n",
    "        self.ns.assign_add(tf.reduce_sum(signal)*self.cs[-1])\n",
    "\n",
    "    def result(self):\n",
    "        return self.ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBack(tf.keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self,cross_section,name='Nb',**kwargs):\n",
    "        super(NBack, self).__init__(name=name, **kwargs)\n",
    "        self.nb = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.cs = cross_section\n",
    "        \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.cast(tf.argmax(y_true,axis=1),self.dtype)\n",
    "        y_pred = tf.cast(tf.argmax(y_pred,axis=1),self.dtype)\n",
    "        \n",
    "        comp_back = tf.cast(0,self.dtype)\n",
    "        for i in range(len(self.cs) - 1):\n",
    "            total = tf.equal(y_true, tf.cast(i,self.dtype))\n",
    "            total = tf.cast(total, tf.bool)\n",
    "        \n",
    "            prediction = tf.equal(y_pred, tf.cast(4,self.dtype))\n",
    "            prediction = tf.cast(prediction, tf.bool)\n",
    "        \n",
    "            back = tf.logical_and(prediction,total)\n",
    "            back = tf.cast(back,self.dtype)\n",
    "            #back = tf.multiply(back,self.cs[i])\n",
    "        \n",
    "            comp_back += tf.reduce_sum(back)*self.cs[i]\n",
    "\n",
    "        self.nb.assign_add(tf.cast(comp_back,self.dtype))\n",
    "\n",
    "    def result(self):\n",
    "        return self.nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "input_shape = x_train.shape\n",
    "\n",
    "from keras.layers.normalization.batch_normalization import BatchNormalization\n",
    "model.add(Dense(10,activation = 'relu',input_dim = input_shape[1]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(25,activation = 'relu',input_dim = 10))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(40,activation = 'relu',input_dim = 25))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(20,activation = 'relu',input_dim = 40))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(12,activation = 'relu',input_dim = 20))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(8,activation = 'relu',input_dim = 12))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(5,activation = 'softmax',input_dim = 8))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy',NSignal(cs_list),NBack(cs_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "5292/5294 [============================>.] - ETA: 0s - loss: 1.3202 - accuracy: 0.3823 - Ns: 91139.7500 - Nb: 809709.0000\n",
      "The training significance is :  0.14837258215778426\n",
      "The validation significance is :  0.21678679055542693\n",
      "The luminosity required for 5 sigma (training) :  1135.6191277584023\n",
      "The luminosity required for 5 sigma (validation) :  531.9543650913057\n",
      "5294/5294 [==============================] - 70s 13ms/step - loss: 1.3202 - accuracy: 0.3823 - Ns: 91169.6719 - Nb: 809709.0000 - val_loss: 0.5533 - val_accuracy: 0.3784 - val_Ns: 59544.2578 - val_Nb: 485367.7188\n",
      "Epoch 17/100\n",
      "5294/5294 [==============================] - ETA: 0s - loss: 1.3198 - accuracy: 0.3825 - Ns: 91522.5469 - Nb: 886461.0000\n",
      "The training significance is :  0.1423528042056954\n",
      "The validation significance is :  0.32902637066893425\n",
      "The luminosity required for 5 sigma (training) :  1233.6954278542687\n",
      "The luminosity required for 5 sigma (validation) :  230.92906367598655\n",
      "5294/5294 [==============================] - 39s 7ms/step - loss: 1.3198 - accuracy: 0.3825 - Ns: 91522.5469 - Nb: 886461.0000 - val_loss: 0.5572 - val_accuracy: 0.3817 - val_Ns: 59726.1562 - val_Nb: 211994.4375\n",
      "Epoch 18/100\n",
      "5290/5294 [============================>.] - ETA: 0s - loss: 1.3193 - accuracy: 0.3836 - Ns: 92903.8203 - Nb: 988324.6875\n",
      "The training significance is :  0.1369467304582601\n",
      "The validation significance is :  0.2143141957771106\n",
      "The luminosity required for 5 sigma (training) :  1333.0200215013429\n",
      "The luminosity required for 5 sigma (validation) :  544.2997451227556\n",
      "5294/5294 [==============================] - 36s 7ms/step - loss: 1.3193 - accuracy: 0.3836 - Ns: 92968.0547 - Nb: 988324.6875 - val_loss: 0.5575 - val_accuracy: 0.3740 - val_Ns: 58973.1836 - val_Nb: 487151.4688\n",
      "Epoch 19/100\n",
      "5291/5294 [============================>.] - ETA: 0s - loss: 1.3190 - accuracy: 0.3830 - Ns: 91729.1016 - Nb: 905409.2500\n",
      "The training significance is :  0.14124509432744534\n",
      "The validation significance is :  0.3367542991150472\n",
      "The luminosity required for 5 sigma (training) :  1253.1217347878223\n",
      "The luminosity required for 5 sigma (validation) :  220.45183142536777\n",
      "5294/5294 [==============================] - 34s 6ms/step - loss: 1.3190 - accuracy: 0.3830 - Ns: 91775.7812 - Nb: 905409.2500 - val_loss: 0.5470 - val_accuracy: 0.3830 - val_Ns: 60063.6523 - val_Nb: 204669.8750\n",
      "Epoch 20/100\n",
      "5289/5294 [============================>.] - ETA: 0s - loss: 1.3186 - accuracy: 0.3833 - Ns: 91964.0469 - Nb: 1002761.9375\n",
      "The training significance is :  0.13461506055273142\n",
      "The validation significance is :  0.18629148402016635\n",
      "The luminosity required for 5 sigma (training) :  1379.5984790038017\n",
      "The luminosity required for 5 sigma (validation) :  720.3673224070337\n",
      "5294/5294 [==============================] - 34s 6ms/step - loss: 1.3186 - accuracy: 0.3833 - Ns: 92050.2188 - Nb: 1002761.9375 - val_loss: 0.5460 - val_accuracy: 0.3881 - val_Ns: 64607.3984 - val_Nb: 773811.6250\n",
      "Epoch 21/100\n",
      "5294/5294 [==============================] - ETA: 0s - loss: 1.3179 - accuracy: 0.3832 - Ns: 90998.6172 - Nb: 1076745.2500\n",
      "The training significance is :  0.12842395985863894\n",
      "The validation significance is :  0.22684680365126964\n",
      "The luminosity required for 5 sigma (training) :  1515.820913998266\n",
      "The luminosity required for 5 sigma (validation) :  485.8192062529404\n",
      "5294/5294 [==============================] - 33s 6ms/step - loss: 1.3179 - accuracy: 0.3832 - Ns: 90998.6172 - Nb: 1076745.2500 - val_loss: 0.5651 - val_accuracy: 0.3741 - val_Ns: 48246.9961 - val_Nb: 291026.1250\n",
      "Epoch 22/100\n",
      "5290/5294 [============================>.] - ETA: 0s - loss: 1.3164 - accuracy: 0.3829 - Ns: 88977.6406 - Nb: 1096947.5000\n",
      "The training significance is :  0.12449827373388983\n",
      "The validation significance is :  0.20091841587624665\n",
      "The luminosity required for 5 sigma (training) :  1612.9219395804375\n",
      "The luminosity required for 5 sigma (validation) :  619.2991985572304\n",
      "5294/5294 [==============================] - 33s 6ms/step - loss: 1.3164 - accuracy: 0.3829 - Ns: 89040.6875 - Nb: 1096947.5000 - val_loss: 0.5550 - val_accuracy: 0.3801 - val_Ns: 60812.4531 - val_Nb: 589389.3750\n",
      "Epoch 23/100\n",
      "5096/5294 [===========================>..] - ETA: 0s - loss: 1.3152 - accuracy: 0.3845 - Ns: 87912.0703 - Nb: 811881.7500"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model.fit(x_train,y_train,epochs=100,batch_size=1024,validation_split=0.4,\n",
    "              class_weight={0:5,1:7,2:4,3:4,4:.005},\n",
    "          callbacks=[backup_callback,tensorboard_callback,sig_callback(total_signal,total_background)])\n",
    "\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5b49e491305f3822\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5b49e491305f3822\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir /home2/kalp_shah/logs/mcc/ --port 8009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11029/11029 [==============================] - 18s 2ms/step - loss: 0.5545 - accuracy: 0.3785 - Ns: 175067.3125 - Nb: 2298663.0000\n"
     ]
    }
   ],
   "source": [
    "tot_pred = model.evaluate(dtset.T[:-2].T,get_res(dtset['type'].values),batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175067.3125, 2298663.0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_pred[2],tot_pred[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.343210853052492"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig = ((tot_pred[2]/total_signal)/np.sqrt((tot_pred[3]/total_background)))*np.sqrt(3000)\n",
    "sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pred = model.predict(dtset.T[:-2].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_back_ax(x):\n",
    "    return x.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = get_back_ax(total_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11293380,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 1, 3, 1, 1, 3, 0, 0, 0, 0, 3, 4, 1, 1, 3, 1, 3, 3, 2, 3, 3,\n",
       "       1, 1, 3, 3, 0, 3, 1, 3, 1, 0, 4, 0, 1, 1, 0, 1, 1, 0, 3, 0, 1, 3,\n",
       "       3, 1, 3, 3])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol[2:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_set = dtset.copy()\n",
    "pred_set['pred'] = sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the test set is :  0.7539642693330075\n"
     ]
    }
   ],
   "source": [
    "cor_pred = len(pred_set[train_len:][pred_set['pred'] == 4][pred_set['tag'] == 1]) + len(pred_set[train_len:][pred_set['pred'] != 4][pred_set['tag'] == 0])\n",
    "print('The accuracy of the test set is : ',cor_pred/(len(pred_set[train_len:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly identified signal (True Positive)     :  438763\n",
      "Falsely identified signal (False Positive)      :  246\n",
      "Correctly identified background (True Negative) :  8073260\n",
      "Falsely identified background (False Negative)  :  2781111\n"
     ]
    }
   ],
   "source": [
    "print('Correctly identified signal (True Positive)     : ',len(pred_set[pred_set['pred'] == 4][pred_set['tag'] == 1]))\n",
    "print('Falsely identified signal (False Positive)      : ',len(pred_set[pred_set['pred'] == 4][pred_set['tag'] == 0]))\n",
    "print('Correctly identified background (True Negative) : ',len(pred_set[pred_set['pred'] != 4][pred_set['tag'] == 0]))\n",
    "print('Falsely identified background (False Negative)  : ',len(pred_set[pred_set['pred'] != 4][pred_set['tag'] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of signal left is     : 0.13187479374040836\n",
      "The amount of background left is : 2.5549843538366672e-05\n"
     ]
    }
   ],
   "source": [
    "print('The amount of signal left is     :', len(pred_set[pred_set['pred'] == 4][pred_set['tag'] == 1])/len(df[-1]))\n",
    "print('The amount of background left is :', len(pred_set[pred_set['pred'] == 4][pred_set['tag'] == 0])/np.sum([len(i) for i in df[:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thus, the rate of correct signal prediction is :  0.9994396470231818\n"
     ]
    }
   ],
   "source": [
    "print('Thus, the rate of correct signal prediction is : ',len(pred_set[pred_set['pred'] == 4][dtset['tag'] == 1])/(len(pred_set[pred_set['pred'] == 4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n2n2 438763\n",
      "ttbar 2\n",
      "wmp 24\n",
      "wpwm 106\n",
      "zwpm 114\n"
     ]
    }
   ],
   "source": [
    "ns = cs_corr['n2n2']*(len(pred_set[pred_set['pred'] == 4][pred_set['tag'] == 1])/(no_of_files['n2n2']*1e5 * red_merging['n2n2']))*L\n",
    "print('n2n2',(len(pred_set[pred_set['pred'] == 4][pred_set['tag'] == 1])))\n",
    "nb = 0\n",
    "\n",
    "for i in range(len(files)-1):\n",
    "    nb += cs_corr[files[i]]*(len(pred_set[pred_set['pred'] == 4][pred_set['type'] == i])/(no_of_files[files[f]]*1e5 * red_merging[files[f]]))*L\n",
    "    print(files[i],(len(pred_set[pred_set['pred'] == 4][pred_set['type'] == i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of signal is : 134.66649\n",
      "The number of background is : 1583.2944004373726\n",
      "The significance is : 3.3843767489553223\n"
     ]
    }
   ],
   "source": [
    "print('The number of signal is :', ns)\n",
    "print('The number of background is :', nb)\n",
    "print('The significance is :',ns/np.sqrt(nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home2/kalp_shah/Datasets/Models/s5/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('/home2/kalp_shah/datasets/Models/s5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
