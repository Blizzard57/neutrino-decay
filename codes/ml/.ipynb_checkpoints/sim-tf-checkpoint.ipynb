{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import ImageFont\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "mpl.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['ttbar','wmp','wpwm','zwpm','n2n2']\n",
    "\n",
    "cs_lo_k = {\n",
    "            'ttbar':988.57,\n",
    "            'wmp'  :1.95*1e5,\n",
    "            'wpwm' :124.31,\n",
    "            'zwpm' :51.82,\n",
    "            'n2n2' :1\n",
    "          }\n",
    "\n",
    "br_ratio = {\n",
    "            'ttbar':0.67*(1-0.67)*2,\n",
    "            'wmp'  :(1-0.67),\n",
    "            'wpwm' :(1-0.67)*0.67*2,\n",
    "            'zwpm' :0.7*(1-0.67),\n",
    "            'n2n2' :1\n",
    "          }\n",
    "\n",
    "cs_nmg = {\n",
    "         'ttbar':393.30,\n",
    "         'wmp'  :7.865*1e4,\n",
    "         'wpwm' :74.96,\n",
    "         'zwpm' :14.28,\n",
    "         'n2n2' :1\n",
    "         }\n",
    "\n",
    "cs_mg = {'ttbar':5.883,\n",
    "          'wmp':111.5,\n",
    "          'wpwm':0.944,\n",
    "          'zwpm':0.2381,\n",
    "          'n2n2':3.99*1e-4\n",
    "        }\n",
    "\n",
    "cs_pb = []\n",
    "for f in files:\n",
    "    cs_pb.append((cs_lo_k[f]*br_ratio[f]*cs_mg[f])/cs_nmg[f])\n",
    "\n",
    "cs = [i*1e3 for i in cs_pb]\n",
    "#k_f = [1.954,1.356,1.92,2.09,1.0]\n",
    "\n",
    "cs_corr = {files[i] : cs[i] for i in range(len(files))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_files = {'ttbar':0,\n",
    "          'wmp':0,\n",
    "          'wpwm':0,\n",
    "          'zwpm':0,\n",
    "          'n2n2':0\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for f in range(len(files)):\n",
    "    con_df = []\n",
    "    \n",
    "    for i in range(1,53):\n",
    "        try:\n",
    "            con_df.append(pd.read_csv('~/neutrino/datasets/csvdata/' + files[f] + str(i) + '.csv'))\n",
    "            no_of_files[files[f]] += 1\n",
    "        except:\n",
    "            pass\n",
    "            #print(\"Not Here : \",files[f],i)\n",
    "    \n",
    "    df.append(pd.concat(con_df,ignore_index=True))\n",
    "    df[-1]['type'] = f\n",
    "    \n",
    "    if files[f] == \"n2n2\":\n",
    "        df[-1]['tag'] = 1\n",
    "    else:\n",
    "        df[-1]['tag'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the process  ttbar  the number of events :  4100000.0\n",
      "For the process  wmp  the number of events :  4000000.0\n",
      "For the process  wpwm  the number of events :  2800000.0\n",
      "For the process  zwpm  the number of events :  4400000.0\n",
      "For the process  n2n2  the number of events :  3900000.0\n",
      "Number of Datapoints Considered :  19200000.0\n"
     ]
    }
   ],
   "source": [
    "tot_num = 0\n",
    "for i in no_of_files.keys():\n",
    "    tot_num += no_of_files[i]*1e5\n",
    "    print(\"For the process \",i,\" the number of events : \",no_of_files[i]*1e5)\n",
    "print('Number of Datapoints Considered : ',tot_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ptl</th>\n",
       "      <th>etal</th>\n",
       "      <th>energyl</th>\n",
       "      <th>ptj</th>\n",
       "      <th>etaj</th>\n",
       "      <th>energyj</th>\n",
       "      <th>massj</th>\n",
       "      <th>mjj</th>\n",
       "      <th>rjj</th>\n",
       "      <th>rjl</th>\n",
       "      <th>met</th>\n",
       "      <th>n21_1</th>\n",
       "      <th>n21_2</th>\n",
       "      <th>n32_1</th>\n",
       "      <th>n32_2</th>\n",
       "      <th>infl</th>\n",
       "      <th>drfl</th>\n",
       "      <th>type</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>576.562</td>\n",
       "      <td>0.232894</td>\n",
       "      <td>592.269</td>\n",
       "      <td>459.681</td>\n",
       "      <td>0.248122</td>\n",
       "      <td>475.279</td>\n",
       "      <td>36.1316</td>\n",
       "      <td>379.243</td>\n",
       "      <td>1.14509</td>\n",
       "      <td>2.253050</td>\n",
       "      <td>889.067</td>\n",
       "      <td>0.190804</td>\n",
       "      <td>0.258472</td>\n",
       "      <td>0.517955</td>\n",
       "      <td>0.670891</td>\n",
       "      <td>769.506</td>\n",
       "      <td>1.86471</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>823.599</td>\n",
       "      <td>-0.418800</td>\n",
       "      <td>896.887</td>\n",
       "      <td>339.247</td>\n",
       "      <td>-0.696095</td>\n",
       "      <td>431.789</td>\n",
       "      <td>77.3122</td>\n",
       "      <td>1052.580</td>\n",
       "      <td>2.67178</td>\n",
       "      <td>2.072780</td>\n",
       "      <td>1930.330</td>\n",
       "      <td>0.197178</td>\n",
       "      <td>0.222316</td>\n",
       "      <td>0.468612</td>\n",
       "      <td>0.544453</td>\n",
       "      <td>1113.560</td>\n",
       "      <td>1.81712</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>354.758</td>\n",
       "      <td>-1.721930</td>\n",
       "      <td>1024.200</td>\n",
       "      <td>883.807</td>\n",
       "      <td>-0.817714</td>\n",
       "      <td>1200.200</td>\n",
       "      <td>98.7750</td>\n",
       "      <td>1764.850</td>\n",
       "      <td>2.82048</td>\n",
       "      <td>0.922735</td>\n",
       "      <td>3256.570</td>\n",
       "      <td>0.328865</td>\n",
       "      <td>0.361102</td>\n",
       "      <td>0.409280</td>\n",
       "      <td>0.760725</td>\n",
       "      <td>1015.050</td>\n",
       "      <td>2.09248</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>858.275</td>\n",
       "      <td>0.386685</td>\n",
       "      <td>923.245</td>\n",
       "      <td>1258.810</td>\n",
       "      <td>0.184948</td>\n",
       "      <td>1285.290</td>\n",
       "      <td>112.0150</td>\n",
       "      <td>1546.480</td>\n",
       "      <td>1.12283</td>\n",
       "      <td>2.551460</td>\n",
       "      <td>388.116</td>\n",
       "      <td>0.216487</td>\n",
       "      <td>0.234383</td>\n",
       "      <td>0.308864</td>\n",
       "      <td>0.722296</td>\n",
       "      <td>510.332</td>\n",
       "      <td>2.04593</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>590.040</td>\n",
       "      <td>-0.006999</td>\n",
       "      <td>590.055</td>\n",
       "      <td>811.602</td>\n",
       "      <td>0.445120</td>\n",
       "      <td>897.952</td>\n",
       "      <td>90.8938</td>\n",
       "      <td>818.864</td>\n",
       "      <td>1.16291</td>\n",
       "      <td>1.495500</td>\n",
       "      <td>1133.330</td>\n",
       "      <td>0.172456</td>\n",
       "      <td>0.329166</td>\n",
       "      <td>0.461283</td>\n",
       "      <td>0.696238</td>\n",
       "      <td>351.882</td>\n",
       "      <td>3.21196</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ptl      etal   energyl       ptj      etaj   energyj     massj  \\\n",
       "0  576.562  0.232894   592.269   459.681  0.248122   475.279   36.1316   \n",
       "1  823.599 -0.418800   896.887   339.247 -0.696095   431.789   77.3122   \n",
       "2  354.758 -1.721930  1024.200   883.807 -0.817714  1200.200   98.7750   \n",
       "3  858.275  0.386685   923.245  1258.810  0.184948  1285.290  112.0150   \n",
       "4  590.040 -0.006999   590.055   811.602  0.445120   897.952   90.8938   \n",
       "\n",
       "        mjj      rjj       rjl       met     n21_1     n21_2     n32_1  \\\n",
       "0   379.243  1.14509  2.253050   889.067  0.190804  0.258472  0.517955   \n",
       "1  1052.580  2.67178  2.072780  1930.330  0.197178  0.222316  0.468612   \n",
       "2  1764.850  2.82048  0.922735  3256.570  0.328865  0.361102  0.409280   \n",
       "3  1546.480  1.12283  2.551460   388.116  0.216487  0.234383  0.308864   \n",
       "4   818.864  1.16291  1.495500  1133.330  0.172456  0.329166  0.461283   \n",
       "\n",
       "      n32_2      infl     drfl  type  tag  \n",
       "0  0.670891   769.506  1.86471     4    1  \n",
       "1  0.544453  1113.560  1.81712     4    1  \n",
       "2  0.760725  1015.050  2.09248     4    1  \n",
       "3  0.722296   510.332  2.04593     4    1  \n",
       "4  0.696238   351.882  3.21196     4    1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[-1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtset = pd.concat(df,ignore_index=True)\n",
    "dtset = shuffle(dtset)\n",
    "dtset['met'] = np.fabs(dtset['met'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analysis Level Cuts\n",
    "dtset = dtset[dtset['ptl'] >= 120.0][dtset['ptj'] >= 120.0][dtset['etaj'] <= 2.0][dtset['etaj'] >= -2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ptl</th>\n",
       "      <th>etal</th>\n",
       "      <th>energyl</th>\n",
       "      <th>ptj</th>\n",
       "      <th>etaj</th>\n",
       "      <th>energyj</th>\n",
       "      <th>massj</th>\n",
       "      <th>mjj</th>\n",
       "      <th>rjj</th>\n",
       "      <th>rjl</th>\n",
       "      <th>met</th>\n",
       "      <th>n21_1</th>\n",
       "      <th>n21_2</th>\n",
       "      <th>n32_1</th>\n",
       "      <th>n32_2</th>\n",
       "      <th>infl</th>\n",
       "      <th>drfl</th>\n",
       "      <th>type</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1811160</th>\n",
       "      <td>183.666</td>\n",
       "      <td>-0.748592</td>\n",
       "      <td>237.577</td>\n",
       "      <td>149.638</td>\n",
       "      <td>-0.402901</td>\n",
       "      <td>162.663</td>\n",
       "      <td>15.22190</td>\n",
       "      <td>71.2538</td>\n",
       "      <td>0.546117</td>\n",
       "      <td>2.671030</td>\n",
       "      <td>302.963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130607</td>\n",
       "      <td>0.320975</td>\n",
       "      <td>0.621579</td>\n",
       "      <td>122.897</td>\n",
       "      <td>1.478480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9306012</th>\n",
       "      <td>211.225</td>\n",
       "      <td>0.474553</td>\n",
       "      <td>235.459</td>\n",
       "      <td>135.461</td>\n",
       "      <td>0.845731</td>\n",
       "      <td>186.986</td>\n",
       "      <td>6.77865</td>\n",
       "      <td>151.4740</td>\n",
       "      <td>1.435020</td>\n",
       "      <td>2.357210</td>\n",
       "      <td>355.836</td>\n",
       "      <td>0.163345</td>\n",
       "      <td>0.522382</td>\n",
       "      <td>0.205986</td>\n",
       "      <td>0.406678</td>\n",
       "      <td>135.971</td>\n",
       "      <td>1.337320</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747213</th>\n",
       "      <td>127.973</td>\n",
       "      <td>-0.948038</td>\n",
       "      <td>189.921</td>\n",
       "      <td>155.331</td>\n",
       "      <td>0.424858</td>\n",
       "      <td>171.965</td>\n",
       "      <td>28.64430</td>\n",
       "      <td>1296.1600</td>\n",
       "      <td>1.628960</td>\n",
       "      <td>2.857250</td>\n",
       "      <td>3342.470</td>\n",
       "      <td>0.237205</td>\n",
       "      <td>0.300216</td>\n",
       "      <td>0.301006</td>\n",
       "      <td>0.494113</td>\n",
       "      <td>152.926</td>\n",
       "      <td>0.994628</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11269057</th>\n",
       "      <td>699.695</td>\n",
       "      <td>-0.729589</td>\n",
       "      <td>894.328</td>\n",
       "      <td>555.115</td>\n",
       "      <td>0.773183</td>\n",
       "      <td>735.074</td>\n",
       "      <td>90.55750</td>\n",
       "      <td>1022.8800</td>\n",
       "      <td>0.583295</td>\n",
       "      <td>2.343900</td>\n",
       "      <td>773.643</td>\n",
       "      <td>0.175866</td>\n",
       "      <td>0.285804</td>\n",
       "      <td>0.299557</td>\n",
       "      <td>0.562381</td>\n",
       "      <td>365.346</td>\n",
       "      <td>2.072490</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348840</th>\n",
       "      <td>242.668</td>\n",
       "      <td>0.273862</td>\n",
       "      <td>251.825</td>\n",
       "      <td>145.881</td>\n",
       "      <td>-0.261343</td>\n",
       "      <td>151.725</td>\n",
       "      <td>15.87990</td>\n",
       "      <td>90.7368</td>\n",
       "      <td>0.699160</td>\n",
       "      <td>0.576504</td>\n",
       "      <td>671.121</td>\n",
       "      <td>0.156544</td>\n",
       "      <td>0.230697</td>\n",
       "      <td>0.328301</td>\n",
       "      <td>0.332646</td>\n",
       "      <td>144.995</td>\n",
       "      <td>1.158270</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ptl      etal  energyl      ptj      etaj  energyj     massj  \\\n",
       "1811160   183.666 -0.748592  237.577  149.638 -0.402901  162.663  15.22190   \n",
       "9306012   211.225  0.474553  235.459  135.461  0.845731  186.986   6.77865   \n",
       "747213    127.973 -0.948038  189.921  155.331  0.424858  171.965  28.64430   \n",
       "11269057  699.695 -0.729589  894.328  555.115  0.773183  735.074  90.55750   \n",
       "1348840   242.668  0.273862  251.825  145.881 -0.261343  151.725  15.87990   \n",
       "\n",
       "                mjj       rjj       rjl       met     n21_1     n21_2  \\\n",
       "1811160     71.2538  0.546117  2.671030   302.963  0.000000  0.130607   \n",
       "9306012    151.4740  1.435020  2.357210   355.836  0.163345  0.522382   \n",
       "747213    1296.1600  1.628960  2.857250  3342.470  0.237205  0.300216   \n",
       "11269057  1022.8800  0.583295  2.343900   773.643  0.175866  0.285804   \n",
       "1348840     90.7368  0.699160  0.576504   671.121  0.156544  0.230697   \n",
       "\n",
       "             n32_1     n32_2     infl      drfl  type  tag  \n",
       "1811160   0.320975  0.621579  122.897  1.478480     0    0  \n",
       "9306012   0.205986  0.406678  135.971  1.337320     3    0  \n",
       "747213    0.301006  0.494113  152.926  0.994628     0    0  \n",
       "11269057  0.299557  0.562381  365.346  2.072490     4    1  \n",
       "1348840   0.328301  0.332646  144.995  1.158270     0    0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes :  (9034704, 17) (9034704,) (2258676, 17) (2258676,)\n"
     ]
    }
   ],
   "source": [
    "train_len = int(0.8*len(dtset))\n",
    "x_train = dtset.T[:-2].T[:train_len]\n",
    "y_train = dtset['tag'][:train_len]\n",
    "\n",
    "x_test = dtset.T[:-2].T[train_len:]\n",
    "y_test = dtset['tag'][train_len:]\n",
    "\n",
    "print('Shapes : ',x_train.shape,y_train.shape,x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.experimental.BackupAndRestore(backup_dir=\"/home2/kalp_shah/tmp/backup\")\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Significance(tf.keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name='significance', **kwargs):\n",
    "        super(Significance, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred,type_array,sample_weight=None):\n",
    "        tf.where(y_pred >= 0.7,1,y_pred)\n",
    "        tf.where(y_pred < 0.7,0,y_pred)\n",
    "        \n",
    "        y_true = tf.cast(y_true, tf.bool)\n",
    "        y_pred = tf.cast(y_pred, tf.bool)\n",
    "        \n",
    "        values = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))\n",
    "        values = tf.cast(values, self.dtype)\n",
    "        \n",
    "        ns = tf.multiply(values,type_array[1,])\n",
    "        \n",
    "        if sample_weight is not None:\n",
    "            sample_weight = tf.cast(sample_weight, self.dtype)\n",
    "            sample_weight = tf.broadcast_to(sample_weight, values.shape)\n",
    "            values = tf.multiply(values, sample_weight)\n",
    "        \n",
    "        self.true_positives.assign( tf.cast(len(y_pred), self.dtype))\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "input_shape = x_train.shape\n",
    "\n",
    "from keras.layers.normalization.batch_normalization import BatchNormalization\n",
    "model.add(Dense(10,activation = 'relu',input_dim = input_shape[1]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(25,activation = 'relu',input_dim = 10))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(40,activation = 'relu',input_dim = 25))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(20,activation = 'relu',input_dim = 40))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(12,activation = 'relu',input_dim = 20))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(8,activation = 'relu',input_dim = 12))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1,activation = 'sigmoid',input_dim = 8))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "14117/14117 [==============================] - 51s 4ms/step - loss: 0.0044 - accuracy: 0.8350 - val_loss: 0.4602 - val_accuracy: 0.8249\n",
      "Epoch 74/100\n",
      "14117/14117 [==============================] - 51s 4ms/step - loss: 0.0044 - accuracy: 0.8353 - val_loss: 0.4563 - val_accuracy: 0.8298\n",
      "Epoch 75/100\n",
      "14117/14117 [==============================] - 51s 4ms/step - loss: 0.0044 - accuracy: 0.8349 - val_loss: 0.4420 - val_accuracy: 0.8331\n",
      "Epoch 76/100\n",
      "14117/14117 [==============================] - 52s 4ms/step - loss: 0.0044 - accuracy: 0.8351 - val_loss: 0.4442 - val_accuracy: 0.8297\n",
      "Epoch 77/100\n",
      "14117/14117 [==============================] - 52s 4ms/step - loss: 0.0044 - accuracy: 0.8350 - val_loss: 0.4417 - val_accuracy: 0.8315\n",
      "Epoch 78/100\n",
      "14117/14117 [==============================] - 51s 4ms/step - loss: 0.0044 - accuracy: 0.8349 - val_loss: 0.3994 - val_accuracy: 0.8480\n",
      "Epoch 79/100\n",
      "14117/14117 [==============================] - 51s 4ms/step - loss: 0.0044 - accuracy: 0.8355 - val_loss: 0.4073 - val_accuracy: 0.8491\n",
      "Epoch 80/100\n",
      "14117/14117 [==============================] - 52s 4ms/step - loss: 0.0044 - accuracy: 0.8355 - val_loss: 0.4877 - val_accuracy: 0.8210\n",
      "Epoch 81/100\n",
      "14117/14117 [==============================] - 52s 4ms/step - loss: 0.0044 - accuracy: 0.8352 - val_loss: 0.4912 - val_accuracy: 0.8148\n",
      "Epoch 82/100\n",
      "14117/14117 [==============================] - 52s 4ms/step - loss: 0.0044 - accuracy: 0.8355 - val_loss: 0.4636 - val_accuracy: 0.8245\n",
      "Epoch 83/100\n",
      "14117/14117 [==============================] - 51s 4ms/step - loss: 0.0044 - accuracy: 0.8356 - val_loss: 0.4481 - val_accuracy: 0.8267\n",
      "Epoch 84/100\n",
      "14117/14117 [==============================] - 50s 4ms/step - loss: 0.0044 - accuracy: 0.8353 - val_loss: 0.3849 - val_accuracy: 0.8564\n",
      "Epoch 85/100\n",
      "14117/14117 [==============================] - 52s 4ms/step - loss: 0.0044 - accuracy: 0.8358 - val_loss: 0.3634 - val_accuracy: 0.8568\n",
      "Epoch 86/100\n",
      "14117/14117 [==============================] - 51s 4ms/step - loss: 0.0044 - accuracy: 0.8356 - val_loss: 0.4684 - val_accuracy: 0.8285\n",
      "Epoch 87/100\n",
      "14117/14117 [==============================] - 52s 4ms/step - loss: 0.0044 - accuracy: 0.8352 - val_loss: 0.5157 - val_accuracy: 0.8061\n",
      "Epoch 88/100\n",
      "14117/14117 [==============================] - 52s 4ms/step - loss: 0.0044 - accuracy: 0.8356 - val_loss: 0.4793 - val_accuracy: 0.8238\n",
      "Epoch 89/100\n",
      "14117/14117 [==============================] - 51s 4ms/step - loss: 0.0044 - accuracy: 0.8359 - val_loss: 0.4096 - val_accuracy: 0.8438\n",
      "Epoch 90/100\n",
      "14117/14117 [==============================] - 51s 4ms/step - loss: 0.0044 - accuracy: 0.8360 - val_loss: 0.4035 - val_accuracy: 0.8431\n",
      "Epoch 91/100\n",
      "14117/14117 [==============================] - 51s 4ms/step - loss: 0.0044 - accuracy: 0.8357 - val_loss: 0.4431 - val_accuracy: 0.8347\n",
      "Epoch 92/100\n",
      "14117/14117 [==============================] - 51s 4ms/step - loss: 0.0044 - accuracy: 0.8354 - val_loss: 0.4390 - val_accuracy: 0.8289\n",
      "Epoch 93/100\n",
      "14117/14117 [==============================] - 51s 4ms/step - loss: 0.0044 - accuracy: 0.8356 - val_loss: 0.4630 - val_accuracy: 0.8289\n",
      "Epoch 94/100\n",
      "14117/14117 [==============================] - 51s 4ms/step - loss: 0.0044 - accuracy: 0.8358 - val_loss: 0.4739 - val_accuracy: 0.8250\n",
      "Epoch 95/100\n",
      "14117/14117 [==============================] - 51s 4ms/step - loss: 0.0044 - accuracy: 0.8358 - val_loss: 0.4381 - val_accuracy: 0.8342\n",
      "Epoch 96/100\n",
      "14117/14117 [==============================] - 51s 4ms/step - loss: 0.0044 - accuracy: 0.8359 - val_loss: 0.4433 - val_accuracy: 0.8295\n",
      "Epoch 97/100\n",
      "14117/14117 [==============================] - 51s 4ms/step - loss: 0.0044 - accuracy: 0.8356 - val_loss: 0.4376 - val_accuracy: 0.8304\n",
      "Epoch 98/100\n",
      "14117/14117 [==============================] - 51s 4ms/step - loss: 0.0044 - accuracy: 0.8359 - val_loss: 0.4419 - val_accuracy: 0.8304\n",
      "Epoch 99/100\n",
      "14117/14117 [==============================] - 52s 4ms/step - loss: 0.0043 - accuracy: 0.8359 - val_loss: 0.4895 - val_accuracy: 0.8201\n",
      "Epoch 100/100\n",
      "14117/14117 [==============================] - 51s 4ms/step - loss: 0.0043 - accuracy: 0.8364 - val_loss: 0.4219 - val_accuracy: 0.8420\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model.fit(x_train,y_train,epochs=100,batch_size=512,validation_split=0.2,\n",
    "              class_weight={0:.993,1:0.007},callbacks=[callback,tensorboard_callback])\n",
    "    \n",
    "except:\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 8008 (pid 23385), started 0:24:15 ago. (Use '!kill 23385' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8d76a6abd986cfe8\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8d76a6abd986cfe8\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit --port 8008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_pred = model.predict(dtset.T[:-2].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_set = dtset.copy()\n",
    "pred_set['pred'] = tot_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the test set is :  0.8424010349425947\n"
     ]
    }
   ],
   "source": [
    "cor_pred = len(pred_set[train_len:][pred_set['pred'] >= 0.5][pred_set['tag'] == 1]) + len(pred_set[train_len:][pred_set['pred'] < 0.5][pred_set['tag'] == 0])\n",
    "print('The accuracy of the test set is : ',cor_pred/(len(pred_set[train_len:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly identified signal (True Positive)     :  1439022\n",
      "Falsely identified signal (Flase Positive)      :  2947\n",
      "Correctly identified background (True Negative) :  8070559\n",
      "Falsely identified background (False Negative)  :  1780852\n"
     ]
    }
   ],
   "source": [
    "print('Correctly identified signal (True Positive)     : ',len(pred_set[pred_set['pred'] >= 0.5][pred_set['tag'] == 1]))\n",
    "print('Falsely identified signal (Flase Positive)      : ',len(pred_set[pred_set['pred'] >= 0.5][pred_set['tag'] == 0]))\n",
    "print('Correctly identified background (True Negative) : ',len(pred_set[pred_set['pred'] < 0.5][pred_set['tag'] == 0]))\n",
    "print('Falsely identified background (False Negative)  : ',len(pred_set[pred_set['pred'] < 0.5][pred_set['tag'] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of signal left is     : 0.4325130638588712\n",
      "The amount of background left is : 0.0003060788166974251\n"
     ]
    }
   ],
   "source": [
    "print('The amount of signal left is     :', len(pred_set[pred_set['pred'] >= 0.5][pred_set['tag'] == 1])/len(df[-1]))\n",
    "print('The amount of background left is :', len(pred_set[pred_set['pred'] >= 0.5][pred_set['tag'] == 0])/np.sum([len(i) for i in df[:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thus, the rate of correct signal prediction is :  0.9979562667435985\n"
     ]
    }
   ],
   "source": [
    "print('Thus, the rate of correct signal prediction is : ',len(pred_set[pred_set['pred'] >= 0.5][dtset['tag'] == 1])/(len(pred_set[pred_set['pred'] >= 0.5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n2n2 0.399 1070135\n",
      "ttbar 22 6538.845366086956\n",
      "wmp 63 91227.27272727272\n",
      "wpwm 353 692.2567850586979\n",
      "zwpm 551 199.5908264705882\n"
     ]
    }
   ],
   "source": [
    "ns = cs_corr['n2n2']*(len(pred_set[pred_set['pred'] >= 0.7][pred_set['tag'] == 1])/(no_of_files['n2n2']*1e5))*L\n",
    "print('n2n2',cs_corr['n2n2'],(len(pred_set[pred_set['pred'] >= 0.7][pred_set['tag'] == 1])))\n",
    "nb = 0\n",
    "\n",
    "for i in range(len(files)-1):\n",
    "    nb += cs_corr[files[i]]*(len(pred_set[pred_set['pred'] >= 0.7][pred_set['tag'] == 0][pred_set['type'] == i])/((no_of_files[files[i]]*1e5)))*L\n",
    "    print(files[i],len(pred_set[pred_set['pred'] >= 0.7][pred_set['tag'] == 0][pred_set['type'] == i]),cs_corr[files[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of signal is : 328.4491269230769\n",
      "The number of background is : 4752.552148427029\n",
      "The significance is : 4.607798295986711\n"
     ]
    }
   ],
   "source": [
    "print('The number of signal is :', ns)\n",
    "print('The number of background is :', nb)\n",
    "print('The significance is :',ns/np.sqrt(nb + ns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 18:51:15.789644: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home2/kalp_shah/datasets/models/s4/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('/home2/kalp_shah/datasets/models/s4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "cor = tfp.stats.correlation(dtset.values[:-2,:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ptj energyj 0.8240507616760158\n",
      "energyj ptj 0.8240507616760158\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(cor)):\n",
    "    for j in range(len(cor[i])):\n",
    "        if cor[i,j] > 0.8 and i!=j:\n",
    "            print(dtset.keys()[i],dtset.keys()[j],cor[i,j].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(files)):\n",
    "    data = pred_set[pred_set[\"type\"] == i][pred_set[\"pred\"]>=0.5][\"pred\"].values\n",
    "    plt.hist(data,alpha=0.7,bins=20,weights=np.ones_like(data)/len(data))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.5260133e-06, 9.0794361e-05, 9.8490336e-06, ..., 9.6628992e-07,\n",
       "       2.2237360e-02, 1.9050436e-05], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_set[pred_set[\"type\"] == 0][\"pred\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
