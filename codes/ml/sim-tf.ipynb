{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuts on the Right Handed Neutrino Decay\n",
    "\n",
    "This notebook will contain some of the elementary cuts applied on the monoleptonic channel of the right handed neutrino decay.\n",
    "\n",
    "The signal and the background for the process are as follows :\n",
    "- Signal\n",
    "    - n2n2 <br>\n",
    "$p p → Z' → N_r N_r, N_r → Z v_l → j j v_l, N_r → W l → l j j$\n",
    "\n",
    "- Background \n",
    "    - ttbar <br>\n",
    "$p p → t t, t → W b, W → j j$\n",
    "\n",
    "    - wmp <br>\n",
    "$ p p → W → l v_l$\n",
    "\n",
    "    - wpmp <br>\n",
    "$ p p → W+ W- → l v_l j j$\n",
    "\n",
    "    - zwmp <br>\n",
    "$ p p → Z W, Z → j j, W → l v_l $\n",
    "\n",
    "    - zzjj <br>\n",
    "$ p p → Z Z, Z → j j $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters used\n",
    "\n",
    "### Testing parameters :\n",
    "- gX = 0.1\n",
    "- gN = 0.1\n",
    "- Zn2 = 2.838\n",
    "- Mzp = 3000 GeV\n",
    "- Beam Energy = 14 TeV\n",
    "- Default Jet Matching Settings\n",
    "\n",
    "### Generation Level Cuts :\n",
    "- Minimum $P_T$ of leading Lepton = 120\n",
    "- Minimum $P_T$ of leading Jet = 120\n",
    "- Minimum $\\eta_j$ = -2\n",
    "- Maximum $\\eta_j$ = 2\n",
    "\n",
    "### Analysis Level Cuts (Using Topology):\n",
    "- Minimum Number of Leptons = 1\n",
    "- Minimum number of Narrow Jets = 2\n",
    "- Minimum Number of Fat Jets = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "Preprocessing the python files to get the imports required and the Machine Learning to work properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style as mpl\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from sklearn.utils import shuffle\n",
    "import datetime\n",
    "import visualkeras\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "mpl.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 19:51:24.560301: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-15 19:51:25.220563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9626 MB memory:  -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "mn2 = 750\n",
    "prop_seed = 345\n",
    "train_div = 0.5\n",
    "back_callback_dir = \"/home2/kalp_shah/neutrino/codes/ml/backup/dnn\"\n",
    "log_folder = \"logs/dnn\"\n",
    "model_dir = \"/home2/kalp_shah/neutrino/datasets/model/\"\n",
    "sig_epoch = {'test' : [], 'complete' : []}\n",
    "model_max = Sequential()\n",
    "max_sig = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home2/kalp_shah/neutrino/codes/ml/backup/dnn\n",
    "!rm -rf logs/dnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculating the Cross Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculation of the cross section is done as follows :\n",
    "\n",
    "$\\sigma_p = \\sigma_{LO} \\frac{\\sigma_{MGcuts}}{\\sigma_{MGno-cuts}} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2n2_cs = {500  : 5.13*1e-4,\n",
    "           750  : 3.83*1e-4,\n",
    "           1000 : 2.42*1e-4,\n",
    "           1250 : 9.56*1e-5,\n",
    "           1400 : 4.74*1e-5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_lo_k = { 'ttbar':988.57,\n",
    "            'wmp'  :1.95*1e5,\n",
    "            'wpwm' :124.31,\n",
    "            'zwpm' :51.82,\n",
    "            'n2n2' :1}\n",
    "\n",
    "br_ratio = {'ttbar':0.67*(1-0.67)*2,\n",
    "            'wmp'  :(1-0.67),\n",
    "            'wpwm' :(1-0.67)*0.67*2,\n",
    "            'zwpm' :0.7*(1-0.67),\n",
    "            'n2n2' :1}\n",
    "\n",
    "cs_nmg = {  'ttbar':393.30,\n",
    "            'wmp'  :7.865*1e4,\n",
    "            'wpwm' :74.96,\n",
    "            'zwpm' :14.28,\n",
    "            'n2n2' :1}\n",
    "\n",
    "cs_mg = {   'ttbar':5.883,\n",
    "            'wmp':111.5,\n",
    "            'wpwm':0.944,\n",
    "            'zwpm':0.2381,\n",
    "            'n2n2':n2n2_cs[mn2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['ttbar','wmp','wpwm','zwpm','n2n2']\n",
    "\n",
    "# The cross sections are given in picobarn\n",
    "cs_pb = []\n",
    "for f in files:\n",
    "    cs_pb.append((cs_lo_k[f]*br_ratio[f]*cs_mg[f])/cs_nmg[f])\n",
    "\n",
    "cs = [i*1e3 for i in cs_pb]\n",
    "cs_corr = {files[i] : cs[i] for i in range(len(files))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_print = pd.DataFrame([cs_corr.keys(),cs_corr.values()]).T\n",
    "cs_print.rename(columns = {0:'Process',1:'Cross section (fb)'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_19dd5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_19dd5_level0_col0\" class=\"col_heading level0 col0\" >Process</th>\n",
       "      <th id=\"T_19dd5_level0_col1\" class=\"col_heading level0 col1\" >Cross section (fb)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_19dd5_row0_col0\" class=\"data row0 col0\" >ttbar</td>\n",
       "      <td id=\"T_19dd5_row0_col1\" class=\"data row0 col1\" >6538.845366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_19dd5_row1_col0\" class=\"data row1 col0\" >wmp</td>\n",
       "      <td id=\"T_19dd5_row1_col1\" class=\"data row1 col1\" >91227.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_19dd5_row2_col0\" class=\"data row2 col0\" >wpwm</td>\n",
       "      <td id=\"T_19dd5_row2_col1\" class=\"data row2 col1\" >692.256785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_19dd5_row3_col0\" class=\"data row3 col0\" >zwpm</td>\n",
       "      <td id=\"T_19dd5_row3_col1\" class=\"data row3 col1\" >199.590826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_19dd5_row4_col0\" class=\"data row4 col0\" >n2n2</td>\n",
       "      <td id=\"T_19dd5_row4_col1\" class=\"data row4 col1\" >0.383000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1550421df8e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_print.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the amount of events in storage using the following formula :\n",
    "\n",
    "$ N_{p} = N_{files}*N_{Events-per-files} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_files = {'ttbar':0,\n",
    "               'wmp':0,\n",
    "               'wpwm':0,\n",
    "               'zwpm':0,\n",
    "               'n2n2':0\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = []\n",
    "for f in range(len(files)):\n",
    "    con_df = []\n",
    "    \n",
    "    # The maximum file number \n",
    "    for i in range(1,80):\n",
    "        try:\n",
    "            if files[f] == 'n2n2':\n",
    "                con_df.append(pd.read_csv('~/neutrino/datasets/n2n2_' + str(mn2) + '/' + files[f] + str(i) + '.csv'))\n",
    "            else:\n",
    "                con_df.append(pd.read_csv('~/neutrino/datasets/backgrounds/' + files[f] + str(i) + '.csv'))\n",
    "            no_of_files[files[f]] += 1\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    df.append(pd.concat(con_df,ignore_index=True))\n",
    "    df[-1]['type'] = f\n",
    "    \n",
    "    if files[f] == \"n2n2\":\n",
    "        df[-1]['tag'] = 1\n",
    "    else:\n",
    "        df[-1]['tag'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Number of Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_merging = {'ttbar':98159,\n",
    "               'wmp':96494,\n",
    "               'wpwm':97633,\n",
    "               'zwpm':81076,\n",
    "               'n2n2':int(1e5)\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_events = []\n",
    "\n",
    "for f in range(len(files)):\n",
    "    total_events.append(no_of_files[files[f]] * red_merging[files[f]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_print = pd.DataFrame([no_of_files.keys(),total_events]).T\n",
    "nf_print.rename(columns = {0:'Process',1:'Number of Events'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_aed27\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_aed27_level0_col0\" class=\"col_heading level0 col0\" >Process</th>\n",
       "      <th id=\"T_aed27_level0_col1\" class=\"col_heading level0 col1\" >Number of Events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_aed27_row0_col0\" class=\"data row0 col0\" >ttbar</td>\n",
       "      <td id=\"T_aed27_row0_col1\" class=\"data row0 col1\" >6085858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_aed27_row1_col0\" class=\"data row1 col0\" >wmp</td>\n",
       "      <td id=\"T_aed27_row1_col1\" class=\"data row1 col1\" >5886134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_aed27_row2_col0\" class=\"data row2 col0\" >wpwm</td>\n",
       "      <td id=\"T_aed27_row2_col1\" class=\"data row2 col1\" >4002953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_aed27_row3_col0\" class=\"data row3 col0\" >zwpm</td>\n",
       "      <td id=\"T_aed27_row3_col1\" class=\"data row3 col1\" >3648420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_aed27_row4_col0\" class=\"data row4 col0\" >n2n2</td>\n",
       "      <td id=\"T_aed27_row4_col1\" class=\"data row4 col1\" >5000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1551f88187f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf_print.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_bdd1b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_bdd1b_level0_col0\" class=\"col_heading level0 col0\" >ptl</th>\n",
       "      <th id=\"T_bdd1b_level0_col1\" class=\"col_heading level0 col1\" >etal</th>\n",
       "      <th id=\"T_bdd1b_level0_col2\" class=\"col_heading level0 col2\" >energyl</th>\n",
       "      <th id=\"T_bdd1b_level0_col3\" class=\"col_heading level0 col3\" >ptj</th>\n",
       "      <th id=\"T_bdd1b_level0_col4\" class=\"col_heading level0 col4\" >etaj</th>\n",
       "      <th id=\"T_bdd1b_level0_col5\" class=\"col_heading level0 col5\" >energyj</th>\n",
       "      <th id=\"T_bdd1b_level0_col6\" class=\"col_heading level0 col6\" >massj</th>\n",
       "      <th id=\"T_bdd1b_level0_col7\" class=\"col_heading level0 col7\" >mjj</th>\n",
       "      <th id=\"T_bdd1b_level0_col8\" class=\"col_heading level0 col8\" >rjj</th>\n",
       "      <th id=\"T_bdd1b_level0_col9\" class=\"col_heading level0 col9\" >rjl</th>\n",
       "      <th id=\"T_bdd1b_level0_col10\" class=\"col_heading level0 col10\" >met</th>\n",
       "      <th id=\"T_bdd1b_level0_col11\" class=\"col_heading level0 col11\" >n21_1</th>\n",
       "      <th id=\"T_bdd1b_level0_col12\" class=\"col_heading level0 col12\" >n21_2</th>\n",
       "      <th id=\"T_bdd1b_level0_col13\" class=\"col_heading level0 col13\" >n32_1</th>\n",
       "      <th id=\"T_bdd1b_level0_col14\" class=\"col_heading level0 col14\" >n32_2</th>\n",
       "      <th id=\"T_bdd1b_level0_col15\" class=\"col_heading level0 col15\" >infl</th>\n",
       "      <th id=\"T_bdd1b_level0_col16\" class=\"col_heading level0 col16\" >drfl</th>\n",
       "      <th id=\"T_bdd1b_level0_col17\" class=\"col_heading level0 col17\" >type</th>\n",
       "      <th id=\"T_bdd1b_level0_col18\" class=\"col_heading level0 col18\" >tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_bdd1b_row0_col0\" class=\"data row0 col0\" >928.732000</td>\n",
       "      <td id=\"T_bdd1b_row0_col1\" class=\"data row0 col1\" >0.660321</td>\n",
       "      <td id=\"T_bdd1b_row0_col2\" class=\"data row0 col2\" >1138.670000</td>\n",
       "      <td id=\"T_bdd1b_row0_col3\" class=\"data row0 col3\" >128.888000</td>\n",
       "      <td id=\"T_bdd1b_row0_col4\" class=\"data row0 col4\" >-0.661150</td>\n",
       "      <td id=\"T_bdd1b_row0_col5\" class=\"data row0 col5\" >158.918000</td>\n",
       "      <td id=\"T_bdd1b_row0_col6\" class=\"data row0 col6\" >16.113400</td>\n",
       "      <td id=\"T_bdd1b_row0_col7\" class=\"data row0 col7\" >93.933800</td>\n",
       "      <td id=\"T_bdd1b_row0_col8\" class=\"data row0 col8\" >0.843245</td>\n",
       "      <td id=\"T_bdd1b_row0_col9\" class=\"data row0 col9\" >1.791880</td>\n",
       "      <td id=\"T_bdd1b_row0_col10\" class=\"data row0 col10\" >1154.530000</td>\n",
       "      <td id=\"T_bdd1b_row0_col11\" class=\"data row0 col11\" >0.413587</td>\n",
       "      <td id=\"T_bdd1b_row0_col12\" class=\"data row0 col12\" >0.437504</td>\n",
       "      <td id=\"T_bdd1b_row0_col13\" class=\"data row0 col13\" >0.504940</td>\n",
       "      <td id=\"T_bdd1b_row0_col14\" class=\"data row0 col14\" >0.530171</td>\n",
       "      <td id=\"T_bdd1b_row0_col15\" class=\"data row0 col15\" >271.556000</td>\n",
       "      <td id=\"T_bdd1b_row0_col16\" class=\"data row0 col16\" >2.370820</td>\n",
       "      <td id=\"T_bdd1b_row0_col17\" class=\"data row0 col17\" >4</td>\n",
       "      <td id=\"T_bdd1b_row0_col18\" class=\"data row0 col18\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_bdd1b_row1_col0\" class=\"data row1 col0\" >171.961000</td>\n",
       "      <td id=\"T_bdd1b_row1_col1\" class=\"data row1 col1\" >-1.304190</td>\n",
       "      <td id=\"T_bdd1b_row1_col2\" class=\"data row1 col2\" >340.146000</td>\n",
       "      <td id=\"T_bdd1b_row1_col3\" class=\"data row1 col3\" >762.147000</td>\n",
       "      <td id=\"T_bdd1b_row1_col4\" class=\"data row1 col4\" >0.271242</td>\n",
       "      <td id=\"T_bdd1b_row1_col5\" class=\"data row1 col5\" >792.318000</td>\n",
       "      <td id=\"T_bdd1b_row1_col6\" class=\"data row1 col6\" >55.740900</td>\n",
       "      <td id=\"T_bdd1b_row1_col7\" class=\"data row1 col7\" >1519.650000</td>\n",
       "      <td id=\"T_bdd1b_row1_col8\" class=\"data row1 col8\" >0.657866</td>\n",
       "      <td id=\"T_bdd1b_row1_col9\" class=\"data row1 col9\" >1.588940</td>\n",
       "      <td id=\"T_bdd1b_row1_col10\" class=\"data row1 col10\" >272.724000</td>\n",
       "      <td id=\"T_bdd1b_row1_col11\" class=\"data row1 col11\" >0.155415</td>\n",
       "      <td id=\"T_bdd1b_row1_col12\" class=\"data row1 col12\" >0.457475</td>\n",
       "      <td id=\"T_bdd1b_row1_col13\" class=\"data row1 col13\" >0.572989</td>\n",
       "      <td id=\"T_bdd1b_row1_col14\" class=\"data row1 col14\" >0.716689</td>\n",
       "      <td id=\"T_bdd1b_row1_col15\" class=\"data row1 col15\" >1151.980000</td>\n",
       "      <td id=\"T_bdd1b_row1_col16\" class=\"data row1 col16\" >2.243400</td>\n",
       "      <td id=\"T_bdd1b_row1_col17\" class=\"data row1 col17\" >4</td>\n",
       "      <td id=\"T_bdd1b_row1_col18\" class=\"data row1 col18\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_bdd1b_row2_col0\" class=\"data row2 col0\" >570.711000</td>\n",
       "      <td id=\"T_bdd1b_row2_col1\" class=\"data row2 col1\" >-0.459771</td>\n",
       "      <td id=\"T_bdd1b_row2_col2\" class=\"data row2 col2\" >632.103000</td>\n",
       "      <td id=\"T_bdd1b_row2_col3\" class=\"data row2 col3\" >270.644000</td>\n",
       "      <td id=\"T_bdd1b_row2_col4\" class=\"data row2 col4\" >0.332214</td>\n",
       "      <td id=\"T_bdd1b_row2_col5\" class=\"data row2 col5\" >285.822000</td>\n",
       "      <td id=\"T_bdd1b_row2_col6\" class=\"data row2 col6\" >7.777680</td>\n",
       "      <td id=\"T_bdd1b_row2_col7\" class=\"data row2 col7\" >605.465000</td>\n",
       "      <td id=\"T_bdd1b_row2_col8\" class=\"data row2 col8\" >2.463930</td>\n",
       "      <td id=\"T_bdd1b_row2_col9\" class=\"data row2 col9\" >3.203950</td>\n",
       "      <td id=\"T_bdd1b_row2_col10\" class=\"data row2 col10\" >851.541000</td>\n",
       "      <td id=\"T_bdd1b_row2_col11\" class=\"data row2 col11\" >0.270696</td>\n",
       "      <td id=\"T_bdd1b_row2_col12\" class=\"data row2 col12\" >0.310582</td>\n",
       "      <td id=\"T_bdd1b_row2_col13\" class=\"data row2 col13\" >0.159234</td>\n",
       "      <td id=\"T_bdd1b_row2_col14\" class=\"data row2 col14\" >0.665306</td>\n",
       "      <td id=\"T_bdd1b_row2_col15\" class=\"data row2 col15\" >732.662000</td>\n",
       "      <td id=\"T_bdd1b_row2_col16\" class=\"data row2 col16\" >2.079320</td>\n",
       "      <td id=\"T_bdd1b_row2_col17\" class=\"data row2 col17\" >4</td>\n",
       "      <td id=\"T_bdd1b_row2_col18\" class=\"data row2 col18\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_bdd1b_row3_col0\" class=\"data row3 col0\" >606.838000</td>\n",
       "      <td id=\"T_bdd1b_row3_col1\" class=\"data row3 col1\" >0.224155</td>\n",
       "      <td id=\"T_bdd1b_row3_col2\" class=\"data row3 col2\" >622.147000</td>\n",
       "      <td id=\"T_bdd1b_row3_col3\" class=\"data row3 col3\" >1009.930000</td>\n",
       "      <td id=\"T_bdd1b_row3_col4\" class=\"data row3 col4\" >0.653829</td>\n",
       "      <td id=\"T_bdd1b_row3_col5\" class=\"data row3 col5\" >1236.590000</td>\n",
       "      <td id=\"T_bdd1b_row3_col6\" class=\"data row3 col6\" >85.909400</td>\n",
       "      <td id=\"T_bdd1b_row3_col7\" class=\"data row3 col7\" >2005.670000</td>\n",
       "      <td id=\"T_bdd1b_row3_col8\" class=\"data row3 col8\" >3.210830</td>\n",
       "      <td id=\"T_bdd1b_row3_col9\" class=\"data row3 col9\" >3.152860</td>\n",
       "      <td id=\"T_bdd1b_row3_col10\" class=\"data row3 col10\" >314.435000</td>\n",
       "      <td id=\"T_bdd1b_row3_col11\" class=\"data row3 col11\" >0.310787</td>\n",
       "      <td id=\"T_bdd1b_row3_col12\" class=\"data row3 col12\" >0.461950</td>\n",
       "      <td id=\"T_bdd1b_row3_col13\" class=\"data row3 col13\" >0.534193</td>\n",
       "      <td id=\"T_bdd1b_row3_col14\" class=\"data row3 col14\" >0.575369</td>\n",
       "      <td id=\"T_bdd1b_row3_col15\" class=\"data row3 col15\" >418.992000</td>\n",
       "      <td id=\"T_bdd1b_row3_col16\" class=\"data row3 col16\" >2.433750</td>\n",
       "      <td id=\"T_bdd1b_row3_col17\" class=\"data row3 col17\" >4</td>\n",
       "      <td id=\"T_bdd1b_row3_col18\" class=\"data row3 col18\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_bdd1b_row4_col0\" class=\"data row4 col0\" >560.897000</td>\n",
       "      <td id=\"T_bdd1b_row4_col1\" class=\"data row4 col1\" >-0.128569</td>\n",
       "      <td id=\"T_bdd1b_row4_col2\" class=\"data row4 col2\" >565.539000</td>\n",
       "      <td id=\"T_bdd1b_row4_col3\" class=\"data row4 col3\" >561.740000</td>\n",
       "      <td id=\"T_bdd1b_row4_col4\" class=\"data row4 col4\" >1.096740</td>\n",
       "      <td id=\"T_bdd1b_row4_col5\" class=\"data row4 col5\" >938.387000</td>\n",
       "      <td id=\"T_bdd1b_row4_col6\" class=\"data row4 col6\" >81.596100</td>\n",
       "      <td id=\"T_bdd1b_row4_col7\" class=\"data row4 col7\" >1213.140000</td>\n",
       "      <td id=\"T_bdd1b_row4_col8\" class=\"data row4 col8\" >2.882750</td>\n",
       "      <td id=\"T_bdd1b_row4_col9\" class=\"data row4 col9\" >1.505170</td>\n",
       "      <td id=\"T_bdd1b_row4_col10\" class=\"data row4 col10\" >245.536000</td>\n",
       "      <td id=\"T_bdd1b_row4_col11\" class=\"data row4 col11\" >0.204311</td>\n",
       "      <td id=\"T_bdd1b_row4_col12\" class=\"data row4 col12\" >0.320365</td>\n",
       "      <td id=\"T_bdd1b_row4_col13\" class=\"data row4 col13\" >0.795082</td>\n",
       "      <td id=\"T_bdd1b_row4_col14\" class=\"data row4 col14\" >0.947598</td>\n",
       "      <td id=\"T_bdd1b_row4_col15\" class=\"data row4 col15\" >677.436000</td>\n",
       "      <td id=\"T_bdd1b_row4_col16\" class=\"data row4 col16\" >1.597530</td>\n",
       "      <td id=\"T_bdd1b_row4_col17\" class=\"data row4 col17\" >4</td>\n",
       "      <td id=\"T_bdd1b_row4_col18\" class=\"data row4 col18\" >1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1551f87e2e30>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[-1].head().style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Analysis Level Cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(prop_seed)\n",
    "np.random.seed(prop_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtset = pd.concat(df,ignore_index=True)\n",
    "dtset['met'] = np.fabs(dtset['met'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtset = dtset\\\n",
    "       [dtset['ptl'] >= 120.0]\\\n",
    "       [dtset['ptj'] >= 120.0]\\\n",
    "       [dtset['etaj'] <=  2.0]\\\n",
    "       [dtset['etaj'] >= -2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtset = shuffle(dtset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the Train and Test Dataset\n",
    "\n",
    "The division of training and the testing set is 80:20 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percent = int(0.8*len(dtset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = dtset.T[:-2].T[:test_percent]\n",
    "y_train = dtset['tag'][:test_percent]\n",
    "\n",
    "x_test = dtset.T[:-2].T[test_percent:]\n",
    "y_test = dtset['tag'][test_percent:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shapes are :\n",
      "X Train :  (11815580, 17)\n",
      "Y Train :  (11815580,)\n",
      "X Test :   (2953896, 17)\n",
      "Y Test :   (2953896,)\n"
     ]
    }
   ],
   "source": [
    "print('The Shapes are :')\n",
    "print('X Train : ',x_train.shape)\n",
    "print('Y Train : ',y_train.shape)\n",
    "print('X Test :  ',x_test.shape)\n",
    "print('Y Test :  ',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Functions for Saving and Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "backup_callback = tf.keras.callbacks.experimental.BackupAndRestore(backup_dir=back_callback_dir)\n",
    "\n",
    "log_dir = log_folder + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significance(model,x_test,type_test,cs_corr,total_events,L):\n",
    "    total_test = total_events\n",
    "    tot_pred = model.predict(x_test,batch_size=131072)\n",
    "    \n",
    "    pred_values = tf.cast(tf.greater(tot_pred.T,0.7),'int32')\n",
    "    truth_values = tf.cast(tf.equal(type_test,4),'int32')\n",
    "    signal = tf.multiply(pred_values,truth_values)\n",
    "    num_sig = tf.reduce_sum(signal).numpy()\n",
    "    \n",
    "    ns = cs_corr['n2n2']*(num_sig/(total_test[-1]))*L\n",
    "    del(pred_values,truth_values,signal,num_sig)\n",
    "\n",
    "    files = list(cs_corr.keys())\n",
    "    nb = 0\n",
    "    for i in range(len(cs_corr)-1):\n",
    "        pred_values = tf.cast(tf.greater(tot_pred.T,0.7),'int32')\n",
    "        back_values = tf.cast(tf.equal(type_test,i),'int32')\n",
    "        back = tf.multiply(pred_values,back_values)\n",
    "        num_back = tf.reduce_sum(back).numpy()\n",
    "\n",
    "        nb += cs_corr[files[i]]*(num_back/(total_test[i]))*L\n",
    "        del(pred_values,back_values,back,num_back)\n",
    "    \n",
    "    del(tot_pred)\n",
    "    return ns/np.sqrt(nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sig_callback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,model,x_test,type_test,cs_corr,dtset_type,total_events):\n",
    "        self.model = model\n",
    "        self.type_test = type_test\n",
    "        self.cs_corr = cs_corr\n",
    "        self.total_events = total_events\n",
    "        self.x_test = x_test\n",
    "        self.dtset_type = dtset_type\n",
    "\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        global max_sig, model_max\n",
    "        sig = get_significance(self.model,self.x_test,self.type_test,\n",
    "                              self.cs_corr,self.total_events,3000)\n",
    "        print('The '+ self.dtset_type +' significance is : ',sig)\n",
    "        \n",
    "        if epoch==0:\n",
    "            model_max = self.model\n",
    "            max_sig = sig\n",
    "        \n",
    "        elif self.dtset_type == 'test' and max_sig < sig:\n",
    "            model_max = tf.keras.models.clone_model(self.model)\n",
    "            \n",
    "            max_sig = sig\n",
    "            \n",
    "        elif self.dtset_type == 'complete': \n",
    "            gc.collect()\n",
    "            \n",
    "        sig_epoch[self.dtset_type].append(sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "input_shape = x_train.shape\n",
    "\n",
    "model.add(Dense(30,activation = 'relu',input_dim = input_shape[1]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(60,activation = 'relu',input_dim = 30))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(60,activation = 'relu',input_dim = 60))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(40,activation = 'relu',input_dim = 60))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(40,activation = 'relu',input_dim = 40))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(12,activation = 'relu',input_dim = 40))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(8,activation = 'relu',input_dim = 12))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1,activation = 'sigmoid',input_dim = 8))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=2045x710>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualkeras.graph_view(model,node_size=25,layer_spacing=100,ellipsize_after=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2500\n",
      "73/73 [==============================] - 5s 38ms/step - loss: 0.2489 - accuracy: 0.9320 - val_loss: 0.4170 - val_accuracy: 0.8443\n",
      "Epoch 2/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.1304 - accuracy: 0.9455 - val_loss: 0.2048 - val_accuracy: 0.9404\n",
      "Epoch 3/2500\n",
      "73/73 [==============================] - 2s 28ms/step - loss: 0.0820 - accuracy: 0.9332 - val_loss: 0.2416 - val_accuracy: 0.8998\n",
      "Epoch 4/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0584 - accuracy: 0.9215 - val_loss: 0.2833 - val_accuracy: 0.8820\n",
      "Epoch 5/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0447 - accuracy: 0.9113 - val_loss: 0.2888 - val_accuracy: 0.8835\n",
      "Epoch 6/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0359 - accuracy: 0.9024 - val_loss: 0.3066 - val_accuracy: 0.8788\n",
      "Epoch 7/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0297 - accuracy: 0.8972 - val_loss: 0.3402 - val_accuracy: 0.8639\n",
      "Epoch 8/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0243 - accuracy: 0.8943 - val_loss: 0.3719 - val_accuracy: 0.8465\n",
      "Epoch 9/2500\n",
      "73/73 [==============================] - 2s 27ms/step - loss: 0.0203 - accuracy: 0.8983 - val_loss: 0.3721 - val_accuracy: 0.8462\n",
      "Epoch 10/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0183 - accuracy: 0.8982 - val_loss: 0.3311 - val_accuracy: 0.8675\n",
      "Epoch 11/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0169 - accuracy: 0.8969 - val_loss: 0.3327 - val_accuracy: 0.8616\n",
      "Epoch 12/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0159 - accuracy: 0.8958 - val_loss: 0.3508 - val_accuracy: 0.8557\n",
      "Epoch 13/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0151 - accuracy: 0.8954 - val_loss: 0.3153 - val_accuracy: 0.8726\n",
      "Epoch 14/2500\n",
      "73/73 [==============================] - 2s 28ms/step - loss: 0.0145 - accuracy: 0.8946 - val_loss: 0.3159 - val_accuracy: 0.8730\n",
      "Epoch 15/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0140 - accuracy: 0.8952 - val_loss: 0.3636 - val_accuracy: 0.8504\n",
      "Epoch 16/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0137 - accuracy: 0.8946 - val_loss: 0.3843 - val_accuracy: 0.8441\n",
      "Epoch 17/2500\n",
      "73/73 [==============================] - 2s 28ms/step - loss: 0.0132 - accuracy: 0.8939 - val_loss: 0.3087 - val_accuracy: 0.8793\n",
      "Epoch 18/2500\n",
      "73/73 [==============================] - 2s 29ms/step - loss: 0.0129 - accuracy: 0.8929 - val_loss: 0.3561 - val_accuracy: 0.8595\n",
      "Epoch 19/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0125 - accuracy: 0.8932 - val_loss: 0.3509 - val_accuracy: 0.8604\n",
      "Epoch 20/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0124 - accuracy: 0.8930 - val_loss: 0.3511 - val_accuracy: 0.8608\n",
      "Epoch 21/2500\n",
      "73/73 [==============================] - 2s 27ms/step - loss: 0.0121 - accuracy: 0.8938 - val_loss: 0.3832 - val_accuracy: 0.8446\n",
      "Epoch 22/2500\n",
      "73/73 [==============================] - 2s 27ms/step - loss: 0.0120 - accuracy: 0.8933 - val_loss: 0.3130 - val_accuracy: 0.8763\n",
      "Epoch 23/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0118 - accuracy: 0.8935 - val_loss: 0.3270 - val_accuracy: 0.8731\n",
      "Epoch 24/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0116 - accuracy: 0.8937 - val_loss: 0.3208 - val_accuracy: 0.8745\n",
      "Epoch 25/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0116 - accuracy: 0.8923 - val_loss: 0.3495 - val_accuracy: 0.8601\n",
      "Epoch 26/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0115 - accuracy: 0.8935 - val_loss: 0.3314 - val_accuracy: 0.8716\n",
      "Epoch 27/2500\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 0.0114 - accuracy: 0.8927 - val_loss: 0.3122 - val_accuracy: 0.8775\n",
      "Epoch 28/2500\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 0.0113 - accuracy: 0.8928 - val_loss: 0.3036 - val_accuracy: 0.8822\n",
      "Epoch 29/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0112 - accuracy: 0.8931 - val_loss: 0.3397 - val_accuracy: 0.8687\n",
      "Epoch 30/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0112 - accuracy: 0.8931 - val_loss: 0.3666 - val_accuracy: 0.8546\n",
      "Epoch 31/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0111 - accuracy: 0.8927 - val_loss: 0.3596 - val_accuracy: 0.8606\n",
      "Epoch 32/2500\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 0.0110 - accuracy: 0.8931 - val_loss: 0.3027 - val_accuracy: 0.8825\n",
      "Epoch 33/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0110 - accuracy: 0.8929 - val_loss: 0.3262 - val_accuracy: 0.8719\n",
      "Epoch 34/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0110 - accuracy: 0.8930 - val_loss: 0.3971 - val_accuracy: 0.8405\n",
      "Epoch 35/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0109 - accuracy: 0.8930 - val_loss: 0.3147 - val_accuracy: 0.8784\n",
      "Epoch 36/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0109 - accuracy: 0.8938 - val_loss: 0.4031 - val_accuracy: 0.8432\n",
      "Epoch 37/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0108 - accuracy: 0.8933 - val_loss: 0.3106 - val_accuracy: 0.8801\n",
      "Epoch 38/2500\n",
      "73/73 [==============================] - 2s 27ms/step - loss: 0.0108 - accuracy: 0.8936 - val_loss: 0.3938 - val_accuracy: 0.8458\n",
      "Epoch 39/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0110 - accuracy: 0.8919 - val_loss: 0.3002 - val_accuracy: 0.8884\n",
      "Epoch 40/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0108 - accuracy: 0.8943 - val_loss: 0.4131 - val_accuracy: 0.8381\n",
      "Epoch 41/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0107 - accuracy: 0.8940 - val_loss: 0.2992 - val_accuracy: 0.8846\n",
      "Epoch 42/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0106 - accuracy: 0.8940 - val_loss: 0.3079 - val_accuracy: 0.8821\n",
      "Epoch 43/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0106 - accuracy: 0.8941 - val_loss: 0.3156 - val_accuracy: 0.8812\n",
      "Epoch 44/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0106 - accuracy: 0.8943 - val_loss: 0.3046 - val_accuracy: 0.8831\n",
      "Epoch 45/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0106 - accuracy: 0.8940 - val_loss: 0.3393 - val_accuracy: 0.8718\n",
      "Epoch 46/2500\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 0.0106 - accuracy: 0.8941 - val_loss: 0.4318 - val_accuracy: 0.8298\n",
      "Epoch 47/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0106 - accuracy: 0.8943 - val_loss: 0.3737 - val_accuracy: 0.8551\n",
      "Epoch 48/2500\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 0.0105 - accuracy: 0.8945 - val_loss: 0.3505 - val_accuracy: 0.8645\n",
      "Epoch 49/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0105 - accuracy: 0.8949 - val_loss: 0.3752 - val_accuracy: 0.8554\n",
      "Epoch 50/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0105 - accuracy: 0.8947 - val_loss: 0.3555 - val_accuracy: 0.8661\n",
      "Epoch 51/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0104 - accuracy: 0.8952 - val_loss: 0.4223 - val_accuracy: 0.8419\n",
      "Epoch 52/2500\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 0.0104 - accuracy: 0.8949 - val_loss: 0.3921 - val_accuracy: 0.8525\n",
      "Epoch 53/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0104 - accuracy: 0.8951 - val_loss: 0.4200 - val_accuracy: 0.8423\n",
      "Epoch 54/2500\n",
      "73/73 [==============================] - 2s 27ms/step - loss: 0.0104 - accuracy: 0.8959 - val_loss: 0.4325 - val_accuracy: 0.8383\n",
      "Epoch 55/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0104 - accuracy: 0.8959 - val_loss: 0.4295 - val_accuracy: 0.8380\n",
      "Epoch 56/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0104 - accuracy: 0.8957 - val_loss: 0.4507 - val_accuracy: 0.8323\n",
      "Epoch 57/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0103 - accuracy: 0.8963 - val_loss: 0.4159 - val_accuracy: 0.8450\n",
      "Epoch 58/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0103 - accuracy: 0.8960 - val_loss: 0.3655 - val_accuracy: 0.8643\n",
      "Epoch 59/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0103 - accuracy: 0.8965 - val_loss: 0.4153 - val_accuracy: 0.8441\n",
      "Epoch 60/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0103 - accuracy: 0.8963 - val_loss: 0.4183 - val_accuracy: 0.8413\n",
      "Epoch 61/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0102 - accuracy: 0.8969 - val_loss: 0.3742 - val_accuracy: 0.8595\n",
      "Epoch 62/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0102 - accuracy: 0.8969 - val_loss: 0.3941 - val_accuracy: 0.8519\n",
      "Epoch 63/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0102 - accuracy: 0.8970 - val_loss: 0.4385 - val_accuracy: 0.8356\n",
      "Epoch 64/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0102 - accuracy: 0.8972 - val_loss: 0.5099 - val_accuracy: 0.8136\n",
      "Epoch 65/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0103 - accuracy: 0.8970 - val_loss: 0.3762 - val_accuracy: 0.8592\n",
      "Epoch 66/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0101 - accuracy: 0.8976 - val_loss: 0.3686 - val_accuracy: 0.8580\n",
      "Epoch 67/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0101 - accuracy: 0.8980 - val_loss: 0.2520 - val_accuracy: 0.9059\n",
      "Epoch 68/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0101 - accuracy: 0.8982 - val_loss: 0.3414 - val_accuracy: 0.8657\n",
      "Epoch 69/2500\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 0.0101 - accuracy: 0.8984 - val_loss: 0.3308 - val_accuracy: 0.8679\n",
      "Epoch 70/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0100 - accuracy: 0.8981 - val_loss: 0.2897 - val_accuracy: 0.8892\n",
      "Epoch 71/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0101 - accuracy: 0.8988 - val_loss: 0.3283 - val_accuracy: 0.8738\n",
      "Epoch 72/2500\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 0.0101 - accuracy: 0.8979 - val_loss: 0.4763 - val_accuracy: 0.8159\n",
      "Epoch 73/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0101 - accuracy: 0.8982 - val_loss: 0.3343 - val_accuracy: 0.8724\n",
      "Epoch 74/2500\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 0.0100 - accuracy: 0.8988 - val_loss: 0.2845 - val_accuracy: 0.8906\n",
      "Epoch 75/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0100 - accuracy: 0.8990 - val_loss: 0.2869 - val_accuracy: 0.8886\n",
      "Epoch 76/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0100 - accuracy: 0.8992 - val_loss: 0.3286 - val_accuracy: 0.8722\n",
      "Epoch 77/2500\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 0.0100 - accuracy: 0.8990 - val_loss: 0.2363 - val_accuracy: 0.9100\n",
      "Epoch 78/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0100 - accuracy: 0.8990 - val_loss: 0.3021 - val_accuracy: 0.8826\n",
      "Epoch 79/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0100 - accuracy: 0.8989 - val_loss: 0.3233 - val_accuracy: 0.8738\n",
      "Epoch 80/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0100 - accuracy: 0.8990 - val_loss: 0.3083 - val_accuracy: 0.8806\n",
      "Epoch 81/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0099 - accuracy: 0.8993 - val_loss: 0.2550 - val_accuracy: 0.9032\n",
      "Epoch 82/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0099 - accuracy: 0.8993 - val_loss: 0.2421 - val_accuracy: 0.9090\n",
      "Epoch 83/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0099 - accuracy: 0.8997 - val_loss: 0.2914 - val_accuracy: 0.8860\n",
      "Epoch 84/2500\n",
      "73/73 [==============================] - 2s 27ms/step - loss: 0.0100 - accuracy: 0.8990 - val_loss: 0.3183 - val_accuracy: 0.8773\n",
      "Epoch 85/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0099 - accuracy: 0.8995 - val_loss: 0.2252 - val_accuracy: 0.9162\n",
      "Epoch 86/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0099 - accuracy: 0.8999 - val_loss: 0.2490 - val_accuracy: 0.9045\n",
      "Epoch 87/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0099 - accuracy: 0.8996 - val_loss: 0.3061 - val_accuracy: 0.8804\n",
      "Epoch 88/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0099 - accuracy: 0.8998 - val_loss: 0.2976 - val_accuracy: 0.8865\n",
      "Epoch 89/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0099 - accuracy: 0.9000 - val_loss: 0.2649 - val_accuracy: 0.9001\n",
      "Epoch 90/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0099 - accuracy: 0.8997 - val_loss: 0.2270 - val_accuracy: 0.9147\n",
      "Epoch 91/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0099 - accuracy: 0.9000 - val_loss: 0.2900 - val_accuracy: 0.8867\n",
      "Epoch 92/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0099 - accuracy: 0.9002 - val_loss: 0.2448 - val_accuracy: 0.9075\n",
      "Epoch 93/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0099 - accuracy: 0.9006 - val_loss: 0.2302 - val_accuracy: 0.9120\n",
      "Epoch 94/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0099 - accuracy: 0.9006 - val_loss: 0.2420 - val_accuracy: 0.9065\n",
      "Epoch 95/2500\n",
      "73/73 [==============================] - 2s 27ms/step - loss: 0.0099 - accuracy: 0.8998 - val_loss: 0.2870 - val_accuracy: 0.8893\n",
      "Epoch 96/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0099 - accuracy: 0.8998 - val_loss: 0.2771 - val_accuracy: 0.8965\n",
      "Epoch 97/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0099 - accuracy: 0.8999 - val_loss: 0.3107 - val_accuracy: 0.8815\n",
      "Epoch 98/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0098 - accuracy: 0.9007 - val_loss: 0.2972 - val_accuracy: 0.8856\n",
      "Epoch 99/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0098 - accuracy: 0.9007 - val_loss: 0.3255 - val_accuracy: 0.8742\n",
      "Epoch 100/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0098 - accuracy: 0.9007 - val_loss: 0.2735 - val_accuracy: 0.8939\n",
      "Epoch 101/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0098 - accuracy: 0.9007 - val_loss: 0.2375 - val_accuracy: 0.9108\n",
      "Epoch 102/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0098 - accuracy: 0.9008 - val_loss: 0.2596 - val_accuracy: 0.9013\n",
      "Epoch 103/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0098 - accuracy: 0.9012 - val_loss: 0.2420 - val_accuracy: 0.9093\n",
      "Epoch 104/2500\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 0.0098 - accuracy: 0.9015 - val_loss: 0.2491 - val_accuracy: 0.9062\n",
      "Epoch 105/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0098 - accuracy: 0.9016 - val_loss: 0.2671 - val_accuracy: 0.8969\n",
      "Epoch 106/2500\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 0.0097 - accuracy: 0.9019 - val_loss: 0.2345 - val_accuracy: 0.9096\n",
      "Epoch 107/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0097 - accuracy: 0.9024 - val_loss: 0.2383 - val_accuracy: 0.9075\n",
      "Epoch 108/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0096 - accuracy: 0.9035 - val_loss: 0.2571 - val_accuracy: 0.8989\n",
      "Epoch 109/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0094 - accuracy: 0.9074 - val_loss: 0.1654 - val_accuracy: 0.9377\n",
      "Epoch 110/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0091 - accuracy: 0.9114 - val_loss: 0.1780 - val_accuracy: 0.9341\n",
      "Epoch 111/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0088 - accuracy: 0.9146 - val_loss: 0.1551 - val_accuracy: 0.9441\n",
      "Epoch 112/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0087 - accuracy: 0.9154 - val_loss: 0.1908 - val_accuracy: 0.9299\n",
      "Epoch 113/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0086 - accuracy: 0.9168 - val_loss: 0.2213 - val_accuracy: 0.9181\n",
      "Epoch 114/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0086 - accuracy: 0.9172 - val_loss: 0.2423 - val_accuracy: 0.9089\n",
      "Epoch 115/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0085 - accuracy: 0.9183 - val_loss: 0.2165 - val_accuracy: 0.9189\n",
      "Epoch 116/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0085 - accuracy: 0.9179 - val_loss: 0.2654 - val_accuracy: 0.8996\n",
      "Epoch 117/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0084 - accuracy: 0.9189 - val_loss: 0.1892 - val_accuracy: 0.9322\n",
      "Epoch 118/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0084 - accuracy: 0.9191 - val_loss: 0.2200 - val_accuracy: 0.9193\n",
      "Epoch 119/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0083 - accuracy: 0.9197 - val_loss: 0.2260 - val_accuracy: 0.9144\n",
      "Epoch 120/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0083 - accuracy: 0.9198 - val_loss: 0.2015 - val_accuracy: 0.9249\n",
      "Epoch 121/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0083 - accuracy: 0.9201 - val_loss: 0.2366 - val_accuracy: 0.9138\n",
      "Epoch 122/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0083 - accuracy: 0.9200 - val_loss: 0.2486 - val_accuracy: 0.9064\n",
      "Epoch 123/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0083 - accuracy: 0.9201 - val_loss: 0.2119 - val_accuracy: 0.9227\n",
      "Epoch 124/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0082 - accuracy: 0.9210 - val_loss: 0.2573 - val_accuracy: 0.9002\n",
      "Epoch 125/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0082 - accuracy: 0.9209 - val_loss: 0.2129 - val_accuracy: 0.9220\n",
      "Epoch 126/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0082 - accuracy: 0.9214 - val_loss: 0.2021 - val_accuracy: 0.9260\n",
      "Epoch 127/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0081 - accuracy: 0.9215 - val_loss: 0.1969 - val_accuracy: 0.9291\n",
      "Epoch 128/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0081 - accuracy: 0.9216 - val_loss: 0.2263 - val_accuracy: 0.9160\n",
      "Epoch 129/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0081 - accuracy: 0.9221 - val_loss: 0.2282 - val_accuracy: 0.9140\n",
      "Epoch 130/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0081 - accuracy: 0.9218 - val_loss: 0.2433 - val_accuracy: 0.9084\n",
      "Epoch 131/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0081 - accuracy: 0.9219 - val_loss: 0.2439 - val_accuracy: 0.9063\n",
      "Epoch 132/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0081 - accuracy: 0.9219 - val_loss: 0.2133 - val_accuracy: 0.9227\n",
      "Epoch 133/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0081 - accuracy: 0.9225 - val_loss: 0.2343 - val_accuracy: 0.9110\n",
      "Epoch 134/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0081 - accuracy: 0.9222 - val_loss: 0.2061 - val_accuracy: 0.9255\n",
      "Epoch 135/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0081 - accuracy: 0.9224 - val_loss: 0.2187 - val_accuracy: 0.9185\n",
      "Epoch 136/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0080 - accuracy: 0.9228 - val_loss: 0.2342 - val_accuracy: 0.9128\n",
      "Epoch 137/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0080 - accuracy: 0.9229 - val_loss: 0.2098 - val_accuracy: 0.9222\n",
      "Epoch 138/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0080 - accuracy: 0.9232 - val_loss: 0.1927 - val_accuracy: 0.9284\n",
      "Epoch 139/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0080 - accuracy: 0.9230 - val_loss: 0.2081 - val_accuracy: 0.9239\n",
      "Epoch 140/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0080 - accuracy: 0.9231 - val_loss: 0.2143 - val_accuracy: 0.9213\n",
      "Epoch 141/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0080 - accuracy: 0.9234 - val_loss: 0.2246 - val_accuracy: 0.9175\n",
      "Epoch 142/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0079 - accuracy: 0.9238 - val_loss: 0.2518 - val_accuracy: 0.9083\n",
      "Epoch 143/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0080 - accuracy: 0.9232 - val_loss: 0.2071 - val_accuracy: 0.9239\n",
      "Epoch 144/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0079 - accuracy: 0.9239 - val_loss: 0.2666 - val_accuracy: 0.8947\n",
      "Epoch 145/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0079 - accuracy: 0.9237 - val_loss: 0.2575 - val_accuracy: 0.9037\n",
      "Epoch 146/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0080 - accuracy: 0.9232 - val_loss: 0.2117 - val_accuracy: 0.9222\n",
      "Epoch 147/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0079 - accuracy: 0.9240 - val_loss: 0.1955 - val_accuracy: 0.9297\n",
      "Epoch 148/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0079 - accuracy: 0.9243 - val_loss: 0.2205 - val_accuracy: 0.9171\n",
      "Epoch 149/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0079 - accuracy: 0.9241 - val_loss: 0.2000 - val_accuracy: 0.9261\n",
      "Epoch 150/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0078 - accuracy: 0.9247 - val_loss: 0.2080 - val_accuracy: 0.9234\n",
      "Epoch 151/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0079 - accuracy: 0.9240 - val_loss: 0.2262 - val_accuracy: 0.9143\n",
      "Epoch 152/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0079 - accuracy: 0.9245 - val_loss: 0.2160 - val_accuracy: 0.9194\n",
      "Epoch 153/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0079 - accuracy: 0.9246 - val_loss: 0.2087 - val_accuracy: 0.9233\n",
      "Epoch 154/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0078 - accuracy: 0.9248 - val_loss: 0.1922 - val_accuracy: 0.9290\n",
      "Epoch 155/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0078 - accuracy: 0.9251 - val_loss: 0.2383 - val_accuracy: 0.9121\n",
      "Epoch 156/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0078 - accuracy: 0.9252 - val_loss: 0.2067 - val_accuracy: 0.9255\n",
      "Epoch 157/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0078 - accuracy: 0.9249 - val_loss: 0.2285 - val_accuracy: 0.9152\n",
      "Epoch 158/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0078 - accuracy: 0.9253 - val_loss: 0.1844 - val_accuracy: 0.9336\n",
      "Epoch 159/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0078 - accuracy: 0.9248 - val_loss: 0.2105 - val_accuracy: 0.9239\n",
      "Epoch 160/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0078 - accuracy: 0.9251 - val_loss: 0.2473 - val_accuracy: 0.9078\n",
      "Epoch 161/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0078 - accuracy: 0.9252 - val_loss: 0.2292 - val_accuracy: 0.9140\n",
      "Epoch 162/2500\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 0.0077 - accuracy: 0.9259 - val_loss: 0.2059 - val_accuracy: 0.9241\n",
      "Epoch 163/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0077 - accuracy: 0.9258 - val_loss: 0.1918 - val_accuracy: 0.9298\n",
      "Epoch 164/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0078 - accuracy: 0.9248 - val_loss: 0.1934 - val_accuracy: 0.9295\n",
      "Epoch 165/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0078 - accuracy: 0.9253 - val_loss: 0.1916 - val_accuracy: 0.9293\n",
      "Epoch 166/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0077 - accuracy: 0.9260 - val_loss: 0.1952 - val_accuracy: 0.9281\n",
      "Epoch 167/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0077 - accuracy: 0.9259 - val_loss: 0.1861 - val_accuracy: 0.9316\n",
      "Epoch 168/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0077 - accuracy: 0.9261 - val_loss: 0.1836 - val_accuracy: 0.9336\n",
      "Epoch 169/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0077 - accuracy: 0.9260 - val_loss: 0.2235 - val_accuracy: 0.9171\n",
      "Epoch 170/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0077 - accuracy: 0.9261 - val_loss: 0.2157 - val_accuracy: 0.9184\n",
      "Epoch 171/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0077 - accuracy: 0.9262 - val_loss: 0.1988 - val_accuracy: 0.9276\n",
      "Epoch 172/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0077 - accuracy: 0.9259 - val_loss: 0.1972 - val_accuracy: 0.9281\n",
      "Epoch 173/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0077 - accuracy: 0.9264 - val_loss: 0.2033 - val_accuracy: 0.9242\n",
      "Epoch 174/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0077 - accuracy: 0.9263 - val_loss: 0.1815 - val_accuracy: 0.9343\n",
      "Epoch 175/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0077 - accuracy: 0.9261 - val_loss: 0.1983 - val_accuracy: 0.9267\n",
      "Epoch 176/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0077 - accuracy: 0.9266 - val_loss: 0.2122 - val_accuracy: 0.9226\n",
      "Epoch 177/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0077 - accuracy: 0.9262 - val_loss: 0.2277 - val_accuracy: 0.9151\n",
      "Epoch 178/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0076 - accuracy: 0.9266 - val_loss: 0.2024 - val_accuracy: 0.9256\n",
      "Epoch 179/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0076 - accuracy: 0.9267 - val_loss: 0.1854 - val_accuracy: 0.9309\n",
      "Epoch 180/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0077 - accuracy: 0.9267 - val_loss: 0.2330 - val_accuracy: 0.9135\n",
      "Epoch 181/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0077 - accuracy: 0.9260 - val_loss: 0.1962 - val_accuracy: 0.9283\n",
      "Epoch 182/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0076 - accuracy: 0.9266 - val_loss: 0.1937 - val_accuracy: 0.9294\n",
      "Epoch 183/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0076 - accuracy: 0.9267 - val_loss: 0.2193 - val_accuracy: 0.9194\n",
      "Epoch 184/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0076 - accuracy: 0.9266 - val_loss: 0.2164 - val_accuracy: 0.9210\n",
      "Epoch 185/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0076 - accuracy: 0.9267 - val_loss: 0.1929 - val_accuracy: 0.9309\n",
      "Epoch 186/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0076 - accuracy: 0.9268 - val_loss: 0.2422 - val_accuracy: 0.9089\n",
      "Epoch 187/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0076 - accuracy: 0.9265 - val_loss: 0.1985 - val_accuracy: 0.9268\n",
      "Epoch 188/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0076 - accuracy: 0.9268 - val_loss: 0.2007 - val_accuracy: 0.9253\n",
      "Epoch 189/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0076 - accuracy: 0.9270 - val_loss: 0.2267 - val_accuracy: 0.9157\n",
      "Epoch 190/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0076 - accuracy: 0.9270 - val_loss: 0.2415 - val_accuracy: 0.9084\n",
      "Epoch 191/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0076 - accuracy: 0.9268 - val_loss: 0.1882 - val_accuracy: 0.9309\n",
      "Epoch 192/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0076 - accuracy: 0.9275 - val_loss: 0.2159 - val_accuracy: 0.9205\n",
      "Epoch 193/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0076 - accuracy: 0.9272 - val_loss: 0.2059 - val_accuracy: 0.9240\n",
      "Epoch 194/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0076 - accuracy: 0.9272 - val_loss: 0.2050 - val_accuracy: 0.9249\n",
      "Epoch 195/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0076 - accuracy: 0.9274 - val_loss: 0.1700 - val_accuracy: 0.9380\n",
      "Epoch 196/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0076 - accuracy: 0.9268 - val_loss: 0.1846 - val_accuracy: 0.9326\n",
      "Epoch 197/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0076 - accuracy: 0.9272 - val_loss: 0.2032 - val_accuracy: 0.9263\n",
      "Epoch 198/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0076 - accuracy: 0.9274 - val_loss: 0.2229 - val_accuracy: 0.9171\n",
      "Epoch 199/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0076 - accuracy: 0.9276 - val_loss: 0.1823 - val_accuracy: 0.9338\n",
      "Epoch 200/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0076 - accuracy: 0.9277 - val_loss: 0.2435 - val_accuracy: 0.9095\n",
      "Epoch 201/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0076 - accuracy: 0.9271 - val_loss: 0.1789 - val_accuracy: 0.9353\n",
      "Epoch 202/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0076 - accuracy: 0.9271 - val_loss: 0.1977 - val_accuracy: 0.9273\n",
      "Epoch 203/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0076 - accuracy: 0.9271 - val_loss: 0.1954 - val_accuracy: 0.9280\n",
      "Epoch 204/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0076 - accuracy: 0.9276 - val_loss: 0.1804 - val_accuracy: 0.9344\n",
      "Epoch 205/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0076 - accuracy: 0.9274 - val_loss: 0.2115 - val_accuracy: 0.9219\n",
      "Epoch 206/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0075 - accuracy: 0.9277 - val_loss: 0.2063 - val_accuracy: 0.9225\n",
      "Epoch 207/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0075 - accuracy: 0.9275 - val_loss: 0.2012 - val_accuracy: 0.9268\n",
      "Epoch 208/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0075 - accuracy: 0.9279 - val_loss: 0.1996 - val_accuracy: 0.9264\n",
      "Epoch 209/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0075 - accuracy: 0.9281 - val_loss: 0.1896 - val_accuracy: 0.9312\n",
      "Epoch 210/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0075 - accuracy: 0.9276 - val_loss: 0.1900 - val_accuracy: 0.9314\n",
      "Epoch 211/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0075 - accuracy: 0.9279 - val_loss: 0.2115 - val_accuracy: 0.9226\n",
      "Epoch 212/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0075 - accuracy: 0.9279 - val_loss: 0.1855 - val_accuracy: 0.9319\n",
      "Epoch 213/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0075 - accuracy: 0.9278 - val_loss: 0.1778 - val_accuracy: 0.9355\n",
      "Epoch 214/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0075 - accuracy: 0.9280 - val_loss: 0.1979 - val_accuracy: 0.9266\n",
      "Epoch 215/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0075 - accuracy: 0.9280 - val_loss: 0.2003 - val_accuracy: 0.9272\n",
      "Epoch 216/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0075 - accuracy: 0.9280 - val_loss: 0.2136 - val_accuracy: 0.9216\n",
      "Epoch 217/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0075 - accuracy: 0.9280 - val_loss: 0.2294 - val_accuracy: 0.9199\n",
      "Epoch 218/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0077 - accuracy: 0.9268 - val_loss: 0.2173 - val_accuracy: 0.9189\n",
      "Epoch 219/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0075 - accuracy: 0.9278 - val_loss: 0.1696 - val_accuracy: 0.9393\n",
      "Epoch 220/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0075 - accuracy: 0.9281 - val_loss: 0.2168 - val_accuracy: 0.9200\n",
      "Epoch 221/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0075 - accuracy: 0.9281 - val_loss: 0.2145 - val_accuracy: 0.9209\n",
      "Epoch 222/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0075 - accuracy: 0.9282 - val_loss: 0.2305 - val_accuracy: 0.9148\n",
      "Epoch 223/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0075 - accuracy: 0.9284 - val_loss: 0.2296 - val_accuracy: 0.9137\n",
      "Epoch 224/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0075 - accuracy: 0.9282 - val_loss: 0.2031 - val_accuracy: 0.9248\n",
      "Epoch 225/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0075 - accuracy: 0.9282 - val_loss: 0.1977 - val_accuracy: 0.9269\n",
      "Epoch 226/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0075 - accuracy: 0.9281 - val_loss: 0.1850 - val_accuracy: 0.9324\n",
      "Epoch 227/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0075 - accuracy: 0.9283 - val_loss: 0.2265 - val_accuracy: 0.9146\n",
      "Epoch 228/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0075 - accuracy: 0.9282 - val_loss: 0.2106 - val_accuracy: 0.9224\n",
      "Epoch 229/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0075 - accuracy: 0.9283 - val_loss: 0.2037 - val_accuracy: 0.9257\n",
      "Epoch 230/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0074 - accuracy: 0.9284 - val_loss: 0.1981 - val_accuracy: 0.9278\n",
      "Epoch 231/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0075 - accuracy: 0.9282 - val_loss: 0.1955 - val_accuracy: 0.9293\n",
      "Epoch 232/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9287 - val_loss: 0.2014 - val_accuracy: 0.9265\n",
      "Epoch 233/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0075 - accuracy: 0.9285 - val_loss: 0.1808 - val_accuracy: 0.9350\n",
      "Epoch 234/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0075 - accuracy: 0.9282 - val_loss: 0.2235 - val_accuracy: 0.9164\n",
      "Epoch 235/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9285 - val_loss: 0.2681 - val_accuracy: 0.8984\n",
      "Epoch 236/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0075 - accuracy: 0.9280 - val_loss: 0.1837 - val_accuracy: 0.9328\n",
      "Epoch 237/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9286 - val_loss: 0.2084 - val_accuracy: 0.9234\n",
      "Epoch 238/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0075 - accuracy: 0.9280 - val_loss: 0.2055 - val_accuracy: 0.9241\n",
      "Epoch 239/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0075 - accuracy: 0.9285 - val_loss: 0.2129 - val_accuracy: 0.9203\n",
      "Epoch 240/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9287 - val_loss: 0.2100 - val_accuracy: 0.9232\n",
      "Epoch 241/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9287 - val_loss: 0.1916 - val_accuracy: 0.9292\n",
      "Epoch 242/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9289 - val_loss: 0.2392 - val_accuracy: 0.9087\n",
      "Epoch 243/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0074 - accuracy: 0.9286 - val_loss: 0.2028 - val_accuracy: 0.9250\n",
      "Epoch 244/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9287 - val_loss: 0.1997 - val_accuracy: 0.9264\n",
      "Epoch 245/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9287 - val_loss: 0.2087 - val_accuracy: 0.9226\n",
      "Epoch 246/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9286 - val_loss: 0.2023 - val_accuracy: 0.9256\n",
      "Epoch 247/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0074 - accuracy: 0.9285 - val_loss: 0.1651 - val_accuracy: 0.9409\n",
      "Epoch 248/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9291 - val_loss: 0.2154 - val_accuracy: 0.9198\n",
      "Epoch 249/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0074 - accuracy: 0.9284 - val_loss: 0.2102 - val_accuracy: 0.9226\n",
      "Epoch 250/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0074 - accuracy: 0.9291 - val_loss: 0.1823 - val_accuracy: 0.9322\n",
      "Epoch 251/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0074 - accuracy: 0.9287 - val_loss: 0.2079 - val_accuracy: 0.9221\n",
      "Epoch 252/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0075 - accuracy: 0.9284 - val_loss: 0.2255 - val_accuracy: 0.9158\n",
      "Epoch 253/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0074 - accuracy: 0.9289 - val_loss: 0.1924 - val_accuracy: 0.9290\n",
      "Epoch 254/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0074 - accuracy: 0.9287 - val_loss: 0.2122 - val_accuracy: 0.9224\n",
      "Epoch 255/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9294 - val_loss: 0.2146 - val_accuracy: 0.9205\n",
      "Epoch 256/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9287 - val_loss: 0.1909 - val_accuracy: 0.9305\n",
      "Epoch 257/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9292 - val_loss: 0.1902 - val_accuracy: 0.9301\n",
      "Epoch 258/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9290 - val_loss: 0.2276 - val_accuracy: 0.9160\n",
      "Epoch 259/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9288 - val_loss: 0.2064 - val_accuracy: 0.9228\n",
      "Epoch 260/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9291 - val_loss: 0.1841 - val_accuracy: 0.9323\n",
      "Epoch 261/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9292 - val_loss: 0.1925 - val_accuracy: 0.9288\n",
      "Epoch 262/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9288 - val_loss: 0.2362 - val_accuracy: 0.9131\n",
      "Epoch 263/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0075 - accuracy: 0.9277 - val_loss: 0.1635 - val_accuracy: 0.9416\n",
      "Epoch 264/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9288 - val_loss: 0.2149 - val_accuracy: 0.9200\n",
      "Epoch 265/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0075 - accuracy: 0.9283 - val_loss: 0.1947 - val_accuracy: 0.9288\n",
      "Epoch 266/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0074 - accuracy: 0.9292 - val_loss: 0.1959 - val_accuracy: 0.9275\n",
      "Epoch 267/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0074 - accuracy: 0.9290 - val_loss: 0.1992 - val_accuracy: 0.9269\n",
      "Epoch 268/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9293 - val_loss: 0.2180 - val_accuracy: 0.9194\n",
      "Epoch 269/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9289 - val_loss: 0.1815 - val_accuracy: 0.9350\n",
      "Epoch 270/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9289 - val_loss: 0.2142 - val_accuracy: 0.9201\n",
      "Epoch 271/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9292 - val_loss: 0.1977 - val_accuracy: 0.9272\n",
      "Epoch 272/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9285 - val_loss: 0.2139 - val_accuracy: 0.9217\n",
      "Epoch 273/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9291 - val_loss: 0.2147 - val_accuracy: 0.9198\n",
      "Epoch 274/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9293 - val_loss: 0.2219 - val_accuracy: 0.9194\n",
      "Epoch 275/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0074 - accuracy: 0.9294 - val_loss: 0.1868 - val_accuracy: 0.9322\n",
      "Epoch 276/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9292 - val_loss: 0.2207 - val_accuracy: 0.9175\n",
      "Epoch 277/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9291 - val_loss: 0.1945 - val_accuracy: 0.9271\n",
      "Epoch 278/2500\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 0.0073 - accuracy: 0.9294 - val_loss: 0.1918 - val_accuracy: 0.9294\n",
      "Epoch 279/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0073 - accuracy: 0.9295 - val_loss: 0.2263 - val_accuracy: 0.9141\n",
      "Epoch 280/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9291 - val_loss: 0.2082 - val_accuracy: 0.9217\n",
      "Epoch 281/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0074 - accuracy: 0.9293 - val_loss: 0.2086 - val_accuracy: 0.9228\n",
      "Epoch 282/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9295 - val_loss: 0.1868 - val_accuracy: 0.9324\n",
      "Epoch 283/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9292 - val_loss: 0.1977 - val_accuracy: 0.9284\n",
      "Epoch 284/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9295 - val_loss: 0.2265 - val_accuracy: 0.9147\n",
      "Epoch 285/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9293 - val_loss: 0.2126 - val_accuracy: 0.9201\n",
      "Epoch 286/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0073 - accuracy: 0.9293 - val_loss: 0.2175 - val_accuracy: 0.9203\n",
      "Epoch 287/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9295 - val_loss: 0.2123 - val_accuracy: 0.9205\n",
      "Epoch 288/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9294 - val_loss: 0.1988 - val_accuracy: 0.9265\n",
      "Epoch 289/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0073 - accuracy: 0.9290 - val_loss: 0.1789 - val_accuracy: 0.9348\n",
      "Epoch 290/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9297 - val_loss: 0.1985 - val_accuracy: 0.9260\n",
      "Epoch 291/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9295 - val_loss: 0.1753 - val_accuracy: 0.9361\n",
      "Epoch 292/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9297 - val_loss: 0.2045 - val_accuracy: 0.9248\n",
      "Epoch 293/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9296 - val_loss: 0.2093 - val_accuracy: 0.9214\n",
      "Epoch 294/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9293 - val_loss: 0.1801 - val_accuracy: 0.9343\n",
      "Epoch 295/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9297 - val_loss: 0.2029 - val_accuracy: 0.9245\n",
      "Epoch 296/2500\n",
      "73/73 [==============================] - 2s 28ms/step - loss: 0.0073 - accuracy: 0.9293 - val_loss: 0.1950 - val_accuracy: 0.9283\n",
      "Epoch 297/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0073 - accuracy: 0.9294 - val_loss: 0.2147 - val_accuracy: 0.9209\n",
      "Epoch 298/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0073 - accuracy: 0.9297 - val_loss: 0.1768 - val_accuracy: 0.9365\n",
      "Epoch 299/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9296 - val_loss: 0.1800 - val_accuracy: 0.9344\n",
      "Epoch 300/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9296 - val_loss: 0.1982 - val_accuracy: 0.9266\n",
      "Epoch 301/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9298 - val_loss: 0.1899 - val_accuracy: 0.9311\n",
      "Epoch 302/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9298 - val_loss: 0.2212 - val_accuracy: 0.9169\n",
      "Epoch 303/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9296 - val_loss: 0.1784 - val_accuracy: 0.9354\n",
      "Epoch 304/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0073 - accuracy: 0.9295 - val_loss: 0.1816 - val_accuracy: 0.9342\n",
      "Epoch 305/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9296 - val_loss: 0.1932 - val_accuracy: 0.9290\n",
      "Epoch 306/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9297 - val_loss: 0.1927 - val_accuracy: 0.9305\n",
      "Epoch 307/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9299 - val_loss: 0.2001 - val_accuracy: 0.9251\n",
      "Epoch 308/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9295 - val_loss: 0.1934 - val_accuracy: 0.9291\n",
      "Epoch 309/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9300 - val_loss: 0.2386 - val_accuracy: 0.9103\n",
      "Epoch 310/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9296 - val_loss: 0.1825 - val_accuracy: 0.9328\n",
      "Epoch 311/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9295 - val_loss: 0.1958 - val_accuracy: 0.9286\n",
      "Epoch 312/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9298 - val_loss: 0.2197 - val_accuracy: 0.9179\n",
      "Epoch 313/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0073 - accuracy: 0.9296 - val_loss: 0.2057 - val_accuracy: 0.9220\n",
      "Epoch 314/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9296 - val_loss: 0.1829 - val_accuracy: 0.9337\n",
      "Epoch 315/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9297 - val_loss: 0.1987 - val_accuracy: 0.9269\n",
      "Epoch 316/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9298 - val_loss: 0.2056 - val_accuracy: 0.9247\n",
      "Epoch 317/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9298 - val_loss: 0.1994 - val_accuracy: 0.9267\n",
      "Epoch 318/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9300 - val_loss: 0.1866 - val_accuracy: 0.9314\n",
      "Epoch 319/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9300 - val_loss: 0.1774 - val_accuracy: 0.9353\n",
      "Epoch 320/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9297 - val_loss: 0.2098 - val_accuracy: 0.9211\n",
      "Epoch 321/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9298 - val_loss: 0.2134 - val_accuracy: 0.9209\n",
      "Epoch 322/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9297 - val_loss: 0.1854 - val_accuracy: 0.9333\n",
      "Epoch 323/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9300 - val_loss: 0.2006 - val_accuracy: 0.9245\n",
      "Epoch 324/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9300 - val_loss: 0.2144 - val_accuracy: 0.9213\n",
      "Epoch 325/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9299 - val_loss: 0.2112 - val_accuracy: 0.9225\n",
      "Epoch 326/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9300 - val_loss: 0.2400 - val_accuracy: 0.9094\n",
      "Epoch 327/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9297 - val_loss: 0.1697 - val_accuracy: 0.9388\n",
      "Epoch 328/2500\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 0.0073 - accuracy: 0.9302 - val_loss: 0.1847 - val_accuracy: 0.9325\n",
      "Epoch 329/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0073 - accuracy: 0.9297 - val_loss: 0.1863 - val_accuracy: 0.9318\n",
      "Epoch 330/2500\n",
      "73/73 [==============================] - 2s 27ms/step - loss: 0.0073 - accuracy: 0.9299 - val_loss: 0.1842 - val_accuracy: 0.9338\n",
      "Epoch 331/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9301 - val_loss: 0.1827 - val_accuracy: 0.9331\n",
      "Epoch 332/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0073 - accuracy: 0.9300 - val_loss: 0.2084 - val_accuracy: 0.9227\n",
      "Epoch 333/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0073 - accuracy: 0.9297 - val_loss: 0.2406 - val_accuracy: 0.9066\n",
      "Epoch 334/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0073 - accuracy: 0.9299 - val_loss: 0.1970 - val_accuracy: 0.9273\n",
      "Epoch 335/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9299 - val_loss: 0.2026 - val_accuracy: 0.9253\n",
      "Epoch 336/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9300 - val_loss: 0.2338 - val_accuracy: 0.9121\n",
      "Epoch 337/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0073 - accuracy: 0.9298 - val_loss: 0.1812 - val_accuracy: 0.9343\n",
      "Epoch 338/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9302 - val_loss: 0.1825 - val_accuracy: 0.9328\n",
      "Epoch 339/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9301 - val_loss: 0.2092 - val_accuracy: 0.9226\n",
      "Epoch 340/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9300 - val_loss: 0.2368 - val_accuracy: 0.9111\n",
      "Epoch 341/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9298 - val_loss: 0.2139 - val_accuracy: 0.9202\n",
      "Epoch 342/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9300 - val_loss: 0.1906 - val_accuracy: 0.9305\n",
      "Epoch 343/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9299 - val_loss: 0.1956 - val_accuracy: 0.9273\n",
      "Epoch 344/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9303 - val_loss: 0.1980 - val_accuracy: 0.9272\n",
      "Epoch 345/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9301 - val_loss: 0.2025 - val_accuracy: 0.9248\n",
      "Epoch 346/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9296 - val_loss: 0.1936 - val_accuracy: 0.9292\n",
      "Epoch 347/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9299 - val_loss: 0.2066 - val_accuracy: 0.9235\n",
      "Epoch 348/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9301 - val_loss: 0.2082 - val_accuracy: 0.9223\n",
      "Epoch 349/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9301 - val_loss: 0.2006 - val_accuracy: 0.9257\n",
      "Epoch 350/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9301 - val_loss: 0.1910 - val_accuracy: 0.9296\n",
      "Epoch 351/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9299 - val_loss: 0.1922 - val_accuracy: 0.9293\n",
      "Epoch 352/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9303 - val_loss: 0.2314 - val_accuracy: 0.9132\n",
      "Epoch 353/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0072 - accuracy: 0.9300 - val_loss: 0.1826 - val_accuracy: 0.9318\n",
      "Epoch 354/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9301 - val_loss: 0.1894 - val_accuracy: 0.9301\n",
      "Epoch 355/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9300 - val_loss: 0.1967 - val_accuracy: 0.9275\n",
      "Epoch 356/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0072 - accuracy: 0.9302 - val_loss: 0.1895 - val_accuracy: 0.9298\n",
      "Epoch 357/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9300 - val_loss: 0.2000 - val_accuracy: 0.9259\n",
      "Epoch 358/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9300 - val_loss: 0.2324 - val_accuracy: 0.9123\n",
      "Epoch 359/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9300 - val_loss: 0.2192 - val_accuracy: 0.9153\n",
      "Epoch 360/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9303 - val_loss: 0.2021 - val_accuracy: 0.9255\n",
      "Epoch 361/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9301 - val_loss: 0.1824 - val_accuracy: 0.9330\n",
      "Epoch 362/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9303 - val_loss: 0.2011 - val_accuracy: 0.9246\n",
      "Epoch 363/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9300 - val_loss: 0.1908 - val_accuracy: 0.9295\n",
      "Epoch 364/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9294 - val_loss: 0.1766 - val_accuracy: 0.9367\n",
      "Epoch 365/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9301 - val_loss: 0.2108 - val_accuracy: 0.9211\n",
      "Epoch 366/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9303 - val_loss: 0.2046 - val_accuracy: 0.9245\n",
      "Epoch 367/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9302 - val_loss: 0.1854 - val_accuracy: 0.9329\n",
      "Epoch 368/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9303 - val_loss: 0.2171 - val_accuracy: 0.9190\n",
      "Epoch 369/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9300 - val_loss: 0.2057 - val_accuracy: 0.9265\n",
      "Epoch 370/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9299 - val_loss: 0.2238 - val_accuracy: 0.9155\n",
      "Epoch 371/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9299 - val_loss: 0.2153 - val_accuracy: 0.9189\n",
      "Epoch 372/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9300 - val_loss: 0.1779 - val_accuracy: 0.9357\n",
      "Epoch 373/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9300 - val_loss: 0.1969 - val_accuracy: 0.9275\n",
      "Epoch 374/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0072 - accuracy: 0.9303 - val_loss: 0.1877 - val_accuracy: 0.9303\n",
      "Epoch 375/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9303 - val_loss: 0.2061 - val_accuracy: 0.9230\n",
      "Epoch 376/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9300 - val_loss: 0.2054 - val_accuracy: 0.9249\n",
      "Epoch 377/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9303 - val_loss: 0.2143 - val_accuracy: 0.9208\n",
      "Epoch 378/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9304 - val_loss: 0.1909 - val_accuracy: 0.9287\n",
      "Epoch 379/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9303 - val_loss: 0.2143 - val_accuracy: 0.9203\n",
      "Epoch 380/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9303 - val_loss: 0.1994 - val_accuracy: 0.9267\n",
      "Epoch 381/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9304 - val_loss: 0.1949 - val_accuracy: 0.9285\n",
      "Epoch 382/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9304 - val_loss: 0.1754 - val_accuracy: 0.9353\n",
      "Epoch 383/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9302 - val_loss: 0.1930 - val_accuracy: 0.9275\n",
      "Epoch 384/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9300 - val_loss: 0.1994 - val_accuracy: 0.9259\n",
      "Epoch 385/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9304 - val_loss: 0.2386 - val_accuracy: 0.9097\n",
      "Epoch 386/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9303 - val_loss: 0.1975 - val_accuracy: 0.9273\n",
      "Epoch 387/2500\n",
      "73/73 [==============================] - 2s 28ms/step - loss: 0.0072 - accuracy: 0.9300 - val_loss: 0.1950 - val_accuracy: 0.9278\n",
      "Epoch 388/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9303 - val_loss: 0.2227 - val_accuracy: 0.9158\n",
      "Epoch 389/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9301 - val_loss: 0.1843 - val_accuracy: 0.9315\n",
      "Epoch 390/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9304 - val_loss: 0.1834 - val_accuracy: 0.9326\n",
      "Epoch 391/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9306 - val_loss: 0.2235 - val_accuracy: 0.9162\n",
      "Epoch 392/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9301 - val_loss: 0.1967 - val_accuracy: 0.9276\n",
      "Epoch 393/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9302 - val_loss: 0.1890 - val_accuracy: 0.9298\n",
      "Epoch 394/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9303 - val_loss: 0.1852 - val_accuracy: 0.9323\n",
      "Epoch 395/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9303 - val_loss: 0.1857 - val_accuracy: 0.9329\n",
      "Epoch 396/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9305 - val_loss: 0.2081 - val_accuracy: 0.9226\n",
      "Epoch 397/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9304 - val_loss: 0.1936 - val_accuracy: 0.9289\n",
      "Epoch 398/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9301 - val_loss: 0.1866 - val_accuracy: 0.9321\n",
      "Epoch 399/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9307 - val_loss: 0.1954 - val_accuracy: 0.9269\n",
      "Epoch 400/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0072 - accuracy: 0.9301 - val_loss: 0.1943 - val_accuracy: 0.9284\n",
      "Epoch 401/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9304 - val_loss: 0.1830 - val_accuracy: 0.9329\n",
      "Epoch 402/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9304 - val_loss: 0.1846 - val_accuracy: 0.9311\n",
      "Epoch 403/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9302 - val_loss: 0.1816 - val_accuracy: 0.9324\n",
      "Epoch 404/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9304 - val_loss: 0.1999 - val_accuracy: 0.9262\n",
      "Epoch 405/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9303 - val_loss: 0.1877 - val_accuracy: 0.9313\n",
      "Epoch 406/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9307 - val_loss: 0.2307 - val_accuracy: 0.9138\n",
      "Epoch 407/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9306 - val_loss: 0.2059 - val_accuracy: 0.9226\n",
      "Epoch 408/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9305 - val_loss: 0.1973 - val_accuracy: 0.9266\n",
      "Epoch 409/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9300 - val_loss: 0.1697 - val_accuracy: 0.9383\n",
      "Epoch 410/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9305 - val_loss: 0.2397 - val_accuracy: 0.9095\n",
      "Epoch 411/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9302 - val_loss: 0.1993 - val_accuracy: 0.9264\n",
      "Epoch 412/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9299 - val_loss: 0.2222 - val_accuracy: 0.9167\n",
      "Epoch 413/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9305 - val_loss: 0.1956 - val_accuracy: 0.9273\n",
      "Epoch 414/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0072 - accuracy: 0.9301 - val_loss: 0.1804 - val_accuracy: 0.9343\n",
      "Epoch 415/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9305 - val_loss: 0.1867 - val_accuracy: 0.9318\n",
      "Epoch 416/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9301 - val_loss: 0.1873 - val_accuracy: 0.9310\n",
      "Epoch 417/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9305 - val_loss: 0.2091 - val_accuracy: 0.9231\n",
      "Epoch 418/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9306 - val_loss: 0.2063 - val_accuracy: 0.9225\n",
      "Epoch 419/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9305 - val_loss: 0.1721 - val_accuracy: 0.9369\n",
      "Epoch 420/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9304 - val_loss: 0.1871 - val_accuracy: 0.9310\n",
      "Epoch 421/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9303 - val_loss: 0.2009 - val_accuracy: 0.9251\n",
      "Epoch 422/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9303 - val_loss: 0.1878 - val_accuracy: 0.9310\n",
      "Epoch 423/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9307 - val_loss: 0.2089 - val_accuracy: 0.9224\n",
      "Epoch 424/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0071 - accuracy: 0.9305 - val_loss: 0.1978 - val_accuracy: 0.9254\n",
      "Epoch 425/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9303 - val_loss: 0.2044 - val_accuracy: 0.9245\n",
      "Epoch 426/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0071 - accuracy: 0.9304 - val_loss: 0.1900 - val_accuracy: 0.9294\n",
      "Epoch 427/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9302 - val_loss: 0.1873 - val_accuracy: 0.9303\n",
      "Epoch 428/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9307 - val_loss: 0.2330 - val_accuracy: 0.9129\n",
      "Epoch 429/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9304 - val_loss: 0.2212 - val_accuracy: 0.9164\n",
      "Epoch 430/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9299 - val_loss: 0.2190 - val_accuracy: 0.9166\n",
      "Epoch 431/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9293 - val_loss: 0.1860 - val_accuracy: 0.9321\n",
      "Epoch 432/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9304 - val_loss: 0.1933 - val_accuracy: 0.9288\n",
      "Epoch 433/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0071 - accuracy: 0.9307 - val_loss: 0.1901 - val_accuracy: 0.9279\n",
      "Epoch 434/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9305 - val_loss: 0.1907 - val_accuracy: 0.9301\n",
      "Epoch 435/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9304 - val_loss: 0.1864 - val_accuracy: 0.9311\n",
      "Epoch 436/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9305 - val_loss: 0.2080 - val_accuracy: 0.9209\n",
      "Epoch 437/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9306 - val_loss: 0.1869 - val_accuracy: 0.9311\n",
      "Epoch 438/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9305 - val_loss: 0.2157 - val_accuracy: 0.9193\n",
      "Epoch 439/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9305 - val_loss: 0.1719 - val_accuracy: 0.9371\n",
      "Epoch 440/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9306 - val_loss: 0.1724 - val_accuracy: 0.9379\n",
      "Epoch 441/2500\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 0.0071 - accuracy: 0.9303 - val_loss: 0.2031 - val_accuracy: 0.9243\n",
      "Epoch 442/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0072 - accuracy: 0.9305 - val_loss: 0.1959 - val_accuracy: 0.9278\n",
      "Epoch 443/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9307 - val_loss: 0.1909 - val_accuracy: 0.9282\n",
      "Epoch 444/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9306 - val_loss: 0.1974 - val_accuracy: 0.9258\n",
      "Epoch 445/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9306 - val_loss: 0.1824 - val_accuracy: 0.9334\n",
      "Epoch 446/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9305 - val_loss: 0.1875 - val_accuracy: 0.9320\n",
      "Epoch 447/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9304 - val_loss: 0.1834 - val_accuracy: 0.9324\n",
      "Epoch 448/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9307 - val_loss: 0.1948 - val_accuracy: 0.9265\n",
      "Epoch 449/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9304 - val_loss: 0.1909 - val_accuracy: 0.9290\n",
      "Epoch 450/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9308 - val_loss: 0.1961 - val_accuracy: 0.9265\n",
      "Epoch 451/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9305 - val_loss: 0.1846 - val_accuracy: 0.9313\n",
      "Epoch 452/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9306 - val_loss: 0.1894 - val_accuracy: 0.9308\n",
      "Epoch 453/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9307 - val_loss: 0.1974 - val_accuracy: 0.9274\n",
      "Epoch 454/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9302 - val_loss: 0.1984 - val_accuracy: 0.9261\n",
      "Epoch 455/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9307 - val_loss: 0.1889 - val_accuracy: 0.9304\n",
      "Epoch 456/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9305 - val_loss: 0.2074 - val_accuracy: 0.9234\n",
      "Epoch 457/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9308 - val_loss: 0.1853 - val_accuracy: 0.9311\n",
      "Epoch 458/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9305 - val_loss: 0.1925 - val_accuracy: 0.9274\n",
      "Epoch 459/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9308 - val_loss: 0.1899 - val_accuracy: 0.9285\n",
      "Epoch 460/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0071 - accuracy: 0.9301 - val_loss: 0.1889 - val_accuracy: 0.9304\n",
      "Epoch 461/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0071 - accuracy: 0.9307 - val_loss: 0.2119 - val_accuracy: 0.9186\n",
      "Epoch 462/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9304 - val_loss: 0.2198 - val_accuracy: 0.9183\n",
      "Epoch 463/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9308 - val_loss: 0.2126 - val_accuracy: 0.9192\n",
      "Epoch 464/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9309 - val_loss: 0.1683 - val_accuracy: 0.9384\n",
      "Epoch 465/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9307 - val_loss: 0.2007 - val_accuracy: 0.9254\n",
      "Epoch 466/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9303 - val_loss: 0.2034 - val_accuracy: 0.9232\n",
      "Epoch 467/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0071 - accuracy: 0.9304 - val_loss: 0.1864 - val_accuracy: 0.9317\n",
      "Epoch 468/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0071 - accuracy: 0.9311 - val_loss: 0.1765 - val_accuracy: 0.9352\n",
      "Epoch 469/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9305 - val_loss: 0.1744 - val_accuracy: 0.9356\n",
      "Epoch 470/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9308 - val_loss: 0.2071 - val_accuracy: 0.9223\n",
      "Epoch 471/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9306 - val_loss: 0.1857 - val_accuracy: 0.9316\n",
      "Epoch 472/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9308 - val_loss: 0.1776 - val_accuracy: 0.9345\n",
      "Epoch 473/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9308 - val_loss: 0.2181 - val_accuracy: 0.9188\n",
      "Epoch 474/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9305 - val_loss: 0.2024 - val_accuracy: 0.9239\n",
      "Epoch 475/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9308 - val_loss: 0.2063 - val_accuracy: 0.9216\n",
      "Epoch 476/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9307 - val_loss: 0.1876 - val_accuracy: 0.9307\n",
      "Epoch 477/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9307 - val_loss: 0.1871 - val_accuracy: 0.9324\n",
      "Epoch 478/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0072 - accuracy: 0.9301 - val_loss: 0.2067 - val_accuracy: 0.9247\n",
      "Epoch 479/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9309 - val_loss: 0.1840 - val_accuracy: 0.9323\n",
      "Epoch 480/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9307 - val_loss: 0.1997 - val_accuracy: 0.9257\n",
      "Epoch 481/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9307 - val_loss: 0.2092 - val_accuracy: 0.9215\n",
      "Epoch 482/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0071 - accuracy: 0.9307 - val_loss: 0.2170 - val_accuracy: 0.9187\n",
      "Epoch 483/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9305 - val_loss: 0.1924 - val_accuracy: 0.9290\n",
      "Epoch 484/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9310 - val_loss: 0.1787 - val_accuracy: 0.9347\n",
      "Epoch 485/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9307 - val_loss: 0.1771 - val_accuracy: 0.9350\n",
      "Epoch 486/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9306 - val_loss: 0.1845 - val_accuracy: 0.9324\n",
      "Epoch 487/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9310 - val_loss: 0.1896 - val_accuracy: 0.9298\n",
      "Epoch 488/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9310 - val_loss: 0.1878 - val_accuracy: 0.9315\n",
      "Epoch 489/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9310 - val_loss: 0.1985 - val_accuracy: 0.9260\n",
      "Epoch 490/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9308 - val_loss: 0.1885 - val_accuracy: 0.9303\n",
      "Epoch 491/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9308 - val_loss: 0.1867 - val_accuracy: 0.9315\n",
      "Epoch 492/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9310 - val_loss: 0.1886 - val_accuracy: 0.9293\n",
      "Epoch 493/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9309 - val_loss: 0.1796 - val_accuracy: 0.9339\n",
      "Epoch 494/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9307 - val_loss: 0.1712 - val_accuracy: 0.9368\n",
      "Epoch 495/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9308 - val_loss: 0.1765 - val_accuracy: 0.9350\n",
      "Epoch 496/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9310 - val_loss: 0.2205 - val_accuracy: 0.9166\n",
      "Epoch 497/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9306 - val_loss: 0.2041 - val_accuracy: 0.9227\n",
      "Epoch 498/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9307 - val_loss: 0.1926 - val_accuracy: 0.9284\n",
      "Epoch 499/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9308 - val_loss: 0.2073 - val_accuracy: 0.9220\n",
      "Epoch 500/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9306 - val_loss: 0.1967 - val_accuracy: 0.9280\n",
      "Epoch 501/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9309 - val_loss: 0.1802 - val_accuracy: 0.9350\n",
      "Epoch 502/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9310 - val_loss: 0.1791 - val_accuracy: 0.9337\n",
      "Epoch 503/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9311 - val_loss: 0.1889 - val_accuracy: 0.9312\n",
      "Epoch 504/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9309 - val_loss: 0.2126 - val_accuracy: 0.9201\n",
      "Epoch 505/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0071 - accuracy: 0.9310 - val_loss: 0.1953 - val_accuracy: 0.9276\n",
      "Epoch 506/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0071 - accuracy: 0.9312 - val_loss: 0.2063 - val_accuracy: 0.9233\n",
      "Epoch 507/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9310 - val_loss: 0.1987 - val_accuracy: 0.9267\n",
      "Epoch 508/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9311 - val_loss: 0.2040 - val_accuracy: 0.9239\n",
      "Epoch 509/2500\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 0.0071 - accuracy: 0.9308 - val_loss: 0.2003 - val_accuracy: 0.9257\n",
      "Epoch 510/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9311 - val_loss: 0.2019 - val_accuracy: 0.9240\n",
      "Epoch 511/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9308 - val_loss: 0.2092 - val_accuracy: 0.9214\n",
      "Epoch 512/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9309 - val_loss: 0.2204 - val_accuracy: 0.9166\n",
      "Epoch 513/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9310 - val_loss: 0.1820 - val_accuracy: 0.9327\n",
      "Epoch 514/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9310 - val_loss: 0.1826 - val_accuracy: 0.9329\n",
      "Epoch 515/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9312 - val_loss: 0.1944 - val_accuracy: 0.9268\n",
      "Epoch 516/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9308 - val_loss: 0.2042 - val_accuracy: 0.9241\n",
      "Epoch 517/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9308 - val_loss: 0.2093 - val_accuracy: 0.9220\n",
      "Epoch 518/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9313 - val_loss: 0.1873 - val_accuracy: 0.9301\n",
      "Epoch 519/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9308 - val_loss: 0.1824 - val_accuracy: 0.9326\n",
      "Epoch 520/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9304 - val_loss: 0.2058 - val_accuracy: 0.9223\n",
      "Epoch 521/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0071 - accuracy: 0.9309 - val_loss: 0.1809 - val_accuracy: 0.9338\n",
      "Epoch 522/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9310 - val_loss: 0.1833 - val_accuracy: 0.9326\n",
      "Epoch 523/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9310 - val_loss: 0.2129 - val_accuracy: 0.9202\n",
      "Epoch 524/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9311 - val_loss: 0.1907 - val_accuracy: 0.9299\n",
      "Epoch 525/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9307 - val_loss: 0.1916 - val_accuracy: 0.9291\n",
      "Epoch 526/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9310 - val_loss: 0.2114 - val_accuracy: 0.9209\n",
      "Epoch 527/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9311 - val_loss: 0.1741 - val_accuracy: 0.9358\n",
      "Epoch 528/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9309 - val_loss: 0.1857 - val_accuracy: 0.9312\n",
      "Epoch 529/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.2038 - val_accuracy: 0.9231\n",
      "Epoch 530/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0070 - accuracy: 0.9308 - val_loss: 0.1927 - val_accuracy: 0.9285\n",
      "Epoch 531/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9310 - val_loss: 0.1807 - val_accuracy: 0.9336\n",
      "Epoch 532/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9311 - val_loss: 0.1940 - val_accuracy: 0.9282\n",
      "Epoch 533/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9311 - val_loss: 0.1841 - val_accuracy: 0.9322\n",
      "Epoch 534/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9311 - val_loss: 0.1830 - val_accuracy: 0.9320\n",
      "Epoch 535/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9311 - val_loss: 0.2125 - val_accuracy: 0.9197\n",
      "Epoch 536/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0070 - accuracy: 0.9307 - val_loss: 0.2014 - val_accuracy: 0.9245\n",
      "Epoch 537/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9307 - val_loss: 0.1891 - val_accuracy: 0.9303\n",
      "Epoch 538/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9308 - val_loss: 0.1783 - val_accuracy: 0.9338\n",
      "Epoch 539/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9310 - val_loss: 0.2004 - val_accuracy: 0.9250\n",
      "Epoch 540/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0071 - accuracy: 0.9309 - val_loss: 0.1796 - val_accuracy: 0.9335\n",
      "Epoch 541/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9310 - val_loss: 0.2081 - val_accuracy: 0.9218\n",
      "Epoch 542/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9309 - val_loss: 0.2027 - val_accuracy: 0.9235\n",
      "Epoch 543/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.1913 - val_accuracy: 0.9284\n",
      "Epoch 544/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9308 - val_loss: 0.2055 - val_accuracy: 0.9230\n",
      "Epoch 545/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9311 - val_loss: 0.1917 - val_accuracy: 0.9281\n",
      "Epoch 546/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9310 - val_loss: 0.2023 - val_accuracy: 0.9250\n",
      "Epoch 547/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9311 - val_loss: 0.2236 - val_accuracy: 0.9139\n",
      "Epoch 548/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9313 - val_loss: 0.2037 - val_accuracy: 0.9239\n",
      "Epoch 549/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9313 - val_loss: 0.2107 - val_accuracy: 0.9200\n",
      "Epoch 550/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9311 - val_loss: 0.1738 - val_accuracy: 0.9354\n",
      "Epoch 551/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9311 - val_loss: 0.1764 - val_accuracy: 0.9351\n",
      "Epoch 552/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.1822 - val_accuracy: 0.9329\n",
      "Epoch 553/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9313 - val_loss: 0.1819 - val_accuracy: 0.9318\n",
      "Epoch 554/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0070 - accuracy: 0.9311 - val_loss: 0.1829 - val_accuracy: 0.9323\n",
      "Epoch 555/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9311 - val_loss: 0.1931 - val_accuracy: 0.9282\n",
      "Epoch 556/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9310 - val_loss: 0.1768 - val_accuracy: 0.9350\n",
      "Epoch 557/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9313 - val_loss: 0.2038 - val_accuracy: 0.9234\n",
      "Epoch 558/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9308 - val_loss: 0.1840 - val_accuracy: 0.9309\n",
      "Epoch 559/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9310 - val_loss: 0.2076 - val_accuracy: 0.9230\n",
      "Epoch 560/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9311 - val_loss: 0.1787 - val_accuracy: 0.9341\n",
      "Epoch 561/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.2009 - val_accuracy: 0.9253\n",
      "Epoch 562/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9310 - val_loss: 0.1988 - val_accuracy: 0.9258\n",
      "Epoch 563/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.1910 - val_accuracy: 0.9297\n",
      "Epoch 564/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9309 - val_loss: 0.1960 - val_accuracy: 0.9271\n",
      "Epoch 565/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9311 - val_loss: 0.1901 - val_accuracy: 0.9287\n",
      "Epoch 566/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9311 - val_loss: 0.1858 - val_accuracy: 0.9316\n",
      "Epoch 567/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9309 - val_loss: 0.1706 - val_accuracy: 0.9372\n",
      "Epoch 568/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9309 - val_loss: 0.2056 - val_accuracy: 0.9234\n",
      "Epoch 569/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9311 - val_loss: 0.1724 - val_accuracy: 0.9363\n",
      "Epoch 570/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0070 - accuracy: 0.9309 - val_loss: 0.1717 - val_accuracy: 0.9374\n",
      "Epoch 571/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9314 - val_loss: 0.2082 - val_accuracy: 0.9217\n",
      "Epoch 572/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0070 - accuracy: 0.9311 - val_loss: 0.1916 - val_accuracy: 0.9276\n",
      "Epoch 573/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9310 - val_loss: 0.1908 - val_accuracy: 0.9300\n",
      "Epoch 574/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0070 - accuracy: 0.9314 - val_loss: 0.1765 - val_accuracy: 0.9342\n",
      "Epoch 575/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9310 - val_loss: 0.2056 - val_accuracy: 0.9237\n",
      "Epoch 576/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9310 - val_loss: 0.1989 - val_accuracy: 0.9251\n",
      "Epoch 577/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9309 - val_loss: 0.1714 - val_accuracy: 0.9364\n",
      "Epoch 578/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9313 - val_loss: 0.1825 - val_accuracy: 0.9322\n",
      "Epoch 579/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9306 - val_loss: 0.1991 - val_accuracy: 0.9248\n",
      "Epoch 580/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0070 - accuracy: 0.9310 - val_loss: 0.1687 - val_accuracy: 0.9381\n",
      "Epoch 581/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9308 - val_loss: 0.1865 - val_accuracy: 0.9306\n",
      "Epoch 582/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.1785 - val_accuracy: 0.9335\n",
      "Epoch 583/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9311 - val_loss: 0.2133 - val_accuracy: 0.9196\n",
      "Epoch 584/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9308 - val_loss: 0.1876 - val_accuracy: 0.9285\n",
      "Epoch 585/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9311 - val_loss: 0.2064 - val_accuracy: 0.9210\n",
      "Epoch 586/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0070 - accuracy: 0.9308 - val_loss: 0.1966 - val_accuracy: 0.9263\n",
      "Epoch 587/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.2089 - val_accuracy: 0.9204\n",
      "Epoch 588/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.1909 - val_accuracy: 0.9282\n",
      "Epoch 589/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9311 - val_loss: 0.1994 - val_accuracy: 0.9250\n",
      "Epoch 590/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9314 - val_loss: 0.2062 - val_accuracy: 0.9228\n",
      "Epoch 591/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.2179 - val_accuracy: 0.9187\n",
      "Epoch 592/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.1843 - val_accuracy: 0.9316\n",
      "Epoch 593/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9313 - val_loss: 0.1996 - val_accuracy: 0.9248\n",
      "Epoch 594/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9309 - val_loss: 0.1864 - val_accuracy: 0.9312\n",
      "Epoch 595/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9314 - val_loss: 0.2000 - val_accuracy: 0.9247\n",
      "Epoch 596/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9309 - val_loss: 0.1667 - val_accuracy: 0.9379\n",
      "Epoch 597/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9309 - val_loss: 0.1895 - val_accuracy: 0.9309\n",
      "Epoch 598/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9313 - val_loss: 0.2190 - val_accuracy: 0.9166\n",
      "Epoch 599/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0070 - accuracy: 0.9310 - val_loss: 0.1950 - val_accuracy: 0.9258\n",
      "Epoch 600/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9309 - val_loss: 0.1746 - val_accuracy: 0.9353\n",
      "Epoch 601/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9311 - val_loss: 0.1822 - val_accuracy: 0.9327\n",
      "Epoch 602/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9314 - val_loss: 0.1932 - val_accuracy: 0.9279\n",
      "Epoch 603/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.1866 - val_accuracy: 0.9313\n",
      "Epoch 604/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9314 - val_loss: 0.2078 - val_accuracy: 0.9214\n",
      "Epoch 605/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9310 - val_loss: 0.1794 - val_accuracy: 0.9332\n",
      "Epoch 606/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9310 - val_loss: 0.1930 - val_accuracy: 0.9283\n",
      "Epoch 607/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.1738 - val_accuracy: 0.9357\n",
      "Epoch 608/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9311 - val_loss: 0.1913 - val_accuracy: 0.9285\n",
      "Epoch 609/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.2131 - val_accuracy: 0.9194\n",
      "Epoch 610/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9314 - val_loss: 0.2377 - val_accuracy: 0.9096\n",
      "Epoch 611/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.1926 - val_accuracy: 0.9271\n",
      "Epoch 612/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9313 - val_loss: 0.2094 - val_accuracy: 0.9226\n",
      "Epoch 613/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9309 - val_loss: 0.1878 - val_accuracy: 0.9307\n",
      "Epoch 614/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9310 - val_loss: 0.1860 - val_accuracy: 0.9292\n",
      "Epoch 615/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9311 - val_loss: 0.2002 - val_accuracy: 0.9265\n",
      "Epoch 616/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9309 - val_loss: 0.1655 - val_accuracy: 0.9391\n",
      "Epoch 617/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.2013 - val_accuracy: 0.9255\n",
      "Epoch 618/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9313 - val_loss: 0.1830 - val_accuracy: 0.9323\n",
      "Epoch 619/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9313 - val_loss: 0.1787 - val_accuracy: 0.9344\n",
      "Epoch 620/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9311 - val_loss: 0.1804 - val_accuracy: 0.9330\n",
      "Epoch 621/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.1975 - val_accuracy: 0.9266\n",
      "Epoch 622/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0070 - accuracy: 0.9309 - val_loss: 0.1703 - val_accuracy: 0.9361\n",
      "Epoch 623/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.1966 - val_accuracy: 0.9280\n",
      "Epoch 624/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0070 - accuracy: 0.9313 - val_loss: 0.1778 - val_accuracy: 0.9349\n",
      "Epoch 625/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9314 - val_loss: 0.1775 - val_accuracy: 0.9349\n",
      "Epoch 626/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.1904 - val_accuracy: 0.9278\n",
      "Epoch 627/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9317 - val_loss: 0.1904 - val_accuracy: 0.9285\n",
      "Epoch 628/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0070 - accuracy: 0.9310 - val_loss: 0.1746 - val_accuracy: 0.9352\n",
      "Epoch 629/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9314 - val_loss: 0.1833 - val_accuracy: 0.9321\n",
      "Epoch 630/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9311 - val_loss: 0.1774 - val_accuracy: 0.9352\n",
      "Epoch 631/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.1840 - val_accuracy: 0.9317\n",
      "Epoch 632/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9313 - val_loss: 0.1871 - val_accuracy: 0.9292\n",
      "Epoch 633/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9308 - val_loss: 0.1791 - val_accuracy: 0.9343\n",
      "Epoch 634/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9311 - val_loss: 0.1795 - val_accuracy: 0.9332\n",
      "Epoch 635/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9314 - val_loss: 0.1834 - val_accuracy: 0.9316\n",
      "Epoch 636/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9313 - val_loss: 0.2255 - val_accuracy: 0.9148\n",
      "Epoch 637/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9313 - val_loss: 0.1933 - val_accuracy: 0.9270\n",
      "Epoch 638/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.1973 - val_accuracy: 0.9261\n",
      "Epoch 639/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9315 - val_loss: 0.2157 - val_accuracy: 0.9179\n",
      "Epoch 640/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9314 - val_loss: 0.2061 - val_accuracy: 0.9221\n",
      "Epoch 641/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9313 - val_loss: 0.1899 - val_accuracy: 0.9295\n",
      "Epoch 642/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9313 - val_loss: 0.1793 - val_accuracy: 0.9341\n",
      "Epoch 643/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.1909 - val_accuracy: 0.9284\n",
      "Epoch 644/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9314 - val_loss: 0.1998 - val_accuracy: 0.9255\n",
      "Epoch 645/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9314 - val_loss: 0.1867 - val_accuracy: 0.9297\n",
      "Epoch 646/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9313 - val_loss: 0.1869 - val_accuracy: 0.9314\n",
      "Epoch 647/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.1989 - val_accuracy: 0.9245\n",
      "Epoch 648/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9314 - val_loss: 0.1808 - val_accuracy: 0.9339\n",
      "Epoch 649/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9316 - val_loss: 0.1981 - val_accuracy: 0.9258\n",
      "Epoch 650/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9314 - val_loss: 0.1925 - val_accuracy: 0.9287\n",
      "Epoch 651/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9313 - val_loss: 0.2032 - val_accuracy: 0.9235\n",
      "Epoch 652/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9315 - val_loss: 0.1893 - val_accuracy: 0.9299\n",
      "Epoch 653/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9315 - val_loss: 0.1842 - val_accuracy: 0.9298\n",
      "Epoch 654/2500\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 0.0070 - accuracy: 0.9313 - val_loss: 0.1917 - val_accuracy: 0.9280\n",
      "Epoch 655/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0069 - accuracy: 0.9314 - val_loss: 0.2073 - val_accuracy: 0.9227\n",
      "Epoch 656/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9315 - val_loss: 0.1833 - val_accuracy: 0.9323\n",
      "Epoch 657/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9314 - val_loss: 0.1895 - val_accuracy: 0.9290\n",
      "Epoch 658/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9313 - val_loss: 0.1931 - val_accuracy: 0.9280\n",
      "Epoch 659/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0070 - accuracy: 0.9315 - val_loss: 0.1824 - val_accuracy: 0.9324\n",
      "Epoch 660/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.1734 - val_accuracy: 0.9354\n",
      "Epoch 661/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9315 - val_loss: 0.1911 - val_accuracy: 0.9286\n",
      "Epoch 662/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.1843 - val_accuracy: 0.9312\n",
      "Epoch 663/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9314 - val_loss: 0.1729 - val_accuracy: 0.9359\n",
      "Epoch 664/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.1860 - val_accuracy: 0.9308\n",
      "Epoch 665/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9314 - val_loss: 0.1772 - val_accuracy: 0.9331\n",
      "Epoch 666/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9313 - val_loss: 0.1906 - val_accuracy: 0.9282\n",
      "Epoch 667/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.1973 - val_accuracy: 0.9256\n",
      "Epoch 668/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.1893 - val_accuracy: 0.9296\n",
      "Epoch 669/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0069 - accuracy: 0.9314 - val_loss: 0.1831 - val_accuracy: 0.9328\n",
      "Epoch 670/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.1983 - val_accuracy: 0.9252\n",
      "Epoch 671/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9314 - val_loss: 0.1929 - val_accuracy: 0.9286\n",
      "Epoch 672/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9312 - val_loss: 0.1742 - val_accuracy: 0.9352\n",
      "Epoch 673/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.1874 - val_accuracy: 0.9299\n",
      "Epoch 674/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.1868 - val_accuracy: 0.9298\n",
      "Epoch 675/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.1869 - val_accuracy: 0.9313\n",
      "Epoch 676/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.1865 - val_accuracy: 0.9305\n",
      "Epoch 677/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.1951 - val_accuracy: 0.9271\n",
      "Epoch 678/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.1952 - val_accuracy: 0.9268\n",
      "Epoch 679/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9315 - val_loss: 0.1803 - val_accuracy: 0.9334\n",
      "Epoch 680/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.1954 - val_accuracy: 0.9256\n",
      "Epoch 681/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9315 - val_loss: 0.1860 - val_accuracy: 0.9305\n",
      "Epoch 682/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.1766 - val_accuracy: 0.9342\n",
      "Epoch 683/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9315 - val_loss: 0.1872 - val_accuracy: 0.9302\n",
      "Epoch 684/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9318 - val_loss: 0.1701 - val_accuracy: 0.9368\n",
      "Epoch 685/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.1706 - val_accuracy: 0.9374\n",
      "Epoch 686/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9315 - val_loss: 0.1912 - val_accuracy: 0.9284\n",
      "Epoch 687/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.1783 - val_accuracy: 0.9324\n",
      "Epoch 688/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9313 - val_loss: 0.2168 - val_accuracy: 0.9187\n",
      "Epoch 689/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.1840 - val_accuracy: 0.9316\n",
      "Epoch 690/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.2009 - val_accuracy: 0.9236\n",
      "Epoch 691/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9313 - val_loss: 0.1848 - val_accuracy: 0.9310\n",
      "Epoch 692/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9315 - val_loss: 0.1779 - val_accuracy: 0.9337\n",
      "Epoch 693/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.1802 - val_accuracy: 0.9316\n",
      "Epoch 694/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.1961 - val_accuracy: 0.9267\n",
      "Epoch 695/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.1757 - val_accuracy: 0.9355\n",
      "Epoch 696/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9318 - val_loss: 0.1708 - val_accuracy: 0.9358\n",
      "Epoch 697/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.1904 - val_accuracy: 0.9291\n",
      "Epoch 698/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0070 - accuracy: 0.9314 - val_loss: 0.1792 - val_accuracy: 0.9344\n",
      "Epoch 699/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.2026 - val_accuracy: 0.9239\n",
      "Epoch 700/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.1863 - val_accuracy: 0.9312\n",
      "Epoch 701/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.1888 - val_accuracy: 0.9300\n",
      "Epoch 702/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.1851 - val_accuracy: 0.9308\n",
      "Epoch 703/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.1920 - val_accuracy: 0.9286\n",
      "Epoch 704/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.1908 - val_accuracy: 0.9286\n",
      "Epoch 705/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9315 - val_loss: 0.1955 - val_accuracy: 0.9270\n",
      "Epoch 706/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9315 - val_loss: 0.1915 - val_accuracy: 0.9280\n",
      "Epoch 707/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.1848 - val_accuracy: 0.9309\n",
      "Epoch 708/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.2055 - val_accuracy: 0.9219\n",
      "Epoch 709/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.2007 - val_accuracy: 0.9248\n",
      "Epoch 710/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9319 - val_loss: 0.2021 - val_accuracy: 0.9251\n",
      "Epoch 711/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9314 - val_loss: 0.1865 - val_accuracy: 0.9307\n",
      "Epoch 712/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.2244 - val_accuracy: 0.9142\n",
      "Epoch 713/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9318 - val_loss: 0.1749 - val_accuracy: 0.9355\n",
      "Epoch 714/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9319 - val_loss: 0.1733 - val_accuracy: 0.9353\n",
      "Epoch 715/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.2059 - val_accuracy: 0.9215\n",
      "Epoch 716/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.1775 - val_accuracy: 0.9339\n",
      "Epoch 717/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9315 - val_loss: 0.1678 - val_accuracy: 0.9380\n",
      "Epoch 718/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.1938 - val_accuracy: 0.9260\n",
      "Epoch 719/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.1998 - val_accuracy: 0.9248\n",
      "Epoch 720/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9315 - val_loss: 0.1816 - val_accuracy: 0.9322\n",
      "Epoch 721/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.1854 - val_accuracy: 0.9301\n",
      "Epoch 722/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9319 - val_loss: 0.1878 - val_accuracy: 0.9301\n",
      "Epoch 723/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.1871 - val_accuracy: 0.9305\n",
      "Epoch 724/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9318 - val_loss: 0.1791 - val_accuracy: 0.9336\n",
      "Epoch 725/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.1638 - val_accuracy: 0.9394\n",
      "Epoch 726/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9318 - val_loss: 0.1884 - val_accuracy: 0.9290\n",
      "Epoch 727/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9314 - val_loss: 0.1868 - val_accuracy: 0.9314\n",
      "Epoch 728/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9318 - val_loss: 0.1828 - val_accuracy: 0.9318\n",
      "Epoch 729/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0069 - accuracy: 0.9314 - val_loss: 0.1889 - val_accuracy: 0.9295\n",
      "Epoch 730/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9320 - val_loss: 0.1717 - val_accuracy: 0.9372\n",
      "Epoch 731/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.1811 - val_accuracy: 0.9331\n",
      "Epoch 732/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9316 - val_loss: 0.1941 - val_accuracy: 0.9277\n",
      "Epoch 733/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9318 - val_loss: 0.1634 - val_accuracy: 0.9399\n",
      "Epoch 734/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9320 - val_loss: 0.1922 - val_accuracy: 0.9273\n",
      "Epoch 735/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.1909 - val_accuracy: 0.9288\n",
      "Epoch 736/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0069 - accuracy: 0.9314 - val_loss: 0.1876 - val_accuracy: 0.9297\n",
      "Epoch 737/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9319 - val_loss: 0.1631 - val_accuracy: 0.9403\n",
      "Epoch 738/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9320 - val_loss: 0.2110 - val_accuracy: 0.9207\n",
      "Epoch 739/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0069 - accuracy: 0.9320 - val_loss: 0.2118 - val_accuracy: 0.9201\n",
      "Epoch 740/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.1781 - val_accuracy: 0.9346\n",
      "Epoch 741/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9318 - val_loss: 0.1685 - val_accuracy: 0.9374\n",
      "Epoch 742/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9314 - val_loss: 0.1873 - val_accuracy: 0.9302\n",
      "Epoch 743/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9319 - val_loss: 0.1907 - val_accuracy: 0.9270\n",
      "Epoch 744/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.2011 - val_accuracy: 0.9240\n",
      "Epoch 745/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.1875 - val_accuracy: 0.9310\n",
      "Epoch 746/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9320 - val_loss: 0.1847 - val_accuracy: 0.9316\n",
      "Epoch 747/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9319 - val_loss: 0.1811 - val_accuracy: 0.9329\n",
      "Epoch 748/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.1649 - val_accuracy: 0.9392\n",
      "Epoch 749/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9319 - val_loss: 0.1759 - val_accuracy: 0.9352\n",
      "Epoch 750/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9318 - val_loss: 0.1675 - val_accuracy: 0.9381\n",
      "Epoch 751/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0069 - accuracy: 0.9323 - val_loss: 0.1975 - val_accuracy: 0.9256\n",
      "Epoch 752/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.1566 - val_accuracy: 0.9426\n",
      "Epoch 753/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9320 - val_loss: 0.1932 - val_accuracy: 0.9283\n",
      "Epoch 754/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0069 - accuracy: 0.9320 - val_loss: 0.1866 - val_accuracy: 0.9309\n",
      "Epoch 755/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0069 - accuracy: 0.9319 - val_loss: 0.1869 - val_accuracy: 0.9294\n",
      "Epoch 756/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.2021 - val_accuracy: 0.9252\n",
      "Epoch 757/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.1864 - val_accuracy: 0.9321\n",
      "Epoch 758/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9319 - val_loss: 0.2004 - val_accuracy: 0.9252\n",
      "Epoch 759/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9318 - val_loss: 0.1889 - val_accuracy: 0.9298\n",
      "Epoch 760/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9320 - val_loss: 0.1757 - val_accuracy: 0.9347\n",
      "Epoch 761/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9318 - val_loss: 0.1916 - val_accuracy: 0.9274\n",
      "Epoch 762/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.1779 - val_accuracy: 0.9344\n",
      "Epoch 763/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9320 - val_loss: 0.1971 - val_accuracy: 0.9250\n",
      "Epoch 764/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.1603 - val_accuracy: 0.9405\n",
      "Epoch 765/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.2085 - val_accuracy: 0.9214\n",
      "Epoch 766/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9321 - val_loss: 0.1884 - val_accuracy: 0.9291\n",
      "Epoch 767/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9320 - val_loss: 0.1910 - val_accuracy: 0.9293\n",
      "Epoch 768/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9320 - val_loss: 0.1893 - val_accuracy: 0.9305\n",
      "Epoch 769/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9320 - val_loss: 0.1770 - val_accuracy: 0.9339\n",
      "Epoch 770/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9319 - val_loss: 0.1729 - val_accuracy: 0.9357\n",
      "Epoch 771/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0069 - accuracy: 0.9321 - val_loss: 0.1792 - val_accuracy: 0.9335\n",
      "Epoch 772/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9318 - val_loss: 0.1736 - val_accuracy: 0.9359\n",
      "Epoch 773/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9320 - val_loss: 0.1913 - val_accuracy: 0.9288\n",
      "Epoch 774/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9321 - val_loss: 0.1767 - val_accuracy: 0.9343\n",
      "Epoch 775/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0069 - accuracy: 0.9319 - val_loss: 0.1948 - val_accuracy: 0.9275\n",
      "Epoch 776/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.1775 - val_accuracy: 0.9337\n",
      "Epoch 777/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9322 - val_loss: 0.1785 - val_accuracy: 0.9340\n",
      "Epoch 778/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.1905 - val_accuracy: 0.9272\n",
      "Epoch 779/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9322 - val_loss: 0.2060 - val_accuracy: 0.9232\n",
      "Epoch 780/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9320 - val_loss: 0.1840 - val_accuracy: 0.9315\n",
      "Epoch 781/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9320 - val_loss: 0.1935 - val_accuracy: 0.9275\n",
      "Epoch 782/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9322 - val_loss: 0.1728 - val_accuracy: 0.9370\n",
      "Epoch 783/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9320 - val_loss: 0.1767 - val_accuracy: 0.9336\n",
      "Epoch 784/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9318 - val_loss: 0.2150 - val_accuracy: 0.9180\n",
      "Epoch 785/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9314 - val_loss: 0.1758 - val_accuracy: 0.9347\n",
      "Epoch 786/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9320 - val_loss: 0.1967 - val_accuracy: 0.9249\n",
      "Epoch 787/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9320 - val_loss: 0.1656 - val_accuracy: 0.9395\n",
      "Epoch 788/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9321 - val_loss: 0.1947 - val_accuracy: 0.9279\n",
      "Epoch 789/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9323 - val_loss: 0.2011 - val_accuracy: 0.9235\n",
      "Epoch 790/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.1726 - val_accuracy: 0.9357\n",
      "Epoch 791/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0069 - accuracy: 0.9320 - val_loss: 0.1973 - val_accuracy: 0.9247\n",
      "Epoch 792/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9318 - val_loss: 0.1839 - val_accuracy: 0.9313\n",
      "Epoch 793/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9321 - val_loss: 0.2092 - val_accuracy: 0.9204\n",
      "Epoch 794/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9318 - val_loss: 0.1801 - val_accuracy: 0.9323\n",
      "Epoch 795/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0068 - accuracy: 0.9320 - val_loss: 0.1956 - val_accuracy: 0.9263\n",
      "Epoch 796/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.1911 - val_accuracy: 0.9286\n",
      "Epoch 797/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9318 - val_loss: 0.1980 - val_accuracy: 0.9261\n",
      "Epoch 798/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9320 - val_loss: 0.2055 - val_accuracy: 0.9217\n",
      "Epoch 799/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9318 - val_loss: 0.1744 - val_accuracy: 0.9363\n",
      "Epoch 800/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9322 - val_loss: 0.2018 - val_accuracy: 0.9234\n",
      "Epoch 801/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9318 - val_loss: 0.1835 - val_accuracy: 0.9320\n",
      "Epoch 802/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9319 - val_loss: 0.1775 - val_accuracy: 0.9353\n",
      "Epoch 803/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9321 - val_loss: 0.1870 - val_accuracy: 0.9306\n",
      "Epoch 804/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9319 - val_loss: 0.1941 - val_accuracy: 0.9267\n",
      "Epoch 805/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9318 - val_loss: 0.1916 - val_accuracy: 0.9289\n",
      "Epoch 806/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9320 - val_loss: 0.1922 - val_accuracy: 0.9283\n",
      "Epoch 807/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9319 - val_loss: 0.1835 - val_accuracy: 0.9312\n",
      "Epoch 808/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9322 - val_loss: 0.1877 - val_accuracy: 0.9295\n",
      "Epoch 809/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9319 - val_loss: 0.1667 - val_accuracy: 0.9392\n",
      "Epoch 810/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9323 - val_loss: 0.1813 - val_accuracy: 0.9326\n",
      "Epoch 811/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1788 - val_accuracy: 0.9334\n",
      "Epoch 812/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1830 - val_accuracy: 0.9313\n",
      "Epoch 813/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9319 - val_loss: 0.1751 - val_accuracy: 0.9355\n",
      "Epoch 814/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9320 - val_loss: 0.1925 - val_accuracy: 0.9276\n",
      "Epoch 815/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9319 - val_loss: 0.1892 - val_accuracy: 0.9295\n",
      "Epoch 816/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9319 - val_loss: 0.1741 - val_accuracy: 0.9354\n",
      "Epoch 817/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9319 - val_loss: 0.2067 - val_accuracy: 0.9209\n",
      "Epoch 818/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0069 - accuracy: 0.9319 - val_loss: 0.1910 - val_accuracy: 0.9284\n",
      "Epoch 819/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1863 - val_accuracy: 0.9306\n",
      "Epoch 820/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1867 - val_accuracy: 0.9308\n",
      "Epoch 821/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9320 - val_loss: 0.1683 - val_accuracy: 0.9380\n",
      "Epoch 822/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1794 - val_accuracy: 0.9334\n",
      "Epoch 823/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0068 - accuracy: 0.9320 - val_loss: 0.1941 - val_accuracy: 0.9275\n",
      "Epoch 824/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9320 - val_loss: 0.1801 - val_accuracy: 0.9325\n",
      "Epoch 825/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1832 - val_accuracy: 0.9323\n",
      "Epoch 826/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.1868 - val_accuracy: 0.9307\n",
      "Epoch 827/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1809 - val_accuracy: 0.9330\n",
      "Epoch 828/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.2030 - val_accuracy: 0.9241\n",
      "Epoch 829/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9317 - val_loss: 0.1690 - val_accuracy: 0.9372\n",
      "Epoch 830/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9320 - val_loss: 0.1820 - val_accuracy: 0.9310\n",
      "Epoch 831/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1962 - val_accuracy: 0.9262\n",
      "Epoch 832/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1904 - val_accuracy: 0.9273\n",
      "Epoch 833/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1902 - val_accuracy: 0.9287\n",
      "Epoch 834/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1931 - val_accuracy: 0.9276\n",
      "Epoch 835/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9318 - val_loss: 0.1870 - val_accuracy: 0.9303\n",
      "Epoch 836/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1947 - val_accuracy: 0.9266\n",
      "Epoch 837/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1902 - val_accuracy: 0.9292\n",
      "Epoch 838/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9319 - val_loss: 0.1780 - val_accuracy: 0.9338\n",
      "Epoch 839/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1972 - val_accuracy: 0.9255\n",
      "Epoch 840/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9319 - val_loss: 0.1887 - val_accuracy: 0.9301\n",
      "Epoch 841/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1972 - val_accuracy: 0.9253\n",
      "Epoch 842/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9320 - val_loss: 0.1770 - val_accuracy: 0.9344\n",
      "Epoch 843/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.2035 - val_accuracy: 0.9230\n",
      "Epoch 844/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9318 - val_loss: 0.1789 - val_accuracy: 0.9338\n",
      "Epoch 845/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1966 - val_accuracy: 0.9261\n",
      "Epoch 846/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.2011 - val_accuracy: 0.9254\n",
      "Epoch 847/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9320 - val_loss: 0.1721 - val_accuracy: 0.9358\n",
      "Epoch 848/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9321 - val_loss: 0.1889 - val_accuracy: 0.9293\n",
      "Epoch 849/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9313 - val_loss: 0.1940 - val_accuracy: 0.9269\n",
      "Epoch 850/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9320 - val_loss: 0.1704 - val_accuracy: 0.9363\n",
      "Epoch 851/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9320 - val_loss: 0.1775 - val_accuracy: 0.9343\n",
      "Epoch 852/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1765 - val_accuracy: 0.9341\n",
      "Epoch 853/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9316 - val_loss: 0.1856 - val_accuracy: 0.9304\n",
      "Epoch 854/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1903 - val_accuracy: 0.9293\n",
      "Epoch 855/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1867 - val_accuracy: 0.9305\n",
      "Epoch 856/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1816 - val_accuracy: 0.9314\n",
      "Epoch 857/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9319 - val_loss: 0.1807 - val_accuracy: 0.9323\n",
      "Epoch 858/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1784 - val_accuracy: 0.9344\n",
      "Epoch 859/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9320 - val_loss: 0.1891 - val_accuracy: 0.9284\n",
      "Epoch 860/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1949 - val_accuracy: 0.9270\n",
      "Epoch 861/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1887 - val_accuracy: 0.9299\n",
      "Epoch 862/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9320 - val_loss: 0.1991 - val_accuracy: 0.9250\n",
      "Epoch 863/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1816 - val_accuracy: 0.9323\n",
      "Epoch 864/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1697 - val_accuracy: 0.9367\n",
      "Epoch 865/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1945 - val_accuracy: 0.9263\n",
      "Epoch 866/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1908 - val_accuracy: 0.9282\n",
      "Epoch 867/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1932 - val_accuracy: 0.9262\n",
      "Epoch 868/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9318 - val_loss: 0.1988 - val_accuracy: 0.9264\n",
      "Epoch 869/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.2011 - val_accuracy: 0.9234\n",
      "Epoch 870/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0068 - accuracy: 0.9320 - val_loss: 0.1913 - val_accuracy: 0.9298\n",
      "Epoch 871/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1821 - val_accuracy: 0.9322\n",
      "Epoch 872/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1857 - val_accuracy: 0.9293\n",
      "Epoch 873/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9319 - val_loss: 0.1847 - val_accuracy: 0.9310\n",
      "Epoch 874/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.2018 - val_accuracy: 0.9240\n",
      "Epoch 875/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9319 - val_loss: 0.1797 - val_accuracy: 0.9328\n",
      "Epoch 876/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1914 - val_accuracy: 0.9276\n",
      "Epoch 877/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1850 - val_accuracy: 0.9302\n",
      "Epoch 878/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.2069 - val_accuracy: 0.9206\n",
      "Epoch 879/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1911 - val_accuracy: 0.9276\n",
      "Epoch 880/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1717 - val_accuracy: 0.9364\n",
      "Epoch 881/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1904 - val_accuracy: 0.9276\n",
      "Epoch 882/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1919 - val_accuracy: 0.9287\n",
      "Epoch 883/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.1820 - val_accuracy: 0.9320\n",
      "Epoch 884/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1957 - val_accuracy: 0.9269\n",
      "Epoch 885/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1780 - val_accuracy: 0.9347\n",
      "Epoch 886/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1736 - val_accuracy: 0.9360\n",
      "Epoch 887/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9319 - val_loss: 0.1932 - val_accuracy: 0.9270\n",
      "Epoch 888/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1659 - val_accuracy: 0.9383\n",
      "Epoch 889/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1770 - val_accuracy: 0.9350\n",
      "Epoch 890/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9319 - val_loss: 0.1838 - val_accuracy: 0.9323\n",
      "Epoch 891/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1971 - val_accuracy: 0.9252\n",
      "Epoch 892/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1934 - val_accuracy: 0.9283\n",
      "Epoch 893/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1915 - val_accuracy: 0.9286\n",
      "Epoch 894/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.2001 - val_accuracy: 0.9249\n",
      "Epoch 895/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9320 - val_loss: 0.2067 - val_accuracy: 0.9213\n",
      "Epoch 896/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1801 - val_accuracy: 0.9323\n",
      "Epoch 897/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1808 - val_accuracy: 0.9322\n",
      "Epoch 898/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1901 - val_accuracy: 0.9284\n",
      "Epoch 899/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9320 - val_loss: 0.1877 - val_accuracy: 0.9292\n",
      "Epoch 900/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1683 - val_accuracy: 0.9380\n",
      "Epoch 901/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1854 - val_accuracy: 0.9312\n",
      "Epoch 902/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1876 - val_accuracy: 0.9300\n",
      "Epoch 903/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1937 - val_accuracy: 0.9281\n",
      "Epoch 904/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9316 - val_loss: 0.2122 - val_accuracy: 0.9188\n",
      "Epoch 905/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1778 - val_accuracy: 0.9339\n",
      "Epoch 906/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1796 - val_accuracy: 0.9332\n",
      "Epoch 907/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1663 - val_accuracy: 0.9390\n",
      "Epoch 908/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1805 - val_accuracy: 0.9328\n",
      "Epoch 909/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1732 - val_accuracy: 0.9349\n",
      "Epoch 910/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1717 - val_accuracy: 0.9356\n",
      "Epoch 911/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1702 - val_accuracy: 0.9373\n",
      "Epoch 912/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1816 - val_accuracy: 0.9312\n",
      "Epoch 913/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9320 - val_loss: 0.1831 - val_accuracy: 0.9321\n",
      "Epoch 914/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1894 - val_accuracy: 0.9301\n",
      "Epoch 915/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1920 - val_accuracy: 0.9275\n",
      "Epoch 916/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1753 - val_accuracy: 0.9348\n",
      "Epoch 917/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9325 - val_loss: 0.1916 - val_accuracy: 0.9278\n",
      "Epoch 918/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0068 - accuracy: 0.9320 - val_loss: 0.1787 - val_accuracy: 0.9330\n",
      "Epoch 919/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1921 - val_accuracy: 0.9271\n",
      "Epoch 920/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9317 - val_loss: 0.1919 - val_accuracy: 0.9275\n",
      "Epoch 921/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1680 - val_accuracy: 0.9369\n",
      "Epoch 922/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1846 - val_accuracy: 0.9307\n",
      "Epoch 923/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1925 - val_accuracy: 0.9290\n",
      "Epoch 924/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9320 - val_loss: 0.2000 - val_accuracy: 0.9240\n",
      "Epoch 925/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1941 - val_accuracy: 0.9276\n",
      "Epoch 926/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9312 - val_loss: 0.1757 - val_accuracy: 0.9346\n",
      "Epoch 927/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1764 - val_accuracy: 0.9347\n",
      "Epoch 928/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1752 - val_accuracy: 0.9353\n",
      "Epoch 929/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1813 - val_accuracy: 0.9329\n",
      "Epoch 930/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1780 - val_accuracy: 0.9334\n",
      "Epoch 931/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1829 - val_accuracy: 0.9321\n",
      "Epoch 932/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9318 - val_loss: 0.1780 - val_accuracy: 0.9332\n",
      "Epoch 933/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1803 - val_accuracy: 0.9321\n",
      "Epoch 934/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.2129 - val_accuracy: 0.9201\n",
      "Epoch 935/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1819 - val_accuracy: 0.9318\n",
      "Epoch 936/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1779 - val_accuracy: 0.9339\n",
      "Epoch 937/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9325 - val_loss: 0.1837 - val_accuracy: 0.9321\n",
      "Epoch 938/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1708 - val_accuracy: 0.9361\n",
      "Epoch 939/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1736 - val_accuracy: 0.9351\n",
      "Epoch 940/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1927 - val_accuracy: 0.9269\n",
      "Epoch 941/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1834 - val_accuracy: 0.9301\n",
      "Epoch 942/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1920 - val_accuracy: 0.9271\n",
      "Epoch 943/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1996 - val_accuracy: 0.9264\n",
      "Epoch 944/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1820 - val_accuracy: 0.9319\n",
      "Epoch 945/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9325 - val_loss: 0.1683 - val_accuracy: 0.9375\n",
      "Epoch 946/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0068 - accuracy: 0.9325 - val_loss: 0.2027 - val_accuracy: 0.9228\n",
      "Epoch 947/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1952 - val_accuracy: 0.9268\n",
      "Epoch 948/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1697 - val_accuracy: 0.9372\n",
      "Epoch 949/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1850 - val_accuracy: 0.9315\n",
      "Epoch 950/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.2067 - val_accuracy: 0.9206\n",
      "Epoch 951/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1904 - val_accuracy: 0.9281\n",
      "Epoch 952/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.2028 - val_accuracy: 0.9240\n",
      "Epoch 953/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1751 - val_accuracy: 0.9348\n",
      "Epoch 954/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1972 - val_accuracy: 0.9253\n",
      "Epoch 955/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1875 - val_accuracy: 0.9297\n",
      "Epoch 956/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1785 - val_accuracy: 0.9336\n",
      "Epoch 957/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1700 - val_accuracy: 0.9364\n",
      "Epoch 958/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9327 - val_loss: 0.1977 - val_accuracy: 0.9262\n",
      "Epoch 959/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1848 - val_accuracy: 0.9309\n",
      "Epoch 960/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1794 - val_accuracy: 0.9335\n",
      "Epoch 961/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1883 - val_accuracy: 0.9298\n",
      "Epoch 962/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1812 - val_accuracy: 0.9322\n",
      "Epoch 963/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1807 - val_accuracy: 0.9325\n",
      "Epoch 964/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1761 - val_accuracy: 0.9341\n",
      "Epoch 965/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9326 - val_loss: 0.1947 - val_accuracy: 0.9262\n",
      "Epoch 966/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9325 - val_loss: 0.1915 - val_accuracy: 0.9277\n",
      "Epoch 967/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1972 - val_accuracy: 0.9268\n",
      "Epoch 968/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1809 - val_accuracy: 0.9314\n",
      "Epoch 969/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1739 - val_accuracy: 0.9356\n",
      "Epoch 970/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1766 - val_accuracy: 0.9349\n",
      "Epoch 971/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9325 - val_loss: 0.1784 - val_accuracy: 0.9332\n",
      "Epoch 972/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9325 - val_loss: 0.1841 - val_accuracy: 0.9315\n",
      "Epoch 973/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1943 - val_accuracy: 0.9282\n",
      "Epoch 974/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.2161 - val_accuracy: 0.9170\n",
      "Epoch 975/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1926 - val_accuracy: 0.9273\n",
      "Epoch 976/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1827 - val_accuracy: 0.9316\n",
      "Epoch 977/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1939 - val_accuracy: 0.9267\n",
      "Epoch 978/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1648 - val_accuracy: 0.9393\n",
      "Epoch 979/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1943 - val_accuracy: 0.9266\n",
      "Epoch 980/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1893 - val_accuracy: 0.9284\n",
      "Epoch 981/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1736 - val_accuracy: 0.9350\n",
      "Epoch 982/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9325 - val_loss: 0.1731 - val_accuracy: 0.9352\n",
      "Epoch 983/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9325 - val_loss: 0.1658 - val_accuracy: 0.9384\n",
      "Epoch 984/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1870 - val_accuracy: 0.9313\n",
      "Epoch 985/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1905 - val_accuracy: 0.9272\n",
      "Epoch 986/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9326 - val_loss: 0.1891 - val_accuracy: 0.9280\n",
      "Epoch 987/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9326 - val_loss: 0.1952 - val_accuracy: 0.9272\n",
      "Epoch 988/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1844 - val_accuracy: 0.9310\n",
      "Epoch 989/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1586 - val_accuracy: 0.9415\n",
      "Epoch 990/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1635 - val_accuracy: 0.9396\n",
      "Epoch 991/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1927 - val_accuracy: 0.9267\n",
      "Epoch 992/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1937 - val_accuracy: 0.9263\n",
      "Epoch 993/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9325 - val_loss: 0.1852 - val_accuracy: 0.9320\n",
      "Epoch 994/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1699 - val_accuracy: 0.9367\n",
      "Epoch 995/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1870 - val_accuracy: 0.9290\n",
      "Epoch 996/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1836 - val_accuracy: 0.9302\n",
      "Epoch 997/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1689 - val_accuracy: 0.9369\n",
      "Epoch 998/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9326 - val_loss: 0.2021 - val_accuracy: 0.9232\n",
      "Epoch 999/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1947 - val_accuracy: 0.9263\n",
      "Epoch 1000/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1897 - val_accuracy: 0.9283\n",
      "Epoch 1001/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1735 - val_accuracy: 0.9359\n",
      "Epoch 1002/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9326 - val_loss: 0.1716 - val_accuracy: 0.9359\n",
      "Epoch 1003/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1836 - val_accuracy: 0.9318\n",
      "Epoch 1004/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.2004 - val_accuracy: 0.9241\n",
      "Epoch 1005/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1770 - val_accuracy: 0.9326\n",
      "Epoch 1006/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1793 - val_accuracy: 0.9331\n",
      "Epoch 1007/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0068 - accuracy: 0.9327 - val_loss: 0.1757 - val_accuracy: 0.9344\n",
      "Epoch 1008/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1806 - val_accuracy: 0.9321\n",
      "Epoch 1009/2500\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1725 - val_accuracy: 0.9354\n",
      "Epoch 1010/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1833 - val_accuracy: 0.9319\n",
      "Epoch 1011/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1944 - val_accuracy: 0.9264\n",
      "Epoch 1012/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1911 - val_accuracy: 0.9277\n",
      "Epoch 1013/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1712 - val_accuracy: 0.9369\n",
      "Epoch 1014/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9320 - val_loss: 0.1896 - val_accuracy: 0.9288\n",
      "Epoch 1015/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1787 - val_accuracy: 0.9338\n",
      "Epoch 1016/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1603 - val_accuracy: 0.9419\n",
      "Epoch 1017/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1683 - val_accuracy: 0.9375\n",
      "Epoch 1018/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9326 - val_loss: 0.1895 - val_accuracy: 0.9289\n",
      "Epoch 1019/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1781 - val_accuracy: 0.9324\n",
      "Epoch 1020/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9325 - val_loss: 0.1877 - val_accuracy: 0.9285\n",
      "Epoch 1021/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0067 - accuracy: 0.9323 - val_loss: 0.1915 - val_accuracy: 0.9286\n",
      "Epoch 1022/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1710 - val_accuracy: 0.9372\n",
      "Epoch 1023/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1674 - val_accuracy: 0.9377\n",
      "Epoch 1024/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1831 - val_accuracy: 0.9311\n",
      "Epoch 1025/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1821 - val_accuracy: 0.9311\n",
      "Epoch 1026/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1881 - val_accuracy: 0.9304\n",
      "Epoch 1027/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9326 - val_loss: 0.1743 - val_accuracy: 0.9354\n",
      "Epoch 1028/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1746 - val_accuracy: 0.9347\n",
      "Epoch 1029/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1688 - val_accuracy: 0.9374\n",
      "Epoch 1030/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1810 - val_accuracy: 0.9319\n",
      "Epoch 1031/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1864 - val_accuracy: 0.9300\n",
      "Epoch 1032/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1956 - val_accuracy: 0.9262\n",
      "Epoch 1033/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0068 - accuracy: 0.9316 - val_loss: 0.1944 - val_accuracy: 0.9274\n",
      "Epoch 1034/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.2090 - val_accuracy: 0.9202\n",
      "Epoch 1035/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.2052 - val_accuracy: 0.9215\n",
      "Epoch 1036/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1985 - val_accuracy: 0.9236\n",
      "Epoch 1037/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1856 - val_accuracy: 0.9306\n",
      "Epoch 1038/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0067 - accuracy: 0.9323 - val_loss: 0.1797 - val_accuracy: 0.9327\n",
      "Epoch 1039/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1988 - val_accuracy: 0.9248\n",
      "Epoch 1040/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1935 - val_accuracy: 0.9266\n",
      "Epoch 1041/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1944 - val_accuracy: 0.9278\n",
      "Epoch 1042/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9320 - val_loss: 0.1891 - val_accuracy: 0.9299\n",
      "Epoch 1043/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1804 - val_accuracy: 0.9323\n",
      "Epoch 1044/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1824 - val_accuracy: 0.9316\n",
      "Epoch 1045/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1783 - val_accuracy: 0.9331\n",
      "Epoch 1046/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1973 - val_accuracy: 0.9251\n",
      "Epoch 1047/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1866 - val_accuracy: 0.9299\n",
      "Epoch 1048/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.2119 - val_accuracy: 0.9190\n",
      "Epoch 1049/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9320 - val_loss: 0.1614 - val_accuracy: 0.9410\n",
      "Epoch 1050/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9328 - val_loss: 0.1897 - val_accuracy: 0.9285\n",
      "Epoch 1051/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9323 - val_loss: 0.1857 - val_accuracy: 0.9293\n",
      "Epoch 1052/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1898 - val_accuracy: 0.9282\n",
      "Epoch 1053/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9328 - val_loss: 0.2165 - val_accuracy: 0.9168\n",
      "Epoch 1054/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9323 - val_loss: 0.1879 - val_accuracy: 0.9310\n",
      "Epoch 1055/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1744 - val_accuracy: 0.9359\n",
      "Epoch 1056/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1842 - val_accuracy: 0.9310\n",
      "Epoch 1057/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9323 - val_loss: 0.1756 - val_accuracy: 0.9346\n",
      "Epoch 1058/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9328 - val_loss: 0.1893 - val_accuracy: 0.9299\n",
      "Epoch 1059/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1776 - val_accuracy: 0.9341\n",
      "Epoch 1060/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1916 - val_accuracy: 0.9268\n",
      "Epoch 1061/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9323 - val_loss: 0.1708 - val_accuracy: 0.9363\n",
      "Epoch 1062/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1720 - val_accuracy: 0.9358\n",
      "Epoch 1063/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1906 - val_accuracy: 0.9284\n",
      "Epoch 1064/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9323 - val_loss: 0.1692 - val_accuracy: 0.9377\n",
      "Epoch 1065/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1912 - val_accuracy: 0.9283\n",
      "Epoch 1066/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9323 - val_loss: 0.1916 - val_accuracy: 0.9296\n",
      "Epoch 1067/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9319 - val_loss: 0.1734 - val_accuracy: 0.9347\n",
      "Epoch 1068/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0067 - accuracy: 0.9323 - val_loss: 0.1826 - val_accuracy: 0.9310\n",
      "Epoch 1069/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1799 - val_accuracy: 0.9314\n",
      "Epoch 1070/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1895 - val_accuracy: 0.9286\n",
      "Epoch 1071/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9328 - val_loss: 0.1825 - val_accuracy: 0.9323\n",
      "Epoch 1072/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1886 - val_accuracy: 0.9295\n",
      "Epoch 1073/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.2000 - val_accuracy: 0.9225\n",
      "Epoch 1074/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1797 - val_accuracy: 0.9335\n",
      "Epoch 1075/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1966 - val_accuracy: 0.9255\n",
      "Epoch 1076/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1707 - val_accuracy: 0.9362\n",
      "Epoch 1077/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1988 - val_accuracy: 0.9248\n",
      "Epoch 1078/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1740 - val_accuracy: 0.9348\n",
      "Epoch 1079/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1840 - val_accuracy: 0.9310\n",
      "Epoch 1080/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.2010 - val_accuracy: 0.9234\n",
      "Epoch 1081/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1724 - val_accuracy: 0.9352\n",
      "Epoch 1082/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1645 - val_accuracy: 0.9387\n",
      "Epoch 1083/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1770 - val_accuracy: 0.9347\n",
      "Epoch 1084/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9329 - val_loss: 0.1805 - val_accuracy: 0.9328\n",
      "Epoch 1085/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1873 - val_accuracy: 0.9298\n",
      "Epoch 1086/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1747 - val_accuracy: 0.9346\n",
      "Epoch 1087/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1911 - val_accuracy: 0.9282\n",
      "Epoch 1088/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1560 - val_accuracy: 0.9421\n",
      "Epoch 1089/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1851 - val_accuracy: 0.9298\n",
      "Epoch 1090/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0068 - accuracy: 0.9325 - val_loss: 0.1730 - val_accuracy: 0.9354\n",
      "Epoch 1091/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9322 - val_loss: 0.1816 - val_accuracy: 0.9308\n",
      "Epoch 1092/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0067 - accuracy: 0.9323 - val_loss: 0.1922 - val_accuracy: 0.9282\n",
      "Epoch 1093/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1711 - val_accuracy: 0.9351\n",
      "Epoch 1094/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1937 - val_accuracy: 0.9263\n",
      "Epoch 1095/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1772 - val_accuracy: 0.9335\n",
      "Epoch 1096/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9321 - val_loss: 0.1892 - val_accuracy: 0.9296\n",
      "Epoch 1097/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1747 - val_accuracy: 0.9348\n",
      "Epoch 1098/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9324 - val_loss: 0.1778 - val_accuracy: 0.9330\n",
      "Epoch 1099/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1705 - val_accuracy: 0.9363\n",
      "Epoch 1100/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1784 - val_accuracy: 0.9343\n",
      "Epoch 1101/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1890 - val_accuracy: 0.9289\n",
      "Epoch 1102/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1594 - val_accuracy: 0.9404\n",
      "Epoch 1103/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9322 - val_loss: 0.1801 - val_accuracy: 0.9324\n",
      "Epoch 1104/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9328 - val_loss: 0.1849 - val_accuracy: 0.9315\n",
      "Epoch 1105/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1926 - val_accuracy: 0.9275\n",
      "Epoch 1106/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1881 - val_accuracy: 0.9300\n",
      "Epoch 1107/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1902 - val_accuracy: 0.9285\n",
      "Epoch 1108/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0068 - accuracy: 0.9320 - val_loss: 0.2029 - val_accuracy: 0.9236\n",
      "Epoch 1109/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1803 - val_accuracy: 0.9321\n",
      "Epoch 1110/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1740 - val_accuracy: 0.9344\n",
      "Epoch 1111/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1974 - val_accuracy: 0.9264\n",
      "Epoch 1112/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1891 - val_accuracy: 0.9282\n",
      "Epoch 1113/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1773 - val_accuracy: 0.9341\n",
      "Epoch 1114/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1703 - val_accuracy: 0.9362\n",
      "Epoch 1115/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1746 - val_accuracy: 0.9356\n",
      "Epoch 1116/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1999 - val_accuracy: 0.9235\n",
      "Epoch 1117/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9325 - val_loss: 0.1841 - val_accuracy: 0.9303\n",
      "Epoch 1118/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1742 - val_accuracy: 0.9342\n",
      "Epoch 1119/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1863 - val_accuracy: 0.9305\n",
      "Epoch 1120/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0067 - accuracy: 0.9321 - val_loss: 0.1920 - val_accuracy: 0.9276\n",
      "Epoch 1121/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1960 - val_accuracy: 0.9253\n",
      "Epoch 1122/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1871 - val_accuracy: 0.9302\n",
      "Epoch 1123/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1835 - val_accuracy: 0.9318\n",
      "Epoch 1124/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1909 - val_accuracy: 0.9287\n",
      "Epoch 1125/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1881 - val_accuracy: 0.9283\n",
      "Epoch 1126/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1923 - val_accuracy: 0.9275\n",
      "Epoch 1127/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1875 - val_accuracy: 0.9293\n",
      "Epoch 1128/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1797 - val_accuracy: 0.9321\n",
      "Epoch 1129/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9320 - val_loss: 0.1987 - val_accuracy: 0.9260\n",
      "Epoch 1130/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1797 - val_accuracy: 0.9323\n",
      "Epoch 1131/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1892 - val_accuracy: 0.9282\n",
      "Epoch 1132/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1676 - val_accuracy: 0.9370\n",
      "Epoch 1133/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1779 - val_accuracy: 0.9334\n",
      "Epoch 1134/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1772 - val_accuracy: 0.9336\n",
      "Epoch 1135/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.2005 - val_accuracy: 0.9242\n",
      "Epoch 1136/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1827 - val_accuracy: 0.9319\n",
      "Epoch 1137/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1885 - val_accuracy: 0.9300\n",
      "Epoch 1138/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0067 - accuracy: 0.9328 - val_loss: 0.2025 - val_accuracy: 0.9223\n",
      "Epoch 1139/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9323 - val_loss: 0.1893 - val_accuracy: 0.9288\n",
      "Epoch 1140/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1744 - val_accuracy: 0.9345\n",
      "Epoch 1141/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9329 - val_loss: 0.1919 - val_accuracy: 0.9272\n",
      "Epoch 1142/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1844 - val_accuracy: 0.9297\n",
      "Epoch 1143/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1843 - val_accuracy: 0.9307\n",
      "Epoch 1144/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1886 - val_accuracy: 0.9291\n",
      "Epoch 1145/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9328 - val_loss: 0.1856 - val_accuracy: 0.9295\n",
      "Epoch 1146/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1883 - val_accuracy: 0.9293\n",
      "Epoch 1147/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1716 - val_accuracy: 0.9358\n",
      "Epoch 1148/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1780 - val_accuracy: 0.9332\n",
      "Epoch 1149/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1820 - val_accuracy: 0.9322\n",
      "Epoch 1150/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1866 - val_accuracy: 0.9290\n",
      "Epoch 1151/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.2201 - val_accuracy: 0.9156\n",
      "Epoch 1152/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1821 - val_accuracy: 0.9309\n",
      "Epoch 1153/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1989 - val_accuracy: 0.9245\n",
      "Epoch 1154/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1812 - val_accuracy: 0.9321\n",
      "Epoch 1155/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1946 - val_accuracy: 0.9257\n",
      "Epoch 1156/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1771 - val_accuracy: 0.9332\n",
      "Epoch 1157/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1786 - val_accuracy: 0.9323\n",
      "Epoch 1158/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1719 - val_accuracy: 0.9360\n",
      "Epoch 1159/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9328 - val_loss: 0.1743 - val_accuracy: 0.9346\n",
      "Epoch 1160/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.2007 - val_accuracy: 0.9261\n",
      "Epoch 1161/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1826 - val_accuracy: 0.9312\n",
      "Epoch 1162/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9323 - val_loss: 0.1900 - val_accuracy: 0.9287\n",
      "Epoch 1163/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1782 - val_accuracy: 0.9326\n",
      "Epoch 1164/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1746 - val_accuracy: 0.9344\n",
      "Epoch 1165/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1965 - val_accuracy: 0.9251\n",
      "Epoch 1166/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1743 - val_accuracy: 0.9347\n",
      "Epoch 1167/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.2200 - val_accuracy: 0.9153\n",
      "Epoch 1168/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9319 - val_loss: 0.1565 - val_accuracy: 0.9423\n",
      "Epoch 1169/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9322 - val_loss: 0.1900 - val_accuracy: 0.9283\n",
      "Epoch 1170/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1787 - val_accuracy: 0.9327\n",
      "Epoch 1171/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1959 - val_accuracy: 0.9265\n",
      "Epoch 1172/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9323 - val_loss: 0.1783 - val_accuracy: 0.9327\n",
      "Epoch 1173/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1768 - val_accuracy: 0.9346\n",
      "Epoch 1174/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1884 - val_accuracy: 0.9285\n",
      "Epoch 1175/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1883 - val_accuracy: 0.9291\n",
      "Epoch 1176/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1799 - val_accuracy: 0.9316\n",
      "Epoch 1177/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1811 - val_accuracy: 0.9328\n",
      "Epoch 1178/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1868 - val_accuracy: 0.9293\n",
      "Epoch 1179/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1957 - val_accuracy: 0.9269\n",
      "Epoch 1180/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1940 - val_accuracy: 0.9263\n",
      "Epoch 1181/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1854 - val_accuracy: 0.9310\n",
      "Epoch 1182/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1728 - val_accuracy: 0.9352\n",
      "Epoch 1183/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1913 - val_accuracy: 0.9263\n",
      "Epoch 1184/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1950 - val_accuracy: 0.9274\n",
      "Epoch 1185/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9328 - val_loss: 0.1735 - val_accuracy: 0.9354\n",
      "Epoch 1186/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1788 - val_accuracy: 0.9326\n",
      "Epoch 1187/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1850 - val_accuracy: 0.9304\n",
      "Epoch 1188/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1891 - val_accuracy: 0.9287\n",
      "Epoch 1189/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1947 - val_accuracy: 0.9271\n",
      "Epoch 1190/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1803 - val_accuracy: 0.9322\n",
      "Epoch 1191/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9328 - val_loss: 0.1943 - val_accuracy: 0.9258\n",
      "Epoch 1192/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1792 - val_accuracy: 0.9322\n",
      "Epoch 1193/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9328 - val_loss: 0.1741 - val_accuracy: 0.9345\n",
      "Epoch 1194/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1750 - val_accuracy: 0.9348\n",
      "Epoch 1195/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1689 - val_accuracy: 0.9373\n",
      "Epoch 1196/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1914 - val_accuracy: 0.9278\n",
      "Epoch 1197/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9323 - val_loss: 0.1810 - val_accuracy: 0.9301\n",
      "Epoch 1198/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1755 - val_accuracy: 0.9336\n",
      "Epoch 1199/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1950 - val_accuracy: 0.9263\n",
      "Epoch 1200/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1868 - val_accuracy: 0.9304\n",
      "Epoch 1201/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1739 - val_accuracy: 0.9357\n",
      "Epoch 1202/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9328 - val_loss: 0.1994 - val_accuracy: 0.9244\n",
      "Epoch 1203/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1717 - val_accuracy: 0.9352\n",
      "Epoch 1204/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9328 - val_loss: 0.2036 - val_accuracy: 0.9234\n",
      "Epoch 1205/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9323 - val_loss: 0.1846 - val_accuracy: 0.9303\n",
      "Epoch 1206/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9328 - val_loss: 0.1780 - val_accuracy: 0.9330\n",
      "Epoch 1207/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1781 - val_accuracy: 0.9333\n",
      "Epoch 1208/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1750 - val_accuracy: 0.9352\n",
      "Epoch 1209/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1770 - val_accuracy: 0.9328\n",
      "Epoch 1210/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1793 - val_accuracy: 0.9324\n",
      "Epoch 1211/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1840 - val_accuracy: 0.9298\n",
      "Epoch 1212/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1720 - val_accuracy: 0.9357\n",
      "Epoch 1213/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1927 - val_accuracy: 0.9267\n",
      "Epoch 1214/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1906 - val_accuracy: 0.9280\n",
      "Epoch 1215/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1637 - val_accuracy: 0.9384\n",
      "Epoch 1216/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1795 - val_accuracy: 0.9329\n",
      "Epoch 1217/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1900 - val_accuracy: 0.9286\n",
      "Epoch 1218/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9328 - val_loss: 0.1889 - val_accuracy: 0.9282\n",
      "Epoch 1219/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9323 - val_loss: 0.1777 - val_accuracy: 0.9328\n",
      "Epoch 1220/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1831 - val_accuracy: 0.9301\n",
      "Epoch 1221/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9323 - val_loss: 0.1840 - val_accuracy: 0.9315\n",
      "Epoch 1222/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1862 - val_accuracy: 0.9305\n",
      "Epoch 1223/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1672 - val_accuracy: 0.9382\n",
      "Epoch 1224/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1820 - val_accuracy: 0.9308\n",
      "Epoch 1225/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1864 - val_accuracy: 0.9298\n",
      "Epoch 1226/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1755 - val_accuracy: 0.9344\n",
      "Epoch 1227/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1788 - val_accuracy: 0.9320\n",
      "Epoch 1228/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1805 - val_accuracy: 0.9324\n",
      "Epoch 1229/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1796 - val_accuracy: 0.9333\n",
      "Epoch 1230/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1872 - val_accuracy: 0.9289\n",
      "Epoch 1231/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.2008 - val_accuracy: 0.9236\n",
      "Epoch 1232/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1836 - val_accuracy: 0.9300\n",
      "Epoch 1233/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1828 - val_accuracy: 0.9321\n",
      "Epoch 1234/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1851 - val_accuracy: 0.9315\n",
      "Epoch 1235/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1848 - val_accuracy: 0.9307\n",
      "Epoch 1236/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1932 - val_accuracy: 0.9260\n",
      "Epoch 1237/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9323 - val_loss: 0.1821 - val_accuracy: 0.9306\n",
      "Epoch 1238/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1813 - val_accuracy: 0.9317\n",
      "Epoch 1239/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1811 - val_accuracy: 0.9317\n",
      "Epoch 1240/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1771 - val_accuracy: 0.9337\n",
      "Epoch 1241/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1707 - val_accuracy: 0.9360\n",
      "Epoch 1242/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1840 - val_accuracy: 0.9299\n",
      "Epoch 1243/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1840 - val_accuracy: 0.9309\n",
      "Epoch 1244/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.2010 - val_accuracy: 0.9224\n",
      "Epoch 1245/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9322 - val_loss: 0.1779 - val_accuracy: 0.9337\n",
      "Epoch 1246/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1765 - val_accuracy: 0.9325\n",
      "Epoch 1247/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1624 - val_accuracy: 0.9393\n",
      "Epoch 1248/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1925 - val_accuracy: 0.9281\n",
      "Epoch 1249/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1895 - val_accuracy: 0.9278\n",
      "Epoch 1250/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9323 - val_loss: 0.2154 - val_accuracy: 0.9169\n",
      "Epoch 1251/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1823 - val_accuracy: 0.9313\n",
      "Epoch 1252/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1750 - val_accuracy: 0.9342\n",
      "Epoch 1253/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1681 - val_accuracy: 0.9368\n",
      "Epoch 1254/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1766 - val_accuracy: 0.9333\n",
      "Epoch 1255/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1781 - val_accuracy: 0.9320\n",
      "Epoch 1256/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.2027 - val_accuracy: 0.9236\n",
      "Epoch 1257/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1675 - val_accuracy: 0.9378\n",
      "Epoch 1258/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1939 - val_accuracy: 0.9262\n",
      "Epoch 1259/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1861 - val_accuracy: 0.9303\n",
      "Epoch 1260/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1867 - val_accuracy: 0.9283\n",
      "Epoch 1261/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9329 - val_loss: 0.2028 - val_accuracy: 0.9216\n",
      "Epoch 1262/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1881 - val_accuracy: 0.9287\n",
      "Epoch 1263/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1824 - val_accuracy: 0.9302\n",
      "Epoch 1264/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1765 - val_accuracy: 0.9323\n",
      "Epoch 1265/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9323 - val_loss: 0.1870 - val_accuracy: 0.9297\n",
      "Epoch 1266/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1901 - val_accuracy: 0.9290\n",
      "Epoch 1267/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9329 - val_loss: 0.2006 - val_accuracy: 0.9245\n",
      "Epoch 1268/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1843 - val_accuracy: 0.9300\n",
      "Epoch 1269/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1899 - val_accuracy: 0.9285\n",
      "Epoch 1270/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1850 - val_accuracy: 0.9297\n",
      "Epoch 1271/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1773 - val_accuracy: 0.9322\n",
      "Epoch 1272/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1878 - val_accuracy: 0.9282\n",
      "Epoch 1273/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1788 - val_accuracy: 0.9324\n",
      "Epoch 1274/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1803 - val_accuracy: 0.9325\n",
      "Epoch 1275/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1650 - val_accuracy: 0.9394\n",
      "Epoch 1276/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1846 - val_accuracy: 0.9293\n",
      "Epoch 1277/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1848 - val_accuracy: 0.9290\n",
      "Epoch 1278/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1845 - val_accuracy: 0.9299\n",
      "Epoch 1279/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1714 - val_accuracy: 0.9349\n",
      "Epoch 1280/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.2134 - val_accuracy: 0.9172\n",
      "Epoch 1281/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9328 - val_loss: 0.1789 - val_accuracy: 0.9329\n",
      "Epoch 1282/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1935 - val_accuracy: 0.9263\n",
      "Epoch 1283/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1748 - val_accuracy: 0.9346\n",
      "Epoch 1284/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9328 - val_loss: 0.1917 - val_accuracy: 0.9276\n",
      "Epoch 1285/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1812 - val_accuracy: 0.9319\n",
      "Epoch 1286/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.2039 - val_accuracy: 0.9225\n",
      "Epoch 1287/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9329 - val_loss: 0.1846 - val_accuracy: 0.9307\n",
      "Epoch 1288/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1736 - val_accuracy: 0.9352\n",
      "Epoch 1289/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.2023 - val_accuracy: 0.9220\n",
      "Epoch 1290/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1721 - val_accuracy: 0.9370\n",
      "Epoch 1291/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9328 - val_loss: 0.1933 - val_accuracy: 0.9273\n",
      "Epoch 1292/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1756 - val_accuracy: 0.9336\n",
      "Epoch 1293/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9328 - val_loss: 0.1664 - val_accuracy: 0.9373\n",
      "Epoch 1294/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1903 - val_accuracy: 0.9280\n",
      "Epoch 1295/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1977 - val_accuracy: 0.9243\n",
      "Epoch 1296/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1898 - val_accuracy: 0.9279\n",
      "Epoch 1297/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1908 - val_accuracy: 0.9276\n",
      "Epoch 1298/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1784 - val_accuracy: 0.9329\n",
      "Epoch 1299/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.2007 - val_accuracy: 0.9242\n",
      "Epoch 1300/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9323 - val_loss: 0.1647 - val_accuracy: 0.9384\n",
      "Epoch 1301/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1999 - val_accuracy: 0.9233\n",
      "Epoch 1302/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1782 - val_accuracy: 0.9337\n",
      "Epoch 1303/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1762 - val_accuracy: 0.9341\n",
      "Epoch 1304/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1739 - val_accuracy: 0.9350\n",
      "Epoch 1305/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1762 - val_accuracy: 0.9331\n",
      "Epoch 1306/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1742 - val_accuracy: 0.9354\n",
      "Epoch 1307/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1888 - val_accuracy: 0.9294\n",
      "Epoch 1308/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.2028 - val_accuracy: 0.9219\n",
      "Epoch 1309/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9328 - val_loss: 0.1972 - val_accuracy: 0.9236\n",
      "Epoch 1310/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1679 - val_accuracy: 0.9374\n",
      "Epoch 1311/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1822 - val_accuracy: 0.9308\n",
      "Epoch 1312/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1690 - val_accuracy: 0.9375\n",
      "Epoch 1313/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1865 - val_accuracy: 0.9304\n",
      "Epoch 1314/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1632 - val_accuracy: 0.9386\n",
      "Epoch 1315/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1692 - val_accuracy: 0.9373\n",
      "Epoch 1316/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1922 - val_accuracy: 0.9268\n",
      "Epoch 1317/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1847 - val_accuracy: 0.9304\n",
      "Epoch 1318/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1836 - val_accuracy: 0.9305\n",
      "Epoch 1319/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1646 - val_accuracy: 0.9389\n",
      "Epoch 1320/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9322 - val_loss: 0.1802 - val_accuracy: 0.9321\n",
      "Epoch 1321/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1803 - val_accuracy: 0.9327\n",
      "Epoch 1322/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.2040 - val_accuracy: 0.9207\n",
      "Epoch 1323/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1702 - val_accuracy: 0.9362\n",
      "Epoch 1324/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9324 - val_loss: 0.1652 - val_accuracy: 0.9389\n",
      "Epoch 1325/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1729 - val_accuracy: 0.9350\n",
      "Epoch 1326/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1868 - val_accuracy: 0.9293\n",
      "Epoch 1327/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1910 - val_accuracy: 0.9273\n",
      "Epoch 1328/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1933 - val_accuracy: 0.9259\n",
      "Epoch 1329/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1898 - val_accuracy: 0.9281\n",
      "Epoch 1330/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.2071 - val_accuracy: 0.9196\n",
      "Epoch 1331/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1795 - val_accuracy: 0.9332\n",
      "Epoch 1332/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1969 - val_accuracy: 0.9245\n",
      "Epoch 1333/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1859 - val_accuracy: 0.9307\n",
      "Epoch 1334/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1643 - val_accuracy: 0.9388\n",
      "Epoch 1335/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1835 - val_accuracy: 0.9301\n",
      "Epoch 1336/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1795 - val_accuracy: 0.9327\n",
      "Epoch 1337/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1739 - val_accuracy: 0.9340\n",
      "Epoch 1338/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0067 - accuracy: 0.9323 - val_loss: 0.1691 - val_accuracy: 0.9378\n",
      "Epoch 1339/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1831 - val_accuracy: 0.9309\n",
      "Epoch 1340/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1684 - val_accuracy: 0.9374\n",
      "Epoch 1341/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1917 - val_accuracy: 0.9277\n",
      "Epoch 1342/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1723 - val_accuracy: 0.9354\n",
      "Epoch 1343/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1898 - val_accuracy: 0.9273\n",
      "Epoch 1344/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1909 - val_accuracy: 0.9261\n",
      "Epoch 1345/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1647 - val_accuracy: 0.9382\n",
      "Epoch 1346/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1863 - val_accuracy: 0.9291\n",
      "Epoch 1347/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1786 - val_accuracy: 0.9312\n",
      "Epoch 1348/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1846 - val_accuracy: 0.9302\n",
      "Epoch 1349/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1775 - val_accuracy: 0.9328\n",
      "Epoch 1350/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1816 - val_accuracy: 0.9328\n",
      "Epoch 1351/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1954 - val_accuracy: 0.9253\n",
      "Epoch 1352/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1825 - val_accuracy: 0.9313\n",
      "Epoch 1353/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1839 - val_accuracy: 0.9311\n",
      "Epoch 1354/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1758 - val_accuracy: 0.9337\n",
      "Epoch 1355/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1866 - val_accuracy: 0.9295\n",
      "Epoch 1356/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9323 - val_loss: 0.1870 - val_accuracy: 0.9299\n",
      "Epoch 1357/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1729 - val_accuracy: 0.9351\n",
      "Epoch 1358/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1757 - val_accuracy: 0.9334\n",
      "Epoch 1359/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1844 - val_accuracy: 0.9303\n",
      "Epoch 1360/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1911 - val_accuracy: 0.9273\n",
      "Epoch 1361/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1823 - val_accuracy: 0.9308\n",
      "Epoch 1362/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1944 - val_accuracy: 0.9265\n",
      "Epoch 1363/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.2013 - val_accuracy: 0.9230\n",
      "Epoch 1364/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1851 - val_accuracy: 0.9290\n",
      "Epoch 1365/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1708 - val_accuracy: 0.9353\n",
      "Epoch 1366/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1886 - val_accuracy: 0.9281\n",
      "Epoch 1367/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.2113 - val_accuracy: 0.9192\n",
      "Epoch 1368/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1682 - val_accuracy: 0.9370\n",
      "Epoch 1369/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1943 - val_accuracy: 0.9264\n",
      "Epoch 1370/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1977 - val_accuracy: 0.9258\n",
      "Epoch 1371/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1969 - val_accuracy: 0.9249\n",
      "Epoch 1372/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1872 - val_accuracy: 0.9276\n",
      "Epoch 1373/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1797 - val_accuracy: 0.9319\n",
      "Epoch 1374/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1828 - val_accuracy: 0.9311\n",
      "Epoch 1375/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1857 - val_accuracy: 0.9302\n",
      "Epoch 1376/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1890 - val_accuracy: 0.9277\n",
      "Epoch 1377/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.2130 - val_accuracy: 0.9175\n",
      "Epoch 1378/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1671 - val_accuracy: 0.9381\n",
      "Epoch 1379/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1761 - val_accuracy: 0.9338\n",
      "Epoch 1380/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1921 - val_accuracy: 0.9263\n",
      "Epoch 1381/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1822 - val_accuracy: 0.9306\n",
      "Epoch 1382/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1707 - val_accuracy: 0.9355\n",
      "Epoch 1383/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1746 - val_accuracy: 0.9340\n",
      "Epoch 1384/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9324 - val_loss: 0.1822 - val_accuracy: 0.9323\n",
      "Epoch 1385/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1826 - val_accuracy: 0.9318\n",
      "Epoch 1386/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1875 - val_accuracy: 0.9291\n",
      "Epoch 1387/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1802 - val_accuracy: 0.9319\n",
      "Epoch 1388/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1832 - val_accuracy: 0.9307\n",
      "Epoch 1389/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1720 - val_accuracy: 0.9354\n",
      "Epoch 1390/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1900 - val_accuracy: 0.9261\n",
      "Epoch 1391/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1882 - val_accuracy: 0.9282\n",
      "Epoch 1392/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1901 - val_accuracy: 0.9281\n",
      "Epoch 1393/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1763 - val_accuracy: 0.9343\n",
      "Epoch 1394/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1830 - val_accuracy: 0.9303\n",
      "Epoch 1395/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1829 - val_accuracy: 0.9314\n",
      "Epoch 1396/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.2155 - val_accuracy: 0.9162\n",
      "Epoch 1397/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1741 - val_accuracy: 0.9346\n",
      "Epoch 1398/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1895 - val_accuracy: 0.9276\n",
      "Epoch 1399/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1685 - val_accuracy: 0.9371\n",
      "Epoch 1400/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1604 - val_accuracy: 0.9401\n",
      "Epoch 1401/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1744 - val_accuracy: 0.9338\n",
      "Epoch 1402/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1902 - val_accuracy: 0.9278\n",
      "Epoch 1403/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1714 - val_accuracy: 0.9354\n",
      "Epoch 1404/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1735 - val_accuracy: 0.9349\n",
      "Epoch 1405/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1926 - val_accuracy: 0.9273\n",
      "Epoch 1406/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1716 - val_accuracy: 0.9357\n",
      "Epoch 1407/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1841 - val_accuracy: 0.9298\n",
      "Epoch 1408/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9322 - val_loss: 0.1975 - val_accuracy: 0.9238\n",
      "Epoch 1409/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9327 - val_loss: 0.1890 - val_accuracy: 0.9279\n",
      "Epoch 1410/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1870 - val_accuracy: 0.9297\n",
      "Epoch 1411/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1648 - val_accuracy: 0.9382\n",
      "Epoch 1412/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1827 - val_accuracy: 0.9319\n",
      "Epoch 1413/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1828 - val_accuracy: 0.9307\n",
      "Epoch 1414/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1639 - val_accuracy: 0.9385\n",
      "Epoch 1415/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1723 - val_accuracy: 0.9358\n",
      "Epoch 1416/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9328 - val_loss: 0.1769 - val_accuracy: 0.9335\n",
      "Epoch 1417/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1654 - val_accuracy: 0.9392\n",
      "Epoch 1418/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1756 - val_accuracy: 0.9334\n",
      "Epoch 1419/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1891 - val_accuracy: 0.9277\n",
      "Epoch 1420/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1900 - val_accuracy: 0.9262\n",
      "Epoch 1421/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9324 - val_loss: 0.1909 - val_accuracy: 0.9269\n",
      "Epoch 1422/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1897 - val_accuracy: 0.9282\n",
      "Epoch 1423/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1955 - val_accuracy: 0.9264\n",
      "Epoch 1424/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1662 - val_accuracy: 0.9383\n",
      "Epoch 1425/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1834 - val_accuracy: 0.9310\n",
      "Epoch 1426/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1874 - val_accuracy: 0.9280\n",
      "Epoch 1427/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.2105 - val_accuracy: 0.9183\n",
      "Epoch 1428/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1810 - val_accuracy: 0.9318\n",
      "Epoch 1429/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1737 - val_accuracy: 0.9339\n",
      "Epoch 1430/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1790 - val_accuracy: 0.9332\n",
      "Epoch 1431/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1722 - val_accuracy: 0.9355\n",
      "Epoch 1432/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1791 - val_accuracy: 0.9316\n",
      "Epoch 1433/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1886 - val_accuracy: 0.9283\n",
      "Epoch 1434/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1838 - val_accuracy: 0.9308\n",
      "Epoch 1435/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1657 - val_accuracy: 0.9384\n",
      "Epoch 1436/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1822 - val_accuracy: 0.9311\n",
      "Epoch 1437/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1950 - val_accuracy: 0.9249\n",
      "Epoch 1438/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1913 - val_accuracy: 0.9273\n",
      "Epoch 1439/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1916 - val_accuracy: 0.9274\n",
      "Epoch 1440/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1798 - val_accuracy: 0.9325\n",
      "Epoch 1441/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1802 - val_accuracy: 0.9318\n",
      "Epoch 1442/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1835 - val_accuracy: 0.9299\n",
      "Epoch 1443/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1855 - val_accuracy: 0.9302\n",
      "Epoch 1444/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1980 - val_accuracy: 0.9248\n",
      "Epoch 1445/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1874 - val_accuracy: 0.9276\n",
      "Epoch 1446/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1814 - val_accuracy: 0.9308\n",
      "Epoch 1447/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9324 - val_loss: 0.1897 - val_accuracy: 0.9279\n",
      "Epoch 1448/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1759 - val_accuracy: 0.9342\n",
      "Epoch 1449/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1971 - val_accuracy: 0.9257\n",
      "Epoch 1450/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9328 - val_loss: 0.1797 - val_accuracy: 0.9318\n",
      "Epoch 1451/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1878 - val_accuracy: 0.9291\n",
      "Epoch 1452/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1625 - val_accuracy: 0.9400\n",
      "Epoch 1453/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1583 - val_accuracy: 0.9415\n",
      "Epoch 1454/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1696 - val_accuracy: 0.9367\n",
      "Epoch 1455/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1735 - val_accuracy: 0.9351\n",
      "Epoch 1456/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1845 - val_accuracy: 0.9314\n",
      "Epoch 1457/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.2032 - val_accuracy: 0.9213\n",
      "Epoch 1458/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1736 - val_accuracy: 0.9351\n",
      "Epoch 1459/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1870 - val_accuracy: 0.9291\n",
      "Epoch 1460/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9323 - val_loss: 0.1849 - val_accuracy: 0.9302\n",
      "Epoch 1461/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1943 - val_accuracy: 0.9241\n",
      "Epoch 1462/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9324 - val_loss: 0.1611 - val_accuracy: 0.9409\n",
      "Epoch 1463/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1947 - val_accuracy: 0.9264\n",
      "Epoch 1464/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1826 - val_accuracy: 0.9314\n",
      "Epoch 1465/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1901 - val_accuracy: 0.9283\n",
      "Epoch 1466/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1775 - val_accuracy: 0.9334\n",
      "Epoch 1467/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1725 - val_accuracy: 0.9357\n",
      "Epoch 1468/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1712 - val_accuracy: 0.9357\n",
      "Epoch 1469/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1840 - val_accuracy: 0.9305\n",
      "Epoch 1470/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1938 - val_accuracy: 0.9275\n",
      "Epoch 1471/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1813 - val_accuracy: 0.9311\n",
      "Epoch 1472/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1839 - val_accuracy: 0.9295\n",
      "Epoch 1473/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1930 - val_accuracy: 0.9265\n",
      "Epoch 1474/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1924 - val_accuracy: 0.9263\n",
      "Epoch 1475/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1839 - val_accuracy: 0.9309\n",
      "Epoch 1476/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1672 - val_accuracy: 0.9383\n",
      "Epoch 1477/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.2056 - val_accuracy: 0.9207\n",
      "Epoch 1478/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1841 - val_accuracy: 0.9296\n",
      "Epoch 1479/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1794 - val_accuracy: 0.9328\n",
      "Epoch 1480/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1890 - val_accuracy: 0.9285\n",
      "Epoch 1481/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1631 - val_accuracy: 0.9390\n",
      "Epoch 1482/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9324 - val_loss: 0.1809 - val_accuracy: 0.9312\n",
      "Epoch 1483/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1850 - val_accuracy: 0.9293\n",
      "Epoch 1484/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1721 - val_accuracy: 0.9354\n",
      "Epoch 1485/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1798 - val_accuracy: 0.9318\n",
      "Epoch 1486/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9326 - val_loss: 0.1781 - val_accuracy: 0.9325\n",
      "Epoch 1487/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1964 - val_accuracy: 0.9253\n",
      "Epoch 1488/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1969 - val_accuracy: 0.9238\n",
      "Epoch 1489/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1949 - val_accuracy: 0.9246\n",
      "Epoch 1490/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9324 - val_loss: 0.1938 - val_accuracy: 0.9274\n",
      "Epoch 1491/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1784 - val_accuracy: 0.9331\n",
      "Epoch 1492/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1733 - val_accuracy: 0.9348\n",
      "Epoch 1493/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9324 - val_loss: 0.1702 - val_accuracy: 0.9371\n",
      "Epoch 1494/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1976 - val_accuracy: 0.9254\n",
      "Epoch 1495/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1738 - val_accuracy: 0.9340\n",
      "Epoch 1496/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.2002 - val_accuracy: 0.9233\n",
      "Epoch 1497/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1760 - val_accuracy: 0.9336\n",
      "Epoch 1498/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1961 - val_accuracy: 0.9232\n",
      "Epoch 1499/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1886 - val_accuracy: 0.9280\n",
      "Epoch 1500/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1760 - val_accuracy: 0.9340\n",
      "Epoch 1501/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9324 - val_loss: 0.1725 - val_accuracy: 0.9359\n",
      "Epoch 1502/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1849 - val_accuracy: 0.9299\n",
      "Epoch 1503/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1929 - val_accuracy: 0.9272\n",
      "Epoch 1504/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1785 - val_accuracy: 0.9325\n",
      "Epoch 1505/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1802 - val_accuracy: 0.9315\n",
      "Epoch 1506/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1761 - val_accuracy: 0.9327\n",
      "Epoch 1507/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1828 - val_accuracy: 0.9314\n",
      "Epoch 1508/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1864 - val_accuracy: 0.9294\n",
      "Epoch 1509/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9324 - val_loss: 0.1788 - val_accuracy: 0.9332\n",
      "Epoch 1510/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1875 - val_accuracy: 0.9295\n",
      "Epoch 1511/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.2050 - val_accuracy: 0.9228\n",
      "Epoch 1512/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9324 - val_loss: 0.1879 - val_accuracy: 0.9288\n",
      "Epoch 1513/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1813 - val_accuracy: 0.9316\n",
      "Epoch 1514/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1704 - val_accuracy: 0.9367\n",
      "Epoch 1515/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1417 - val_accuracy: 0.9483\n",
      "Epoch 1516/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1909 - val_accuracy: 0.9269\n",
      "Epoch 1517/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1694 - val_accuracy: 0.9363\n",
      "Epoch 1518/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1528 - val_accuracy: 0.9428\n",
      "Epoch 1519/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1916 - val_accuracy: 0.9272\n",
      "Epoch 1520/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.2240 - val_accuracy: 0.9127\n",
      "Epoch 1521/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1704 - val_accuracy: 0.9365\n",
      "Epoch 1522/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1861 - val_accuracy: 0.9299\n",
      "Epoch 1523/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1805 - val_accuracy: 0.9324\n",
      "Epoch 1524/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1867 - val_accuracy: 0.9293\n",
      "Epoch 1525/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1879 - val_accuracy: 0.9290\n",
      "Epoch 1526/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1798 - val_accuracy: 0.9325\n",
      "Epoch 1527/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1777 - val_accuracy: 0.9321\n",
      "Epoch 1528/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1890 - val_accuracy: 0.9278\n",
      "Epoch 1529/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.2010 - val_accuracy: 0.9239\n",
      "Epoch 1530/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9324 - val_loss: 0.1789 - val_accuracy: 0.9325\n",
      "Epoch 1531/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1738 - val_accuracy: 0.9325\n",
      "Epoch 1532/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1716 - val_accuracy: 0.9357\n",
      "Epoch 1533/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1995 - val_accuracy: 0.9235\n",
      "Epoch 1534/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1963 - val_accuracy: 0.9260\n",
      "Epoch 1535/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1863 - val_accuracy: 0.9286\n",
      "Epoch 1536/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1771 - val_accuracy: 0.9333\n",
      "Epoch 1537/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1758 - val_accuracy: 0.9332\n",
      "Epoch 1538/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1798 - val_accuracy: 0.9319\n",
      "Epoch 1539/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1877 - val_accuracy: 0.9279\n",
      "Epoch 1540/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1838 - val_accuracy: 0.9304\n",
      "Epoch 1541/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1792 - val_accuracy: 0.9327\n",
      "Epoch 1542/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.2109 - val_accuracy: 0.9192\n",
      "Epoch 1543/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1824 - val_accuracy: 0.9309\n",
      "Epoch 1544/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1763 - val_accuracy: 0.9332\n",
      "Epoch 1545/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1841 - val_accuracy: 0.9313\n",
      "Epoch 1546/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1923 - val_accuracy: 0.9269\n",
      "Epoch 1547/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1682 - val_accuracy: 0.9375\n",
      "Epoch 1548/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1819 - val_accuracy: 0.9308\n",
      "Epoch 1549/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1768 - val_accuracy: 0.9334\n",
      "Epoch 1550/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1737 - val_accuracy: 0.9346\n",
      "Epoch 1551/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1881 - val_accuracy: 0.9285\n",
      "Epoch 1552/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1673 - val_accuracy: 0.9374\n",
      "Epoch 1553/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1942 - val_accuracy: 0.9261\n",
      "Epoch 1554/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1848 - val_accuracy: 0.9295\n",
      "Epoch 1555/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1938 - val_accuracy: 0.9261\n",
      "Epoch 1556/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1739 - val_accuracy: 0.9360\n",
      "Epoch 1557/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1841 - val_accuracy: 0.9306\n",
      "Epoch 1558/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1798 - val_accuracy: 0.9320\n",
      "Epoch 1559/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1923 - val_accuracy: 0.9266\n",
      "Epoch 1560/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1697 - val_accuracy: 0.9364\n",
      "Epoch 1561/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1711 - val_accuracy: 0.9357\n",
      "Epoch 1562/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1945 - val_accuracy: 0.9258\n",
      "Epoch 1563/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1821 - val_accuracy: 0.9311\n",
      "Epoch 1564/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1645 - val_accuracy: 0.9386\n",
      "Epoch 1565/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1928 - val_accuracy: 0.9267\n",
      "Epoch 1566/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1709 - val_accuracy: 0.9352\n",
      "Epoch 1567/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1925 - val_accuracy: 0.9271\n",
      "Epoch 1568/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1740 - val_accuracy: 0.9351\n",
      "Epoch 1569/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1809 - val_accuracy: 0.9320\n",
      "Epoch 1570/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1775 - val_accuracy: 0.9331\n",
      "Epoch 1571/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1716 - val_accuracy: 0.9366\n",
      "Epoch 1572/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1835 - val_accuracy: 0.9310\n",
      "Epoch 1573/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1873 - val_accuracy: 0.9301\n",
      "Epoch 1574/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1876 - val_accuracy: 0.9292\n",
      "Epoch 1575/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1933 - val_accuracy: 0.9250\n",
      "Epoch 1576/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1829 - val_accuracy: 0.9299\n",
      "Epoch 1577/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1904 - val_accuracy: 0.9273\n",
      "Epoch 1578/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1889 - val_accuracy: 0.9282\n",
      "Epoch 1579/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1729 - val_accuracy: 0.9337\n",
      "Epoch 1580/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1819 - val_accuracy: 0.9306\n",
      "Epoch 1581/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.2114 - val_accuracy: 0.9180\n",
      "Epoch 1582/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1715 - val_accuracy: 0.9354\n",
      "Epoch 1583/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1887 - val_accuracy: 0.9266\n",
      "Epoch 1584/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1828 - val_accuracy: 0.9306\n",
      "Epoch 1585/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1902 - val_accuracy: 0.9281\n",
      "Epoch 1586/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1828 - val_accuracy: 0.9312\n",
      "Epoch 1587/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1837 - val_accuracy: 0.9304\n",
      "Epoch 1588/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1717 - val_accuracy: 0.9361\n",
      "Epoch 1589/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1782 - val_accuracy: 0.9333\n",
      "Epoch 1590/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1916 - val_accuracy: 0.9282\n",
      "Epoch 1591/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1883 - val_accuracy: 0.9286\n",
      "Epoch 1592/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1891 - val_accuracy: 0.9276\n",
      "Epoch 1593/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1704 - val_accuracy: 0.9353\n",
      "Epoch 1594/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1948 - val_accuracy: 0.9268\n",
      "Epoch 1595/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1817 - val_accuracy: 0.9325\n",
      "Epoch 1596/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.2105 - val_accuracy: 0.9187\n",
      "Epoch 1597/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1837 - val_accuracy: 0.9290\n",
      "Epoch 1598/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1820 - val_accuracy: 0.9316\n",
      "Epoch 1599/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1876 - val_accuracy: 0.9290\n",
      "Epoch 1600/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1969 - val_accuracy: 0.9253\n",
      "Epoch 1601/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1762 - val_accuracy: 0.9339\n",
      "Epoch 1602/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1881 - val_accuracy: 0.9276\n",
      "Epoch 1603/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1953 - val_accuracy: 0.9250\n",
      "Epoch 1604/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1864 - val_accuracy: 0.9295\n",
      "Epoch 1605/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9332 - val_loss: 0.1819 - val_accuracy: 0.9308\n",
      "Epoch 1606/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1713 - val_accuracy: 0.9358\n",
      "Epoch 1607/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1968 - val_accuracy: 0.9239\n",
      "Epoch 1608/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1999 - val_accuracy: 0.9239\n",
      "Epoch 1609/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1937 - val_accuracy: 0.9260\n",
      "Epoch 1610/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1733 - val_accuracy: 0.9345\n",
      "Epoch 1611/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1776 - val_accuracy: 0.9328\n",
      "Epoch 1612/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1700 - val_accuracy: 0.9360\n",
      "Epoch 1613/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1806 - val_accuracy: 0.9314\n",
      "Epoch 1614/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1884 - val_accuracy: 0.9277\n",
      "Epoch 1615/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9324 - val_loss: 0.1928 - val_accuracy: 0.9276\n",
      "Epoch 1616/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1965 - val_accuracy: 0.9252\n",
      "Epoch 1617/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1914 - val_accuracy: 0.9277\n",
      "Epoch 1618/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1744 - val_accuracy: 0.9334\n",
      "Epoch 1619/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1866 - val_accuracy: 0.9298\n",
      "Epoch 1620/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1816 - val_accuracy: 0.9321\n",
      "Epoch 1621/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1715 - val_accuracy: 0.9351\n",
      "Epoch 1622/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.2001 - val_accuracy: 0.9235\n",
      "Epoch 1623/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9328 - val_loss: 0.1593 - val_accuracy: 0.9408\n",
      "Epoch 1624/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1760 - val_accuracy: 0.9331\n",
      "Epoch 1625/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1646 - val_accuracy: 0.9381\n",
      "Epoch 1626/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1691 - val_accuracy: 0.9365\n",
      "Epoch 1627/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1902 - val_accuracy: 0.9282\n",
      "Epoch 1628/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1760 - val_accuracy: 0.9339\n",
      "Epoch 1629/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1898 - val_accuracy: 0.9280\n",
      "Epoch 1630/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1831 - val_accuracy: 0.9306\n",
      "Epoch 1631/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1859 - val_accuracy: 0.9305\n",
      "Epoch 1632/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1932 - val_accuracy: 0.9257\n",
      "Epoch 1633/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1783 - val_accuracy: 0.9319\n",
      "Epoch 1634/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1849 - val_accuracy: 0.9298\n",
      "Epoch 1635/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1873 - val_accuracy: 0.9280\n",
      "Epoch 1636/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1939 - val_accuracy: 0.9260\n",
      "Epoch 1637/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1871 - val_accuracy: 0.9298\n",
      "Epoch 1638/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1760 - val_accuracy: 0.9331\n",
      "Epoch 1639/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1689 - val_accuracy: 0.9361\n",
      "Epoch 1640/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1586 - val_accuracy: 0.9411\n",
      "Epoch 1641/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1923 - val_accuracy: 0.9265\n",
      "Epoch 1642/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1783 - val_accuracy: 0.9319\n",
      "Epoch 1643/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1787 - val_accuracy: 0.9329\n",
      "Epoch 1644/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.2032 - val_accuracy: 0.9221\n",
      "Epoch 1645/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1645 - val_accuracy: 0.9382\n",
      "Epoch 1646/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1867 - val_accuracy: 0.9289\n",
      "Epoch 1647/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1727 - val_accuracy: 0.9351\n",
      "Epoch 1648/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1845 - val_accuracy: 0.9301\n",
      "Epoch 1649/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1757 - val_accuracy: 0.9343\n",
      "Epoch 1650/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1665 - val_accuracy: 0.9379\n",
      "Epoch 1651/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1808 - val_accuracy: 0.9325\n",
      "Epoch 1652/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1865 - val_accuracy: 0.9298\n",
      "Epoch 1653/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1778 - val_accuracy: 0.9329\n",
      "Epoch 1654/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1899 - val_accuracy: 0.9277\n",
      "Epoch 1655/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1853 - val_accuracy: 0.9300\n",
      "Epoch 1656/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1945 - val_accuracy: 0.9262\n",
      "Epoch 1657/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1901 - val_accuracy: 0.9285\n",
      "Epoch 1658/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.2001 - val_accuracy: 0.9239\n",
      "Epoch 1659/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1898 - val_accuracy: 0.9276\n",
      "Epoch 1660/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1934 - val_accuracy: 0.9272\n",
      "Epoch 1661/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.2062 - val_accuracy: 0.9207\n",
      "Epoch 1662/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1837 - val_accuracy: 0.9298\n",
      "Epoch 1663/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1743 - val_accuracy: 0.9341\n",
      "Epoch 1664/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1956 - val_accuracy: 0.9247\n",
      "Epoch 1665/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1735 - val_accuracy: 0.9343\n",
      "Epoch 1666/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1676 - val_accuracy: 0.9374\n",
      "Epoch 1667/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.2014 - val_accuracy: 0.9231\n",
      "Epoch 1668/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1783 - val_accuracy: 0.9333\n",
      "Epoch 1669/2500\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1838 - val_accuracy: 0.9311\n",
      "Epoch 1670/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1711 - val_accuracy: 0.9356\n",
      "Epoch 1671/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1770 - val_accuracy: 0.9330\n",
      "Epoch 1672/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1747 - val_accuracy: 0.9342\n",
      "Epoch 1673/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1919 - val_accuracy: 0.9275\n",
      "Epoch 1674/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1829 - val_accuracy: 0.9312\n",
      "Epoch 1675/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1860 - val_accuracy: 0.9294\n",
      "Epoch 1676/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9328 - val_loss: 0.1793 - val_accuracy: 0.9318\n",
      "Epoch 1677/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1811 - val_accuracy: 0.9323\n",
      "Epoch 1678/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1730 - val_accuracy: 0.9349\n",
      "Epoch 1679/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1913 - val_accuracy: 0.9260\n",
      "Epoch 1680/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1719 - val_accuracy: 0.9348\n",
      "Epoch 1681/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1801 - val_accuracy: 0.9317\n",
      "Epoch 1682/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1881 - val_accuracy: 0.9281\n",
      "Epoch 1683/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1828 - val_accuracy: 0.9308\n",
      "Epoch 1684/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1724 - val_accuracy: 0.9353\n",
      "Epoch 1685/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1914 - val_accuracy: 0.9276\n",
      "Epoch 1686/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1952 - val_accuracy: 0.9250\n",
      "Epoch 1687/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1927 - val_accuracy: 0.9255\n",
      "Epoch 1688/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1817 - val_accuracy: 0.9308\n",
      "Epoch 1689/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1835 - val_accuracy: 0.9313\n",
      "Epoch 1690/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1769 - val_accuracy: 0.9337\n",
      "Epoch 1691/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1942 - val_accuracy: 0.9261\n",
      "Epoch 1692/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1755 - val_accuracy: 0.9344\n",
      "Epoch 1693/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1806 - val_accuracy: 0.9315\n",
      "Epoch 1694/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1761 - val_accuracy: 0.9336\n",
      "Epoch 1695/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1798 - val_accuracy: 0.9309\n",
      "Epoch 1696/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0067 - accuracy: 0.9325 - val_loss: 0.1807 - val_accuracy: 0.9319\n",
      "Epoch 1697/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1850 - val_accuracy: 0.9303\n",
      "Epoch 1698/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1806 - val_accuracy: 0.9318\n",
      "Epoch 1699/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1847 - val_accuracy: 0.9301\n",
      "Epoch 1700/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1689 - val_accuracy: 0.9358\n",
      "Epoch 1701/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1780 - val_accuracy: 0.9334\n",
      "Epoch 1702/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1934 - val_accuracy: 0.9264\n",
      "Epoch 1703/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1808 - val_accuracy: 0.9317\n",
      "Epoch 1704/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1826 - val_accuracy: 0.9301\n",
      "Epoch 1705/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1764 - val_accuracy: 0.9334\n",
      "Epoch 1706/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1532 - val_accuracy: 0.9431\n",
      "Epoch 1707/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1968 - val_accuracy: 0.9235\n",
      "Epoch 1708/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1898 - val_accuracy: 0.9279\n",
      "Epoch 1709/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1819 - val_accuracy: 0.9305\n",
      "Epoch 1710/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1558 - val_accuracy: 0.9414\n",
      "Epoch 1711/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1811 - val_accuracy: 0.9314\n",
      "Epoch 1712/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1863 - val_accuracy: 0.9292\n",
      "Epoch 1713/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1829 - val_accuracy: 0.9312\n",
      "Epoch 1714/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1918 - val_accuracy: 0.9271\n",
      "Epoch 1715/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1746 - val_accuracy: 0.9338\n",
      "Epoch 1716/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1876 - val_accuracy: 0.9278\n",
      "Epoch 1717/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1950 - val_accuracy: 0.9266\n",
      "Epoch 1718/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1922 - val_accuracy: 0.9268\n",
      "Epoch 1719/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1882 - val_accuracy: 0.9278\n",
      "Epoch 1720/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1767 - val_accuracy: 0.9332\n",
      "Epoch 1721/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1790 - val_accuracy: 0.9328\n",
      "Epoch 1722/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1836 - val_accuracy: 0.9304\n",
      "Epoch 1723/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1778 - val_accuracy: 0.9330\n",
      "Epoch 1724/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1823 - val_accuracy: 0.9316\n",
      "Epoch 1725/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1775 - val_accuracy: 0.9333\n",
      "Epoch 1726/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1836 - val_accuracy: 0.9303\n",
      "Epoch 1727/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1944 - val_accuracy: 0.9265\n",
      "Epoch 1728/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1766 - val_accuracy: 0.9321\n",
      "Epoch 1729/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1757 - val_accuracy: 0.9342\n",
      "Epoch 1730/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1724 - val_accuracy: 0.9354\n",
      "Epoch 1731/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1725 - val_accuracy: 0.9351\n",
      "Epoch 1732/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1986 - val_accuracy: 0.9242\n",
      "Epoch 1733/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1711 - val_accuracy: 0.9353\n",
      "Epoch 1734/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1756 - val_accuracy: 0.9353\n",
      "Epoch 1735/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9332 - val_loss: 0.2244 - val_accuracy: 0.9138\n",
      "Epoch 1736/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1950 - val_accuracy: 0.9255\n",
      "Epoch 1737/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1835 - val_accuracy: 0.9297\n",
      "Epoch 1738/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1775 - val_accuracy: 0.9333\n",
      "Epoch 1739/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1798 - val_accuracy: 0.9322\n",
      "Epoch 1740/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9332 - val_loss: 0.1781 - val_accuracy: 0.9336\n",
      "Epoch 1741/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1806 - val_accuracy: 0.9324\n",
      "Epoch 1742/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1824 - val_accuracy: 0.9307\n",
      "Epoch 1743/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1841 - val_accuracy: 0.9296\n",
      "Epoch 1744/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1808 - val_accuracy: 0.9311\n",
      "Epoch 1745/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1877 - val_accuracy: 0.9281\n",
      "Epoch 1746/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1891 - val_accuracy: 0.9283\n",
      "Epoch 1747/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1659 - val_accuracy: 0.9379\n",
      "Epoch 1748/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1872 - val_accuracy: 0.9281\n",
      "Epoch 1749/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1978 - val_accuracy: 0.9251\n",
      "Epoch 1750/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1817 - val_accuracy: 0.9314\n",
      "Epoch 1751/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1785 - val_accuracy: 0.9334\n",
      "Epoch 1752/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1787 - val_accuracy: 0.9334\n",
      "Epoch 1753/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1817 - val_accuracy: 0.9318\n",
      "Epoch 1754/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1841 - val_accuracy: 0.9316\n",
      "Epoch 1755/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1643 - val_accuracy: 0.9390\n",
      "Epoch 1756/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1844 - val_accuracy: 0.9312\n",
      "Epoch 1757/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1812 - val_accuracy: 0.9318\n",
      "Epoch 1758/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9332 - val_loss: 0.1908 - val_accuracy: 0.9269\n",
      "Epoch 1759/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1840 - val_accuracy: 0.9290\n",
      "Epoch 1760/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1728 - val_accuracy: 0.9360\n",
      "Epoch 1761/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9332 - val_loss: 0.1705 - val_accuracy: 0.9352\n",
      "Epoch 1762/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1741 - val_accuracy: 0.9341\n",
      "Epoch 1763/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1813 - val_accuracy: 0.9316\n",
      "Epoch 1764/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1816 - val_accuracy: 0.9318\n",
      "Epoch 1765/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1963 - val_accuracy: 0.9250\n",
      "Epoch 1766/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1769 - val_accuracy: 0.9332\n",
      "Epoch 1767/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1753 - val_accuracy: 0.9340\n",
      "Epoch 1768/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1891 - val_accuracy: 0.9282\n",
      "Epoch 1769/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1841 - val_accuracy: 0.9300\n",
      "Epoch 1770/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1909 - val_accuracy: 0.9274\n",
      "Epoch 1771/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1684 - val_accuracy: 0.9367\n",
      "Epoch 1772/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1688 - val_accuracy: 0.9360\n",
      "Epoch 1773/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1843 - val_accuracy: 0.9305\n",
      "Epoch 1774/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1836 - val_accuracy: 0.9290\n",
      "Epoch 1775/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1766 - val_accuracy: 0.9338\n",
      "Epoch 1776/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1736 - val_accuracy: 0.9343\n",
      "Epoch 1777/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1851 - val_accuracy: 0.9298\n",
      "Epoch 1778/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1683 - val_accuracy: 0.9364\n",
      "Epoch 1779/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1792 - val_accuracy: 0.9332\n",
      "Epoch 1780/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1851 - val_accuracy: 0.9300\n",
      "Epoch 1781/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9332 - val_loss: 0.1888 - val_accuracy: 0.9283\n",
      "Epoch 1782/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1846 - val_accuracy: 0.9309\n",
      "Epoch 1783/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1926 - val_accuracy: 0.9261\n",
      "Epoch 1784/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1853 - val_accuracy: 0.9301\n",
      "Epoch 1785/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1897 - val_accuracy: 0.9287\n",
      "Epoch 1786/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1715 - val_accuracy: 0.9358\n",
      "Epoch 1787/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9332 - val_loss: 0.1982 - val_accuracy: 0.9239\n",
      "Epoch 1788/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1736 - val_accuracy: 0.9347\n",
      "Epoch 1789/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1787 - val_accuracy: 0.9323\n",
      "Epoch 1790/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1905 - val_accuracy: 0.9263\n",
      "Epoch 1791/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1754 - val_accuracy: 0.9332\n",
      "Epoch 1792/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1694 - val_accuracy: 0.9368\n",
      "Epoch 1793/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1825 - val_accuracy: 0.9300\n",
      "Epoch 1794/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1770 - val_accuracy: 0.9330\n",
      "Epoch 1795/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1663 - val_accuracy: 0.9373\n",
      "Epoch 1796/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1882 - val_accuracy: 0.9283\n",
      "Epoch 1797/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1878 - val_accuracy: 0.9295\n",
      "Epoch 1798/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.2002 - val_accuracy: 0.9237\n",
      "Epoch 1799/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1721 - val_accuracy: 0.9347\n",
      "Epoch 1800/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1808 - val_accuracy: 0.9324\n",
      "Epoch 1801/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1822 - val_accuracy: 0.9307\n",
      "Epoch 1802/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1707 - val_accuracy: 0.9361\n",
      "Epoch 1803/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1963 - val_accuracy: 0.9258\n",
      "Epoch 1804/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1727 - val_accuracy: 0.9354\n",
      "Epoch 1805/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1785 - val_accuracy: 0.9329\n",
      "Epoch 1806/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1862 - val_accuracy: 0.9302\n",
      "Epoch 1807/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1735 - val_accuracy: 0.9346\n",
      "Epoch 1808/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1748 - val_accuracy: 0.9335\n",
      "Epoch 1809/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1965 - val_accuracy: 0.9252\n",
      "Epoch 1810/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9333 - val_loss: 0.1751 - val_accuracy: 0.9339\n",
      "Epoch 1811/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1866 - val_accuracy: 0.9291\n",
      "Epoch 1812/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1959 - val_accuracy: 0.9256\n",
      "Epoch 1813/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1844 - val_accuracy: 0.9306\n",
      "Epoch 1814/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1656 - val_accuracy: 0.9372\n",
      "Epoch 1815/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1701 - val_accuracy: 0.9368\n",
      "Epoch 1816/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1867 - val_accuracy: 0.9298\n",
      "Epoch 1817/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1783 - val_accuracy: 0.9329\n",
      "Epoch 1818/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1828 - val_accuracy: 0.9297\n",
      "Epoch 1819/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1769 - val_accuracy: 0.9328\n",
      "Epoch 1820/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1849 - val_accuracy: 0.9304\n",
      "Epoch 1821/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1697 - val_accuracy: 0.9362\n",
      "Epoch 1822/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1802 - val_accuracy: 0.9324\n",
      "Epoch 1823/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1704 - val_accuracy: 0.9363\n",
      "Epoch 1824/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1888 - val_accuracy: 0.9270\n",
      "Epoch 1825/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1712 - val_accuracy: 0.9358\n",
      "Epoch 1826/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1892 - val_accuracy: 0.9287\n",
      "Epoch 1827/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1887 - val_accuracy: 0.9276\n",
      "Epoch 1828/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1783 - val_accuracy: 0.9327\n",
      "Epoch 1829/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1793 - val_accuracy: 0.9319\n",
      "Epoch 1830/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1690 - val_accuracy: 0.9366\n",
      "Epoch 1831/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1890 - val_accuracy: 0.9276\n",
      "Epoch 1832/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1764 - val_accuracy: 0.9341\n",
      "Epoch 1833/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1636 - val_accuracy: 0.9376\n",
      "Epoch 1834/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1885 - val_accuracy: 0.9287\n",
      "Epoch 1835/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1923 - val_accuracy: 0.9270\n",
      "Epoch 1836/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1864 - val_accuracy: 0.9295\n",
      "Epoch 1837/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1740 - val_accuracy: 0.9343\n",
      "Epoch 1838/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1747 - val_accuracy: 0.9337\n",
      "Epoch 1839/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1934 - val_accuracy: 0.9269\n",
      "Epoch 1840/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9323 - val_loss: 0.1767 - val_accuracy: 0.9325\n",
      "Epoch 1841/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1930 - val_accuracy: 0.9247\n",
      "Epoch 1842/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9332 - val_loss: 0.1835 - val_accuracy: 0.9302\n",
      "Epoch 1843/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1930 - val_accuracy: 0.9258\n",
      "Epoch 1844/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1910 - val_accuracy: 0.9269\n",
      "Epoch 1845/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1906 - val_accuracy: 0.9281\n",
      "Epoch 1846/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9328 - val_loss: 0.1881 - val_accuracy: 0.9281\n",
      "Epoch 1847/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1726 - val_accuracy: 0.9353\n",
      "Epoch 1848/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1872 - val_accuracy: 0.9284\n",
      "Epoch 1849/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1881 - val_accuracy: 0.9290\n",
      "Epoch 1850/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1840 - val_accuracy: 0.9306\n",
      "Epoch 1851/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1930 - val_accuracy: 0.9257\n",
      "Epoch 1852/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1785 - val_accuracy: 0.9322\n",
      "Epoch 1853/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9324 - val_loss: 0.1876 - val_accuracy: 0.9291\n",
      "Epoch 1854/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1769 - val_accuracy: 0.9323\n",
      "Epoch 1855/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1792 - val_accuracy: 0.9312\n",
      "Epoch 1856/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1916 - val_accuracy: 0.9266\n",
      "Epoch 1857/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1938 - val_accuracy: 0.9253\n",
      "Epoch 1858/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1824 - val_accuracy: 0.9319\n",
      "Epoch 1859/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1729 - val_accuracy: 0.9343\n",
      "Epoch 1860/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1878 - val_accuracy: 0.9288\n",
      "Epoch 1861/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1947 - val_accuracy: 0.9253\n",
      "Epoch 1862/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1828 - val_accuracy: 0.9299\n",
      "Epoch 1863/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1914 - val_accuracy: 0.9266\n",
      "Epoch 1864/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1786 - val_accuracy: 0.9323\n",
      "Epoch 1865/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1862 - val_accuracy: 0.9288\n",
      "Epoch 1866/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1895 - val_accuracy: 0.9290\n",
      "Epoch 1867/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1973 - val_accuracy: 0.9248\n",
      "Epoch 1868/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1783 - val_accuracy: 0.9329\n",
      "Epoch 1869/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1816 - val_accuracy: 0.9317\n",
      "Epoch 1870/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1727 - val_accuracy: 0.9354\n",
      "Epoch 1871/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1925 - val_accuracy: 0.9264\n",
      "Epoch 1872/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1817 - val_accuracy: 0.9317\n",
      "Epoch 1873/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1621 - val_accuracy: 0.9395\n",
      "Epoch 1874/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1849 - val_accuracy: 0.9295\n",
      "Epoch 1875/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1786 - val_accuracy: 0.9322\n",
      "Epoch 1876/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1925 - val_accuracy: 0.9261\n",
      "Epoch 1877/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1774 - val_accuracy: 0.9328\n",
      "Epoch 1878/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1903 - val_accuracy: 0.9266\n",
      "Epoch 1879/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1934 - val_accuracy: 0.9263\n",
      "Epoch 1880/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1924 - val_accuracy: 0.9249\n",
      "Epoch 1881/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1826 - val_accuracy: 0.9321\n",
      "Epoch 1882/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1875 - val_accuracy: 0.9275\n",
      "Epoch 1883/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1844 - val_accuracy: 0.9308\n",
      "Epoch 1884/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1733 - val_accuracy: 0.9345\n",
      "Epoch 1885/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1776 - val_accuracy: 0.9332\n",
      "Epoch 1886/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1742 - val_accuracy: 0.9334\n",
      "Epoch 1887/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1817 - val_accuracy: 0.9310\n",
      "Epoch 1888/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1735 - val_accuracy: 0.9351\n",
      "Epoch 1889/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9324 - val_loss: 0.1853 - val_accuracy: 0.9301\n",
      "Epoch 1890/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1804 - val_accuracy: 0.9320\n",
      "Epoch 1891/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1855 - val_accuracy: 0.9288\n",
      "Epoch 1892/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1780 - val_accuracy: 0.9328\n",
      "Epoch 1893/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.2023 - val_accuracy: 0.9238\n",
      "Epoch 1894/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1879 - val_accuracy: 0.9288\n",
      "Epoch 1895/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1840 - val_accuracy: 0.9297\n",
      "Epoch 1896/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1977 - val_accuracy: 0.9254\n",
      "Epoch 1897/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0065 - accuracy: 0.9328 - val_loss: 0.1699 - val_accuracy: 0.9351\n",
      "Epoch 1898/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1786 - val_accuracy: 0.9308\n",
      "Epoch 1899/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1814 - val_accuracy: 0.9311\n",
      "Epoch 1900/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1744 - val_accuracy: 0.9339\n",
      "Epoch 1901/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1741 - val_accuracy: 0.9340\n",
      "Epoch 1902/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1841 - val_accuracy: 0.9305\n",
      "Epoch 1903/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1721 - val_accuracy: 0.9362\n",
      "Epoch 1904/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1674 - val_accuracy: 0.9372\n",
      "Epoch 1905/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1912 - val_accuracy: 0.9268\n",
      "Epoch 1906/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1792 - val_accuracy: 0.9318\n",
      "Epoch 1907/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1801 - val_accuracy: 0.9320\n",
      "Epoch 1908/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1946 - val_accuracy: 0.9257\n",
      "Epoch 1909/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1765 - val_accuracy: 0.9327\n",
      "Epoch 1910/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1763 - val_accuracy: 0.9347\n",
      "Epoch 1911/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9323 - val_loss: 0.1881 - val_accuracy: 0.9294\n",
      "Epoch 1912/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1906 - val_accuracy: 0.9277\n",
      "Epoch 1913/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1872 - val_accuracy: 0.9284\n",
      "Epoch 1914/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1829 - val_accuracy: 0.9300\n",
      "Epoch 1915/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1801 - val_accuracy: 0.9318\n",
      "Epoch 1916/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1655 - val_accuracy: 0.9386\n",
      "Epoch 1917/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1735 - val_accuracy: 0.9356\n",
      "Epoch 1918/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1821 - val_accuracy: 0.9321\n",
      "Epoch 1919/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1734 - val_accuracy: 0.9348\n",
      "Epoch 1920/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1632 - val_accuracy: 0.9390\n",
      "Epoch 1921/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1800 - val_accuracy: 0.9319\n",
      "Epoch 1922/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1906 - val_accuracy: 0.9278\n",
      "Epoch 1923/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1782 - val_accuracy: 0.9329\n",
      "Epoch 1924/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.2043 - val_accuracy: 0.9225\n",
      "Epoch 1925/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1707 - val_accuracy: 0.9355\n",
      "Epoch 1926/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1675 - val_accuracy: 0.9377\n",
      "Epoch 1927/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1742 - val_accuracy: 0.9340\n",
      "Epoch 1928/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1861 - val_accuracy: 0.9288\n",
      "Epoch 1929/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1733 - val_accuracy: 0.9349\n",
      "Epoch 1930/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1762 - val_accuracy: 0.9325\n",
      "Epoch 1931/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1699 - val_accuracy: 0.9363\n",
      "Epoch 1932/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1930 - val_accuracy: 0.9263\n",
      "Epoch 1933/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1879 - val_accuracy: 0.9279\n",
      "Epoch 1934/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1710 - val_accuracy: 0.9360\n",
      "Epoch 1935/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1811 - val_accuracy: 0.9317\n",
      "Epoch 1936/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1718 - val_accuracy: 0.9359\n",
      "Epoch 1937/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1878 - val_accuracy: 0.9299\n",
      "Epoch 1938/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1695 - val_accuracy: 0.9367\n",
      "Epoch 1939/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1657 - val_accuracy: 0.9384\n",
      "Epoch 1940/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1771 - val_accuracy: 0.9338\n",
      "Epoch 1941/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9328 - val_loss: 0.1919 - val_accuracy: 0.9267\n",
      "Epoch 1942/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1759 - val_accuracy: 0.9341\n",
      "Epoch 1943/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1785 - val_accuracy: 0.9325\n",
      "Epoch 1944/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1816 - val_accuracy: 0.9312\n",
      "Epoch 1945/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1921 - val_accuracy: 0.9268\n",
      "Epoch 1946/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1846 - val_accuracy: 0.9297\n",
      "Epoch 1947/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1831 - val_accuracy: 0.9300\n",
      "Epoch 1948/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1825 - val_accuracy: 0.9304\n",
      "Epoch 1949/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9327 - val_loss: 0.1669 - val_accuracy: 0.9386\n",
      "Epoch 1950/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1859 - val_accuracy: 0.9285\n",
      "Epoch 1951/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1847 - val_accuracy: 0.9306\n",
      "Epoch 1952/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1945 - val_accuracy: 0.9252\n",
      "Epoch 1953/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.2151 - val_accuracy: 0.9164\n",
      "Epoch 1954/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1764 - val_accuracy: 0.9337\n",
      "Epoch 1955/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1929 - val_accuracy: 0.9265\n",
      "Epoch 1956/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1720 - val_accuracy: 0.9358\n",
      "Epoch 1957/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1609 - val_accuracy: 0.9404\n",
      "Epoch 1958/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1821 - val_accuracy: 0.9305\n",
      "Epoch 1959/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1875 - val_accuracy: 0.9286\n",
      "Epoch 1960/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1956 - val_accuracy: 0.9243\n",
      "Epoch 1961/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1850 - val_accuracy: 0.9301\n",
      "Epoch 1962/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1603 - val_accuracy: 0.9393\n",
      "Epoch 1963/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1770 - val_accuracy: 0.9344\n",
      "Epoch 1964/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1927 - val_accuracy: 0.9268\n",
      "Epoch 1965/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1808 - val_accuracy: 0.9311\n",
      "Epoch 1966/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9332 - val_loss: 0.1884 - val_accuracy: 0.9287\n",
      "Epoch 1967/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1733 - val_accuracy: 0.9353\n",
      "Epoch 1968/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1861 - val_accuracy: 0.9302\n",
      "Epoch 1969/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1766 - val_accuracy: 0.9337\n",
      "Epoch 1970/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1665 - val_accuracy: 0.9374\n",
      "Epoch 1971/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1866 - val_accuracy: 0.9290\n",
      "Epoch 1972/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1701 - val_accuracy: 0.9362\n",
      "Epoch 1973/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1798 - val_accuracy: 0.9320\n",
      "Epoch 1974/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1825 - val_accuracy: 0.9310\n",
      "Epoch 1975/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1966 - val_accuracy: 0.9252\n",
      "Epoch 1976/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1908 - val_accuracy: 0.9291\n",
      "Epoch 1977/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1771 - val_accuracy: 0.9330\n",
      "Epoch 1978/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1756 - val_accuracy: 0.9345\n",
      "Epoch 1979/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1807 - val_accuracy: 0.9315\n",
      "Epoch 1980/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1827 - val_accuracy: 0.9316\n",
      "Epoch 1981/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1858 - val_accuracy: 0.9289\n",
      "Epoch 1982/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1756 - val_accuracy: 0.9343\n",
      "Epoch 1983/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.2056 - val_accuracy: 0.9222\n",
      "Epoch 1984/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1763 - val_accuracy: 0.9342\n",
      "Epoch 1985/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1781 - val_accuracy: 0.9320\n",
      "Epoch 1986/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1825 - val_accuracy: 0.9304\n",
      "Epoch 1987/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1766 - val_accuracy: 0.9336\n",
      "Epoch 1988/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1910 - val_accuracy: 0.9273\n",
      "Epoch 1989/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1855 - val_accuracy: 0.9299\n",
      "Epoch 1990/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.2055 - val_accuracy: 0.9209\n",
      "Epoch 1991/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1656 - val_accuracy: 0.9388\n",
      "Epoch 1992/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1756 - val_accuracy: 0.9336\n",
      "Epoch 1993/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1848 - val_accuracy: 0.9292\n",
      "Epoch 1994/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1892 - val_accuracy: 0.9291\n",
      "Epoch 1995/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1888 - val_accuracy: 0.9284\n",
      "Epoch 1996/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.1850 - val_accuracy: 0.9310\n",
      "Epoch 1997/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1741 - val_accuracy: 0.9340\n",
      "Epoch 1998/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1700 - val_accuracy: 0.9370\n",
      "Epoch 1999/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1930 - val_accuracy: 0.9250\n",
      "Epoch 2000/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.2009 - val_accuracy: 0.9234\n",
      "Epoch 2001/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1953 - val_accuracy: 0.9253\n",
      "Epoch 2002/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1955 - val_accuracy: 0.9264\n",
      "Epoch 2003/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1669 - val_accuracy: 0.9379\n",
      "Epoch 2004/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1878 - val_accuracy: 0.9295\n",
      "Epoch 2005/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1858 - val_accuracy: 0.9297\n",
      "Epoch 2006/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1762 - val_accuracy: 0.9334\n",
      "Epoch 2007/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1659 - val_accuracy: 0.9386\n",
      "Epoch 2008/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1879 - val_accuracy: 0.9295\n",
      "Epoch 2009/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1743 - val_accuracy: 0.9348\n",
      "Epoch 2010/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1988 - val_accuracy: 0.9237\n",
      "Epoch 2011/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1685 - val_accuracy: 0.9365\n",
      "Epoch 2012/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1838 - val_accuracy: 0.9297\n",
      "Epoch 2013/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1694 - val_accuracy: 0.9368\n",
      "Epoch 2014/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1708 - val_accuracy: 0.9363\n",
      "Epoch 2015/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1750 - val_accuracy: 0.9337\n",
      "Epoch 2016/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1742 - val_accuracy: 0.9347\n",
      "Epoch 2017/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1946 - val_accuracy: 0.9252\n",
      "Epoch 2018/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1852 - val_accuracy: 0.9293\n",
      "Epoch 2019/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1824 - val_accuracy: 0.9304\n",
      "Epoch 2020/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1791 - val_accuracy: 0.9319\n",
      "Epoch 2021/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1889 - val_accuracy: 0.9283\n",
      "Epoch 2022/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9325 - val_loss: 0.1707 - val_accuracy: 0.9367\n",
      "Epoch 2023/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9328 - val_loss: 0.1667 - val_accuracy: 0.9378\n",
      "Epoch 2024/2500\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1933 - val_accuracy: 0.9266\n",
      "Epoch 2025/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1684 - val_accuracy: 0.9371\n",
      "Epoch 2026/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1676 - val_accuracy: 0.9373\n",
      "Epoch 2027/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1883 - val_accuracy: 0.9278\n",
      "Epoch 2028/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1763 - val_accuracy: 0.9331\n",
      "Epoch 2029/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1650 - val_accuracy: 0.9391\n",
      "Epoch 2030/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1769 - val_accuracy: 0.9334\n",
      "Epoch 2031/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1729 - val_accuracy: 0.9353\n",
      "Epoch 2032/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9327 - val_loss: 0.1877 - val_accuracy: 0.9296\n",
      "Epoch 2033/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1897 - val_accuracy: 0.9277\n",
      "Epoch 2034/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1725 - val_accuracy: 0.9354\n",
      "Epoch 2035/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1715 - val_accuracy: 0.9342\n",
      "Epoch 2036/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0066 - accuracy: 0.9331 - val_loss: 0.2113 - val_accuracy: 0.9197\n",
      "Epoch 2037/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1876 - val_accuracy: 0.9277\n",
      "Epoch 2038/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1928 - val_accuracy: 0.9271\n",
      "Epoch 2039/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1950 - val_accuracy: 0.9259\n",
      "Epoch 2040/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1741 - val_accuracy: 0.9346\n",
      "Epoch 2041/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1921 - val_accuracy: 0.9267\n",
      "Epoch 2042/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1905 - val_accuracy: 0.9273\n",
      "Epoch 2043/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1871 - val_accuracy: 0.9289\n",
      "Epoch 2044/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1823 - val_accuracy: 0.9313\n",
      "Epoch 2045/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1649 - val_accuracy: 0.9384\n",
      "Epoch 2046/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1963 - val_accuracy: 0.9252\n",
      "Epoch 2047/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1716 - val_accuracy: 0.9352\n",
      "Epoch 2048/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9327 - val_loss: 0.1631 - val_accuracy: 0.9389\n",
      "Epoch 2049/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1878 - val_accuracy: 0.9280\n",
      "Epoch 2050/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1932 - val_accuracy: 0.9256\n",
      "Epoch 2051/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1730 - val_accuracy: 0.9341\n",
      "Epoch 2052/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1825 - val_accuracy: 0.9304\n",
      "Epoch 2053/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1862 - val_accuracy: 0.9286\n",
      "Epoch 2054/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1807 - val_accuracy: 0.9316\n",
      "Epoch 2055/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1941 - val_accuracy: 0.9256\n",
      "Epoch 2056/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1751 - val_accuracy: 0.9352\n",
      "Epoch 2057/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1579 - val_accuracy: 0.9411\n",
      "Epoch 2058/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1838 - val_accuracy: 0.9309\n",
      "Epoch 2059/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1723 - val_accuracy: 0.9351\n",
      "Epoch 2060/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1759 - val_accuracy: 0.9335\n",
      "Epoch 2061/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1863 - val_accuracy: 0.9291\n",
      "Epoch 2062/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1989 - val_accuracy: 0.9244\n",
      "Epoch 2063/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1871 - val_accuracy: 0.9289\n",
      "Epoch 2064/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1717 - val_accuracy: 0.9354\n",
      "Epoch 2065/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1696 - val_accuracy: 0.9357\n",
      "Epoch 2066/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.2035 - val_accuracy: 0.9233\n",
      "Epoch 2067/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1820 - val_accuracy: 0.9307\n",
      "Epoch 2068/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9328 - val_loss: 0.1806 - val_accuracy: 0.9318\n",
      "Epoch 2069/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1732 - val_accuracy: 0.9345\n",
      "Epoch 2070/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1875 - val_accuracy: 0.9299\n",
      "Epoch 2071/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9330 - val_loss: 0.1842 - val_accuracy: 0.9303\n",
      "Epoch 2072/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1665 - val_accuracy: 0.9378\n",
      "Epoch 2073/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1905 - val_accuracy: 0.9279\n",
      "Epoch 2074/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1818 - val_accuracy: 0.9315\n",
      "Epoch 2075/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1856 - val_accuracy: 0.9298\n",
      "Epoch 2076/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1806 - val_accuracy: 0.9318\n",
      "Epoch 2077/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.2029 - val_accuracy: 0.9212\n",
      "Epoch 2078/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1637 - val_accuracy: 0.9389\n",
      "Epoch 2079/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1869 - val_accuracy: 0.9298\n",
      "Epoch 2080/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1748 - val_accuracy: 0.9336\n",
      "Epoch 2081/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1800 - val_accuracy: 0.9320\n",
      "Epoch 2082/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1784 - val_accuracy: 0.9329\n",
      "Epoch 2083/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1694 - val_accuracy: 0.9367\n",
      "Epoch 2084/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1702 - val_accuracy: 0.9354\n",
      "Epoch 2085/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1901 - val_accuracy: 0.9282\n",
      "Epoch 2086/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1663 - val_accuracy: 0.9377\n",
      "Epoch 2087/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1898 - val_accuracy: 0.9270\n",
      "Epoch 2088/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1663 - val_accuracy: 0.9380\n",
      "Epoch 2089/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1991 - val_accuracy: 0.9249\n",
      "Epoch 2090/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1806 - val_accuracy: 0.9315\n",
      "Epoch 2091/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1896 - val_accuracy: 0.9280\n",
      "Epoch 2092/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1850 - val_accuracy: 0.9309\n",
      "Epoch 2093/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1739 - val_accuracy: 0.9337\n",
      "Epoch 2094/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1713 - val_accuracy: 0.9358\n",
      "Epoch 2095/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1872 - val_accuracy: 0.9293\n",
      "Epoch 2096/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1692 - val_accuracy: 0.9374\n",
      "Epoch 2097/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1900 - val_accuracy: 0.9272\n",
      "Epoch 2098/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1625 - val_accuracy: 0.9396\n",
      "Epoch 2099/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1912 - val_accuracy: 0.9265\n",
      "Epoch 2100/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1907 - val_accuracy: 0.9277\n",
      "Epoch 2101/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1886 - val_accuracy: 0.9274\n",
      "Epoch 2102/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.2004 - val_accuracy: 0.9227\n",
      "Epoch 2103/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1763 - val_accuracy: 0.9339\n",
      "Epoch 2104/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1713 - val_accuracy: 0.9356\n",
      "Epoch 2105/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1845 - val_accuracy: 0.9299\n",
      "Epoch 2106/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.2103 - val_accuracy: 0.9185\n",
      "Epoch 2107/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1597 - val_accuracy: 0.9411\n",
      "Epoch 2108/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1688 - val_accuracy: 0.9359\n",
      "Epoch 2109/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1851 - val_accuracy: 0.9297\n",
      "Epoch 2110/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1734 - val_accuracy: 0.9352\n",
      "Epoch 2111/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1767 - val_accuracy: 0.9335\n",
      "Epoch 2112/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1734 - val_accuracy: 0.9347\n",
      "Epoch 2113/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1761 - val_accuracy: 0.9337\n",
      "Epoch 2114/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9328 - val_loss: 0.1808 - val_accuracy: 0.9305\n",
      "Epoch 2115/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1947 - val_accuracy: 0.9273\n",
      "Epoch 2116/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1711 - val_accuracy: 0.9349\n",
      "Epoch 2117/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1724 - val_accuracy: 0.9353\n",
      "Epoch 2118/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1735 - val_accuracy: 0.9340\n",
      "Epoch 2119/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1644 - val_accuracy: 0.9380\n",
      "Epoch 2120/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1815 - val_accuracy: 0.9317\n",
      "Epoch 2121/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.2035 - val_accuracy: 0.9221\n",
      "Epoch 2122/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1838 - val_accuracy: 0.9319\n",
      "Epoch 2123/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1693 - val_accuracy: 0.9362\n",
      "Epoch 2124/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.2129 - val_accuracy: 0.9184\n",
      "Epoch 2125/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1873 - val_accuracy: 0.9286\n",
      "Epoch 2126/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1909 - val_accuracy: 0.9281\n",
      "Epoch 2127/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1737 - val_accuracy: 0.9348\n",
      "Epoch 2128/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1776 - val_accuracy: 0.9322\n",
      "Epoch 2129/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1704 - val_accuracy: 0.9362\n",
      "Epoch 2130/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1780 - val_accuracy: 0.9329\n",
      "Epoch 2131/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1663 - val_accuracy: 0.9371\n",
      "Epoch 2132/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1757 - val_accuracy: 0.9341\n",
      "Epoch 2133/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1731 - val_accuracy: 0.9355\n",
      "Epoch 2134/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1700 - val_accuracy: 0.9362\n",
      "Epoch 2135/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1970 - val_accuracy: 0.9245\n",
      "Epoch 2136/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1630 - val_accuracy: 0.9398\n",
      "Epoch 2137/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1937 - val_accuracy: 0.9272\n",
      "Epoch 2138/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1879 - val_accuracy: 0.9299\n",
      "Epoch 2139/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1936 - val_accuracy: 0.9264\n",
      "Epoch 2140/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9322 - val_loss: 0.1699 - val_accuracy: 0.9355\n",
      "Epoch 2141/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.2029 - val_accuracy: 0.9223\n",
      "Epoch 2142/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1841 - val_accuracy: 0.9317\n",
      "Epoch 2143/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1670 - val_accuracy: 0.9368\n",
      "Epoch 2144/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1794 - val_accuracy: 0.9319\n",
      "Epoch 2145/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1844 - val_accuracy: 0.9297\n",
      "Epoch 2146/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1875 - val_accuracy: 0.9289\n",
      "Epoch 2147/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1796 - val_accuracy: 0.9322\n",
      "Epoch 2148/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1768 - val_accuracy: 0.9341\n",
      "Epoch 2149/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1867 - val_accuracy: 0.9296\n",
      "Epoch 2150/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1817 - val_accuracy: 0.9294\n",
      "Epoch 2151/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1875 - val_accuracy: 0.9287\n",
      "Epoch 2152/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1619 - val_accuracy: 0.9395\n",
      "Epoch 2153/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1918 - val_accuracy: 0.9263\n",
      "Epoch 2154/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.2053 - val_accuracy: 0.9218\n",
      "Epoch 2155/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1893 - val_accuracy: 0.9281\n",
      "Epoch 2156/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1656 - val_accuracy: 0.9373\n",
      "Epoch 2157/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1774 - val_accuracy: 0.9333\n",
      "Epoch 2158/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1738 - val_accuracy: 0.9351\n",
      "Epoch 2159/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1889 - val_accuracy: 0.9284\n",
      "Epoch 2160/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1734 - val_accuracy: 0.9348\n",
      "Epoch 2161/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1756 - val_accuracy: 0.9329\n",
      "Epoch 2162/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1780 - val_accuracy: 0.9330\n",
      "Epoch 2163/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1687 - val_accuracy: 0.9364\n",
      "Epoch 2164/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1814 - val_accuracy: 0.9308\n",
      "Epoch 2165/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1980 - val_accuracy: 0.9241\n",
      "Epoch 2166/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1780 - val_accuracy: 0.9326\n",
      "Epoch 2167/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1627 - val_accuracy: 0.9388\n",
      "Epoch 2168/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.2016 - val_accuracy: 0.9226\n",
      "Epoch 2169/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1909 - val_accuracy: 0.9271\n",
      "Epoch 2170/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1951 - val_accuracy: 0.9247\n",
      "Epoch 2171/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1823 - val_accuracy: 0.9315\n",
      "Epoch 2172/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1846 - val_accuracy: 0.9305\n",
      "Epoch 2173/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1838 - val_accuracy: 0.9299\n",
      "Epoch 2174/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.2010 - val_accuracy: 0.9233\n",
      "Epoch 2175/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1784 - val_accuracy: 0.9332\n",
      "Epoch 2176/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1771 - val_accuracy: 0.9326\n",
      "Epoch 2177/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1824 - val_accuracy: 0.9308\n",
      "Epoch 2178/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1930 - val_accuracy: 0.9264\n",
      "Epoch 2179/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1684 - val_accuracy: 0.9367\n",
      "Epoch 2180/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1686 - val_accuracy: 0.9366\n",
      "Epoch 2181/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1706 - val_accuracy: 0.9353\n",
      "Epoch 2182/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1854 - val_accuracy: 0.9303\n",
      "Epoch 2183/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1749 - val_accuracy: 0.9342\n",
      "Epoch 2184/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1944 - val_accuracy: 0.9255\n",
      "Epoch 2185/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1755 - val_accuracy: 0.9342\n",
      "Epoch 2186/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1805 - val_accuracy: 0.9308\n",
      "Epoch 2187/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1716 - val_accuracy: 0.9356\n",
      "Epoch 2188/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1829 - val_accuracy: 0.9303\n",
      "Epoch 2189/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1959 - val_accuracy: 0.9250\n",
      "Epoch 2190/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1875 - val_accuracy: 0.9286\n",
      "Epoch 2191/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1839 - val_accuracy: 0.9304\n",
      "Epoch 2192/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1941 - val_accuracy: 0.9252\n",
      "Epoch 2193/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1837 - val_accuracy: 0.9308\n",
      "Epoch 2194/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1832 - val_accuracy: 0.9306\n",
      "Epoch 2195/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1781 - val_accuracy: 0.9323\n",
      "Epoch 2196/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1815 - val_accuracy: 0.9315\n",
      "Epoch 2197/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1760 - val_accuracy: 0.9334\n",
      "Epoch 2198/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1755 - val_accuracy: 0.9341\n",
      "Epoch 2199/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9328 - val_loss: 0.2018 - val_accuracy: 0.9227\n",
      "Epoch 2200/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1745 - val_accuracy: 0.9340\n",
      "Epoch 2201/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1699 - val_accuracy: 0.9362\n",
      "Epoch 2202/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1810 - val_accuracy: 0.9316\n",
      "Epoch 2203/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1703 - val_accuracy: 0.9361\n",
      "Epoch 2204/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1791 - val_accuracy: 0.9310\n",
      "Epoch 2205/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1954 - val_accuracy: 0.9251\n",
      "Epoch 2206/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1900 - val_accuracy: 0.9284\n",
      "Epoch 2207/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1908 - val_accuracy: 0.9274\n",
      "Epoch 2208/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1796 - val_accuracy: 0.9311\n",
      "Epoch 2209/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1775 - val_accuracy: 0.9326\n",
      "Epoch 2210/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1872 - val_accuracy: 0.9291\n",
      "Epoch 2211/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.2043 - val_accuracy: 0.9215\n",
      "Epoch 2212/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9328 - val_loss: 0.1691 - val_accuracy: 0.9379\n",
      "Epoch 2213/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1605 - val_accuracy: 0.9402\n",
      "Epoch 2214/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.2011 - val_accuracy: 0.9231\n",
      "Epoch 2215/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9327 - val_loss: 0.1765 - val_accuracy: 0.9339\n",
      "Epoch 2216/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1733 - val_accuracy: 0.9339\n",
      "Epoch 2217/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9328 - val_loss: 0.1748 - val_accuracy: 0.9343\n",
      "Epoch 2218/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1744 - val_accuracy: 0.9339\n",
      "Epoch 2219/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1823 - val_accuracy: 0.9321\n",
      "Epoch 2220/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1720 - val_accuracy: 0.9354\n",
      "Epoch 2221/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1938 - val_accuracy: 0.9255\n",
      "Epoch 2222/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1825 - val_accuracy: 0.9305\n",
      "Epoch 2223/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1738 - val_accuracy: 0.9344\n",
      "Epoch 2224/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1888 - val_accuracy: 0.9283\n",
      "Epoch 2225/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1795 - val_accuracy: 0.9316\n",
      "Epoch 2226/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1847 - val_accuracy: 0.9297\n",
      "Epoch 2227/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1927 - val_accuracy: 0.9267\n",
      "Epoch 2228/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1749 - val_accuracy: 0.9331\n",
      "Epoch 2229/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1779 - val_accuracy: 0.9335\n",
      "Epoch 2230/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1645 - val_accuracy: 0.9393\n",
      "Epoch 2231/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1819 - val_accuracy: 0.9312\n",
      "Epoch 2232/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1886 - val_accuracy: 0.9271\n",
      "Epoch 2233/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1802 - val_accuracy: 0.9324\n",
      "Epoch 2234/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1732 - val_accuracy: 0.9352\n",
      "Epoch 2235/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1833 - val_accuracy: 0.9301\n",
      "Epoch 2236/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1762 - val_accuracy: 0.9339\n",
      "Epoch 2237/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1724 - val_accuracy: 0.9345\n",
      "Epoch 2238/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1691 - val_accuracy: 0.9361\n",
      "Epoch 2239/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1943 - val_accuracy: 0.9255\n",
      "Epoch 2240/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9328 - val_loss: 0.1761 - val_accuracy: 0.9327\n",
      "Epoch 2241/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1793 - val_accuracy: 0.9326\n",
      "Epoch 2242/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9327 - val_loss: 0.1853 - val_accuracy: 0.9282\n",
      "Epoch 2243/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1934 - val_accuracy: 0.9254\n",
      "Epoch 2244/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1730 - val_accuracy: 0.9348\n",
      "Epoch 2245/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1812 - val_accuracy: 0.9303\n",
      "Epoch 2246/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1850 - val_accuracy: 0.9302\n",
      "Epoch 2247/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1957 - val_accuracy: 0.9258\n",
      "Epoch 2248/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1971 - val_accuracy: 0.9254\n",
      "Epoch 2249/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1863 - val_accuracy: 0.9286\n",
      "Epoch 2250/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1824 - val_accuracy: 0.9311\n",
      "Epoch 2251/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1687 - val_accuracy: 0.9363\n",
      "Epoch 2252/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1867 - val_accuracy: 0.9290\n",
      "Epoch 2253/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.2058 - val_accuracy: 0.9197\n",
      "Epoch 2254/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1765 - val_accuracy: 0.9345\n",
      "Epoch 2255/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1704 - val_accuracy: 0.9360\n",
      "Epoch 2256/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1736 - val_accuracy: 0.9342\n",
      "Epoch 2257/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1820 - val_accuracy: 0.9306\n",
      "Epoch 2258/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1796 - val_accuracy: 0.9316\n",
      "Epoch 2259/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1920 - val_accuracy: 0.9268\n",
      "Epoch 2260/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1781 - val_accuracy: 0.9319\n",
      "Epoch 2261/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1882 - val_accuracy: 0.9291\n",
      "Epoch 2262/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1839 - val_accuracy: 0.9303\n",
      "Epoch 2263/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1747 - val_accuracy: 0.9337\n",
      "Epoch 2264/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1609 - val_accuracy: 0.9402\n",
      "Epoch 2265/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1804 - val_accuracy: 0.9310\n",
      "Epoch 2266/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1814 - val_accuracy: 0.9306\n",
      "Epoch 2267/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1573 - val_accuracy: 0.9414\n",
      "Epoch 2268/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1645 - val_accuracy: 0.9379\n",
      "Epoch 2269/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1921 - val_accuracy: 0.9274\n",
      "Epoch 2270/2500\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1902 - val_accuracy: 0.9277\n",
      "Epoch 2271/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1683 - val_accuracy: 0.9362\n",
      "Epoch 2272/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1873 - val_accuracy: 0.9292\n",
      "Epoch 2273/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1835 - val_accuracy: 0.9305\n",
      "Epoch 2274/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1614 - val_accuracy: 0.9387\n",
      "Epoch 2275/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1627 - val_accuracy: 0.9393\n",
      "Epoch 2276/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1737 - val_accuracy: 0.9344\n",
      "Epoch 2277/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1896 - val_accuracy: 0.9283\n",
      "Epoch 2278/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1713 - val_accuracy: 0.9349\n",
      "Epoch 2279/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9328 - val_loss: 0.1690 - val_accuracy: 0.9365\n",
      "Epoch 2280/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1600 - val_accuracy: 0.9409\n",
      "Epoch 2281/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1655 - val_accuracy: 0.9377\n",
      "Epoch 2282/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1971 - val_accuracy: 0.9242\n",
      "Epoch 2283/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1681 - val_accuracy: 0.9371\n",
      "Epoch 2284/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1694 - val_accuracy: 0.9365\n",
      "Epoch 2285/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1828 - val_accuracy: 0.9303\n",
      "Epoch 2286/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1813 - val_accuracy: 0.9332\n",
      "Epoch 2287/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1818 - val_accuracy: 0.9312\n",
      "Epoch 2288/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1800 - val_accuracy: 0.9315\n",
      "Epoch 2289/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1809 - val_accuracy: 0.9323\n",
      "Epoch 2290/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1917 - val_accuracy: 0.9270\n",
      "Epoch 2291/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1859 - val_accuracy: 0.9295\n",
      "Epoch 2292/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1802 - val_accuracy: 0.9314\n",
      "Epoch 2293/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1742 - val_accuracy: 0.9344\n",
      "Epoch 2294/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1898 - val_accuracy: 0.9278\n",
      "Epoch 2295/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1790 - val_accuracy: 0.9325\n",
      "Epoch 2296/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.2099 - val_accuracy: 0.9191\n",
      "Epoch 2297/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1747 - val_accuracy: 0.9334\n",
      "Epoch 2298/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1852 - val_accuracy: 0.9296\n",
      "Epoch 2299/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1650 - val_accuracy: 0.9369\n",
      "Epoch 2300/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1654 - val_accuracy: 0.9377\n",
      "Epoch 2301/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1960 - val_accuracy: 0.9241\n",
      "Epoch 2302/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1962 - val_accuracy: 0.9239\n",
      "Epoch 2303/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1871 - val_accuracy: 0.9277\n",
      "Epoch 2304/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1897 - val_accuracy: 0.9271\n",
      "Epoch 2305/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1708 - val_accuracy: 0.9360\n",
      "Epoch 2306/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1666 - val_accuracy: 0.9369\n",
      "Epoch 2307/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1838 - val_accuracy: 0.9306\n",
      "Epoch 2308/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1797 - val_accuracy: 0.9327\n",
      "Epoch 2309/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1814 - val_accuracy: 0.9315\n",
      "Epoch 2310/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1672 - val_accuracy: 0.9363\n",
      "Epoch 2311/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1769 - val_accuracy: 0.9328\n",
      "Epoch 2312/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1890 - val_accuracy: 0.9290\n",
      "Epoch 2313/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1719 - val_accuracy: 0.9352\n",
      "Epoch 2314/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1862 - val_accuracy: 0.9303\n",
      "Epoch 2315/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1767 - val_accuracy: 0.9325\n",
      "Epoch 2316/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1707 - val_accuracy: 0.9353\n",
      "Epoch 2317/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1929 - val_accuracy: 0.9268\n",
      "Epoch 2318/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1720 - val_accuracy: 0.9353\n",
      "Epoch 2319/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1946 - val_accuracy: 0.9259\n",
      "Epoch 2320/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1729 - val_accuracy: 0.9347\n",
      "Epoch 2321/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1668 - val_accuracy: 0.9367\n",
      "Epoch 2322/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1797 - val_accuracy: 0.9329\n",
      "Epoch 2323/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9328 - val_loss: 0.1833 - val_accuracy: 0.9291\n",
      "Epoch 2324/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1798 - val_accuracy: 0.9324\n",
      "Epoch 2325/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1758 - val_accuracy: 0.9328\n",
      "Epoch 2326/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9329 - val_loss: 0.1770 - val_accuracy: 0.9333\n",
      "Epoch 2327/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1781 - val_accuracy: 0.9328\n",
      "Epoch 2328/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1812 - val_accuracy: 0.9308\n",
      "Epoch 2329/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1751 - val_accuracy: 0.9341\n",
      "Epoch 2330/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.2049 - val_accuracy: 0.9212\n",
      "Epoch 2331/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1969 - val_accuracy: 0.9240\n",
      "Epoch 2332/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1562 - val_accuracy: 0.9423\n",
      "Epoch 2333/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1722 - val_accuracy: 0.9352\n",
      "Epoch 2334/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9328 - val_loss: 0.1735 - val_accuracy: 0.9351\n",
      "Epoch 2335/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1871 - val_accuracy: 0.9302\n",
      "Epoch 2336/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1772 - val_accuracy: 0.9334\n",
      "Epoch 2337/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1820 - val_accuracy: 0.9319\n",
      "Epoch 2338/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1836 - val_accuracy: 0.9299\n",
      "Epoch 2339/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1921 - val_accuracy: 0.9257\n",
      "Epoch 2340/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1761 - val_accuracy: 0.9326\n",
      "Epoch 2341/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1862 - val_accuracy: 0.9291\n",
      "Epoch 2342/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1858 - val_accuracy: 0.9297\n",
      "Epoch 2343/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1898 - val_accuracy: 0.9287\n",
      "Epoch 2344/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1783 - val_accuracy: 0.9329\n",
      "Epoch 2345/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1993 - val_accuracy: 0.9244\n",
      "Epoch 2346/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1672 - val_accuracy: 0.9381\n",
      "Epoch 2347/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1825 - val_accuracy: 0.9314\n",
      "Epoch 2348/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1757 - val_accuracy: 0.9337\n",
      "Epoch 2349/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1742 - val_accuracy: 0.9343\n",
      "Epoch 2350/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1850 - val_accuracy: 0.9304\n",
      "Epoch 2351/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1850 - val_accuracy: 0.9298\n",
      "Epoch 2352/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9324 - val_loss: 0.1992 - val_accuracy: 0.9241\n",
      "Epoch 2353/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1800 - val_accuracy: 0.9320\n",
      "Epoch 2354/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1841 - val_accuracy: 0.9293\n",
      "Epoch 2355/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1779 - val_accuracy: 0.9326\n",
      "Epoch 2356/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1831 - val_accuracy: 0.9309\n",
      "Epoch 2357/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1621 - val_accuracy: 0.9392\n",
      "Epoch 2358/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1797 - val_accuracy: 0.9329\n",
      "Epoch 2359/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1848 - val_accuracy: 0.9299\n",
      "Epoch 2360/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9327 - val_loss: 0.1737 - val_accuracy: 0.9343\n",
      "Epoch 2361/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1788 - val_accuracy: 0.9334\n",
      "Epoch 2362/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1895 - val_accuracy: 0.9268\n",
      "Epoch 2363/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1877 - val_accuracy: 0.9288\n",
      "Epoch 2364/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1781 - val_accuracy: 0.9320\n",
      "Epoch 2365/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9328 - val_loss: 0.1784 - val_accuracy: 0.9324\n",
      "Epoch 2366/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1893 - val_accuracy: 0.9270\n",
      "Epoch 2367/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1907 - val_accuracy: 0.9268\n",
      "Epoch 2368/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1613 - val_accuracy: 0.9392\n",
      "Epoch 2369/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1856 - val_accuracy: 0.9302\n",
      "Epoch 2370/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9324 - val_loss: 0.1808 - val_accuracy: 0.9313\n",
      "Epoch 2371/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1682 - val_accuracy: 0.9379\n",
      "Epoch 2372/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1873 - val_accuracy: 0.9285\n",
      "Epoch 2373/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1696 - val_accuracy: 0.9369\n",
      "Epoch 2374/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1775 - val_accuracy: 0.9322\n",
      "Epoch 2375/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1810 - val_accuracy: 0.9315\n",
      "Epoch 2376/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1758 - val_accuracy: 0.9336\n",
      "Epoch 2377/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1971 - val_accuracy: 0.9244\n",
      "Epoch 2378/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1813 - val_accuracy: 0.9318\n",
      "Epoch 2379/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1717 - val_accuracy: 0.9349\n",
      "Epoch 2380/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1739 - val_accuracy: 0.9344\n",
      "Epoch 2381/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1700 - val_accuracy: 0.9360\n",
      "Epoch 2382/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9328 - val_loss: 0.1740 - val_accuracy: 0.9341\n",
      "Epoch 2383/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1687 - val_accuracy: 0.9369\n",
      "Epoch 2384/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1829 - val_accuracy: 0.9315\n",
      "Epoch 2385/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1723 - val_accuracy: 0.9354\n",
      "Epoch 2386/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1706 - val_accuracy: 0.9359\n",
      "Epoch 2387/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1797 - val_accuracy: 0.9325\n",
      "Epoch 2388/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1888 - val_accuracy: 0.9290\n",
      "Epoch 2389/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1656 - val_accuracy: 0.9383\n",
      "Epoch 2390/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1773 - val_accuracy: 0.9331\n",
      "Epoch 2391/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1665 - val_accuracy: 0.9370\n",
      "Epoch 2392/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1769 - val_accuracy: 0.9328\n",
      "Epoch 2393/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9328 - val_loss: 0.1821 - val_accuracy: 0.9312\n",
      "Epoch 2394/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1883 - val_accuracy: 0.9285\n",
      "Epoch 2395/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1923 - val_accuracy: 0.9263\n",
      "Epoch 2396/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1761 - val_accuracy: 0.9343\n",
      "Epoch 2397/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1805 - val_accuracy: 0.9316\n",
      "Epoch 2398/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1755 - val_accuracy: 0.9339\n",
      "Epoch 2399/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1729 - val_accuracy: 0.9349\n",
      "Epoch 2400/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1827 - val_accuracy: 0.9307\n",
      "Epoch 2401/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1726 - val_accuracy: 0.9337\n",
      "Epoch 2402/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9327 - val_loss: 0.1883 - val_accuracy: 0.9284\n",
      "Epoch 2403/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1842 - val_accuracy: 0.9308\n",
      "Epoch 2404/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1871 - val_accuracy: 0.9282\n",
      "Epoch 2405/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1713 - val_accuracy: 0.9357\n",
      "Epoch 2406/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1858 - val_accuracy: 0.9308\n",
      "Epoch 2407/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1735 - val_accuracy: 0.9346\n",
      "Epoch 2408/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1792 - val_accuracy: 0.9317\n",
      "Epoch 2409/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1993 - val_accuracy: 0.9229\n",
      "Epoch 2410/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1833 - val_accuracy: 0.9303\n",
      "Epoch 2411/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1696 - val_accuracy: 0.9355\n",
      "Epoch 2412/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1769 - val_accuracy: 0.9337\n",
      "Epoch 2413/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1667 - val_accuracy: 0.9375\n",
      "Epoch 2414/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1857 - val_accuracy: 0.9299\n",
      "Epoch 2415/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1780 - val_accuracy: 0.9327\n",
      "Epoch 2416/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1681 - val_accuracy: 0.9373\n",
      "Epoch 2417/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1880 - val_accuracy: 0.9276\n",
      "Epoch 2418/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9326 - val_loss: 0.1653 - val_accuracy: 0.9381\n",
      "Epoch 2419/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1982 - val_accuracy: 0.9235\n",
      "Epoch 2420/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1687 - val_accuracy: 0.9361\n",
      "Epoch 2421/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9336 - val_loss: 0.1702 - val_accuracy: 0.9355\n",
      "Epoch 2422/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1785 - val_accuracy: 0.9327\n",
      "Epoch 2423/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9336 - val_loss: 0.1861 - val_accuracy: 0.9295\n",
      "Epoch 2424/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1863 - val_accuracy: 0.9290\n",
      "Epoch 2425/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1646 - val_accuracy: 0.9371\n",
      "Epoch 2426/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1699 - val_accuracy: 0.9346\n",
      "Epoch 2427/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.2034 - val_accuracy: 0.9215\n",
      "Epoch 2428/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1922 - val_accuracy: 0.9264\n",
      "Epoch 2429/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1828 - val_accuracy: 0.9304\n",
      "Epoch 2430/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1854 - val_accuracy: 0.9297\n",
      "Epoch 2431/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1830 - val_accuracy: 0.9306\n",
      "Epoch 2432/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1811 - val_accuracy: 0.9317\n",
      "Epoch 2433/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1890 - val_accuracy: 0.9283\n",
      "Epoch 2434/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1658 - val_accuracy: 0.9380\n",
      "Epoch 2435/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1808 - val_accuracy: 0.9320\n",
      "Epoch 2436/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1551 - val_accuracy: 0.9427\n",
      "Epoch 2437/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1825 - val_accuracy: 0.9314\n",
      "Epoch 2438/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1849 - val_accuracy: 0.9296\n",
      "Epoch 2439/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1788 - val_accuracy: 0.9323\n",
      "Epoch 2440/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9337 - val_loss: 0.1649 - val_accuracy: 0.9376\n",
      "Epoch 2441/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1687 - val_accuracy: 0.9370\n",
      "Epoch 2442/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9336 - val_loss: 0.1636 - val_accuracy: 0.9387\n",
      "Epoch 2443/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1854 - val_accuracy: 0.9286\n",
      "Epoch 2444/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1889 - val_accuracy: 0.9269\n",
      "Epoch 2445/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0064 - accuracy: 0.9336 - val_loss: 0.1870 - val_accuracy: 0.9288\n",
      "Epoch 2446/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.2031 - val_accuracy: 0.9224\n",
      "Epoch 2447/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1733 - val_accuracy: 0.9346\n",
      "Epoch 2448/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1787 - val_accuracy: 0.9323\n",
      "Epoch 2449/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1915 - val_accuracy: 0.9261\n",
      "Epoch 2450/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9330 - val_loss: 0.1831 - val_accuracy: 0.9306\n",
      "Epoch 2451/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1768 - val_accuracy: 0.9330\n",
      "Epoch 2452/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1996 - val_accuracy: 0.9236\n",
      "Epoch 2453/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.2026 - val_accuracy: 0.9228\n",
      "Epoch 2454/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1687 - val_accuracy: 0.9367\n",
      "Epoch 2455/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0064 - accuracy: 0.9336 - val_loss: 0.1829 - val_accuracy: 0.9303\n",
      "Epoch 2456/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1685 - val_accuracy: 0.9367\n",
      "Epoch 2457/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1848 - val_accuracy: 0.9300\n",
      "Epoch 2458/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0064 - accuracy: 0.9336 - val_loss: 0.1805 - val_accuracy: 0.9320\n",
      "Epoch 2459/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1731 - val_accuracy: 0.9346\n",
      "Epoch 2460/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9337 - val_loss: 0.1875 - val_accuracy: 0.9283\n",
      "Epoch 2461/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1602 - val_accuracy: 0.9404\n",
      "Epoch 2462/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1957 - val_accuracy: 0.9252\n",
      "Epoch 2463/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1885 - val_accuracy: 0.9284\n",
      "Epoch 2464/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9332 - val_loss: 0.1886 - val_accuracy: 0.9292\n",
      "Epoch 2465/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9338 - val_loss: 0.1963 - val_accuracy: 0.9252\n",
      "Epoch 2466/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1893 - val_accuracy: 0.9268\n",
      "Epoch 2467/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1761 - val_accuracy: 0.9328\n",
      "Epoch 2468/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1695 - val_accuracy: 0.9367\n",
      "Epoch 2469/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1650 - val_accuracy: 0.9386\n",
      "Epoch 2470/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9338 - val_loss: 0.1987 - val_accuracy: 0.9245\n",
      "Epoch 2471/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1657 - val_accuracy: 0.9377\n",
      "Epoch 2472/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1944 - val_accuracy: 0.9260\n",
      "Epoch 2473/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1857 - val_accuracy: 0.9304\n",
      "Epoch 2474/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9336 - val_loss: 0.1971 - val_accuracy: 0.9247\n",
      "Epoch 2475/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9329 - val_loss: 0.1923 - val_accuracy: 0.9267\n",
      "Epoch 2476/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1905 - val_accuracy: 0.9285\n",
      "Epoch 2477/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9337 - val_loss: 0.1723 - val_accuracy: 0.9355\n",
      "Epoch 2478/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0064 - accuracy: 0.9338 - val_loss: 0.1886 - val_accuracy: 0.9277\n",
      "Epoch 2479/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1889 - val_accuracy: 0.9279\n",
      "Epoch 2480/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9336 - val_loss: 0.1819 - val_accuracy: 0.9315\n",
      "Epoch 2481/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1731 - val_accuracy: 0.9346\n",
      "Epoch 2482/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0064 - accuracy: 0.9338 - val_loss: 0.1651 - val_accuracy: 0.9385\n",
      "Epoch 2483/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0064 - accuracy: 0.9336 - val_loss: 0.1641 - val_accuracy: 0.9389\n",
      "Epoch 2484/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9338 - val_loss: 0.1957 - val_accuracy: 0.9260\n",
      "Epoch 2485/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1857 - val_accuracy: 0.9295\n",
      "Epoch 2486/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9333 - val_loss: 0.1750 - val_accuracy: 0.9339\n",
      "Epoch 2487/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1704 - val_accuracy: 0.9360\n",
      "Epoch 2488/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9336 - val_loss: 0.1878 - val_accuracy: 0.9285\n",
      "Epoch 2489/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1747 - val_accuracy: 0.9331\n",
      "Epoch 2490/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1934 - val_accuracy: 0.9277\n",
      "Epoch 2491/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0064 - accuracy: 0.9337 - val_loss: 0.1904 - val_accuracy: 0.9280\n",
      "Epoch 2492/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9335 - val_loss: 0.1705 - val_accuracy: 0.9355\n",
      "Epoch 2493/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1793 - val_accuracy: 0.9316\n",
      "Epoch 2494/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0064 - accuracy: 0.9337 - val_loss: 0.1770 - val_accuracy: 0.9327\n",
      "Epoch 2495/2500\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.0065 - accuracy: 0.9334 - val_loss: 0.1700 - val_accuracy: 0.9352\n",
      "Epoch 2496/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9337 - val_loss: 0.1795 - val_accuracy: 0.9318\n",
      "Epoch 2497/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0065 - accuracy: 0.9338 - val_loss: 0.1868 - val_accuracy: 0.9273\n",
      "Epoch 2498/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0066 - accuracy: 0.9328 - val_loss: 0.1827 - val_accuracy: 0.9304\n",
      "Epoch 2499/2500\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.0064 - accuracy: 0.9340 - val_loss: 0.1741 - val_accuracy: 0.9334\n",
      "Epoch 2500/2500\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0065 - accuracy: 0.9331 - val_loss: 0.1677 - val_accuracy: 0.9373\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model.fit(x_train,y_train,\n",
    "              epochs=2500,batch_size=131072,\n",
    "              class_weight={0:0.999,1:0.025},\n",
    "              callbacks=[backup_callback,tensorboard_callback],\n",
    "              validation_split=0.2\n",
    "              )\n",
    "\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the data overfitting using test set and cheking if the accuracy is similar to the training and the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "722/722 [==============================] - 2s 2ms/step - loss: 0.1674 - accuracy: 0.9374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1673528552055359, 0.9374097585678101]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test,batch_size = 4096,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3606/3606 [==============================] - 6s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_set = dtset.copy()\n",
    "pred_set['pred'] = model.predict(pred_set.T[:-2].T,batch_size = 4096,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_sig = 0.999\n",
    "L = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly identified signal (True Positive)     :  1495783\n",
      "Falsely identified signal (Flase Positive)      :  517\n",
      "Correctly identified background (True Negative) :  10855262\n",
      "Falsely identified background (False Negative)  :  2417914\n"
     ]
    }
   ],
   "source": [
    "print('Correctly identified signal (True Positive)     : ',len(pred_set[pred_set['pred'] >= prob_sig][pred_set['tag'] == 1]))\n",
    "print('Falsely identified signal (Flase Positive)      : ',len(pred_set[pred_set['pred'] >= prob_sig][pred_set['tag'] == 0]))\n",
    "print('Correctly identified background (True Negative) : ',len(pred_set[pred_set['pred'] < prob_sig][pred_set['tag'] == 0]))\n",
    "print('Falsely identified background (False Negative)  : ',len(pred_set[pred_set['pred'] < prob_sig][pred_set['tag'] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thus, the rate of correct signal prediction is :  0.9996544810532647\n"
     ]
    }
   ],
   "source": [
    "print('Thus, the rate of correct signal prediction is : ',len(pred_set[pred_set['pred'] >= prob_sig][pred_set['tag'] == 1])/(len(pred_set[pred_set['pred'] >= prob_sig])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n2n2 1495783 0.38300000000000006\n",
      "ttbar 18 6538.845366086956\n",
      "wmp 41 91227.27272727272\n",
      "wpwm 199 692.2567850586979\n",
      "zwpm 259 199.5908264705882\n"
     ]
    }
   ],
   "source": [
    "ns = cs_corr['n2n2']*(len(pred_set[pred_set['pred'] >= prob_sig][pred_set['tag'] == 1])/(total_events[-1]))*L\n",
    "print('n2n2',(len(pred_set[pred_set['pred'] >= prob_sig][pred_set['tag'] == 1])),cs_corr['n2n2'])\n",
    "nb = 0\n",
    "\n",
    "for i in range(len(files)-1):\n",
    "    nb += cs_corr[files[i]]*(len(pred_set[pred_set['pred'] >= prob_sig][pred_set['tag'] == 0][pred_set['type'] == i])/((total_events[i])))*L\n",
    "    print(files[i],len(pred_set[pred_set['pred'] >= prob_sig][pred_set['tag'] == 0][pred_set['type'] == i]),cs_corr[files[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of signal is : 343.7309334000001\n",
      "The number of background is : 2110.1060329582433\n",
      "The significance is : 7.4828403217746935\n"
     ]
    }
   ],
   "source": [
    "print('The number of signal is :', ns)\n",
    "print('The number of background is :', nb)\n",
    "print('The significance is :',ns/np.sqrt(nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 21:05:35.902067: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home2/kalp_shah/neutrino/datasets/model/dnn750/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(model_dir + \"dnn\" + str(mn2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(files)):\n",
    "    data = pred_set[pred_set[\"type\"] == i][pred_set[\"pred\"]>=0.9][\"pred\"].values\n",
    "    plt.hist(data,alpha=0.7,bins=100,density=True)\n",
    "\n",
    "plt.xlim([0.98,1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
